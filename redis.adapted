[FUNC] **new** commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -108,19 +106,20 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) return NULL;
     void *ptr = malloc(MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */

[FUNC] **new** commit 3ea4c43add4f6038830ae0a6e42821481f7ce9a0
Date:   Thu Feb 25 09:24:41 2021 +0200

    Cleanup usage of malloc_usable_size. (#8554)
    
    * Add better control of malloc_usable_size() usage.
    * Use malloc_usable_size on alpine libc daily job.
    * Add no-malloc-usable-size daily jobs.
    * Fix zmalloc(0) when HAVE_MALLOC_SIZE is undefined.
    
    In order to align with the jemalloc behavior, this should never return
    NULL or OOM panic.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -94,19 +99,19 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
-    void *ptr = malloc(size+PREFIX_SIZE);
+    void *ptr = malloc(MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */

[SEC] **new** commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -91,18 +97,19 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = malloc(size+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -108,19 +106,20 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) return NULL;
     void *ptr = malloc(MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */

commit 3ea4c43add4f6038830ae0a6e42821481f7ce9a0
Date:   Thu Feb 25 09:24:41 2021 +0200

    Cleanup usage of malloc_usable_size. (#8554)
    
    * Add better control of malloc_usable_size() usage.
    * Use malloc_usable_size on alpine libc daily job.
    * Add no-malloc-usable-size daily jobs.
    * Fix zmalloc(0) when HAVE_MALLOC_SIZE is undefined.
    
    In order to align with the jemalloc behavior, this should never return
    NULL or OOM panic.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -94,19 +99,19 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
-    void *ptr = malloc(size+PREFIX_SIZE);
+    void *ptr = malloc(MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -91,18 +97,19 @@
 void *ztrymalloc_usable(size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = malloc(size+PREFIX_SIZE);
 
     if (!ptr) return NULL;
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory or panic */
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -151,8 +150,8 @@
 void *zmalloc_no_tcache(size_t size) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
+    if (size >= SIZE_MAX/2) zmalloc_oom_handler(size);
     void *ptr = mallocx(size+PREFIX_SIZE, MALLOCX_TCACHE_NONE);
     if (!ptr) zmalloc_oom_handler(size);
     update_zmalloc_stat_alloc(zmalloc_size(ptr));
     return ptr;
 }
 

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -133,7 +140,8 @@
 void *zmalloc_no_tcache(size_t size) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = mallocx(size+PREFIX_SIZE, MALLOCX_TCACHE_NONE);
     if (!ptr) zmalloc_oom_handler(size);
     update_zmalloc_stat_alloc(zmalloc_size(ptr));
     return ptr;
 }
 
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -168,20 +167,21 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) return NULL;
     void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory and zero it or panic.
  * We need this wrapper to have a calloc compatible signature */

[FUNC] **new** commit 5dd15443ac755d9ad2a22aa8c341b25d3de82eb4
Date:   Wed Jan 5 12:01:05 2022 +0000

    Added INFO LATENCYSTATS section: latency by percentile distribution/latency by cumulative distribution of latencies (#9462)
    
    # Short description
    
    The Redis extended latency stats track per command latencies and enables:
    - exporting the per-command percentile distribution via the `INFO LATENCYSTATS` command.
      **( percentile distribution is not mergeable between cluster nodes ).**
    - exporting the per-command cumulative latency distributions via the `LATENCY HISTOGRAM` command.
      Using the cumulative distribution of latencies we can merge several stats from different cluster nodes
      to calculate aggregate metrics .
    
    By default, the extended latency monitoring is enabled since the overhead of keeping track of the
    command latency is very small.
    
    If you don't want to track extended latency metrics, you can easily disable it at runtime using the command:
     - `CONFIG SET latency-tracking no`
    
    By default, the exported latency percentiles are the p50, p99, and p999.
    You can alter them at runtime using the command:
    - `CONFIG SET latency-tracking-info-percentiles "0.0 50.0 100.0"`
    
    
    ## Some details:
    - The total size per histogram should sit around 40 KiB. We only allocate those 40KiB when a command
      was called for the first time.
    - With regards to the WRITE overhead As seen below, there is no measurable overhead on the achievable
      ops/sec or full latency spectrum on the client. Including also the measured redis-benchmark for unstable
      vs this branch.
    - We track from 1 nanosecond to 1 second ( everything above 1 second is considered +Inf )
    
    ## `INFO LATENCYSTATS` exposition format
    
       - Format: `latency_percentiles_usec_<CMDNAME>:p0=XX,p50....`
    
    ## `LATENCY HISTOGRAM [command ...]` exposition format
    
    Return a cumulative distribution of latencies in the format of a histogram for the specified command names.
    
    The histogram is composed of a map of time buckets:
    - Each representing a latency range, between 1 nanosecond and roughly 1 second.
    - Each bucket covers twice the previous bucket's range.
    - Empty buckets are not printed.
    - Everything above 1 sec is considered +Inf.
    - At max there will be log2(1000000000)=30 buckets
    
    We reply a map for each command in the format:
    `<command name> : { `calls`: <total command calls> , `histogram` : { <bucket 1> : latency , < bucket 2> : latency, ...  } }`
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -166,18 +166,20 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
+/* Allocate memory and zero it or panic.
+ * We need this wrapper to have a calloc compatible signature */

commit 3ea4c43add4f6038830ae0a6e42821481f7ce9a0
Date:   Thu Feb 25 09:24:41 2021 +0200

    Cleanup usage of malloc_usable_size. (#8554)
    
    * Add better control of malloc_usable_size() usage.
    * Use malloc_usable_size on alpine libc daily job.
    * Add no-malloc-usable-size daily jobs.
    * Fix zmalloc(0) when HAVE_MALLOC_SIZE is undefined.
    
    In order to align with the jemalloc behavior, this should never return
    NULL or OOM panic.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -154,18 +159,18 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
-    void *ptr = calloc(1, size+PREFIX_SIZE);
+    void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -149,17 +157,18 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = calloc(1, size+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
commit 5dd15443ac755d9ad2a22aa8c341b25d3de82eb4
Date:   Wed Jan 5 12:01:05 2022 +0000

    Added INFO LATENCYSTATS section: latency by percentile distribution/latency by cumulative distribution of latencies (#9462)
    
    # Short description
    
    The Redis extended latency stats track per command latencies and enables:
    - exporting the per-command percentile distribution via the `INFO LATENCYSTATS` command.
      **( percentile distribution is not mergeable between cluster nodes ).**
    - exporting the per-command cumulative latency distributions via the `LATENCY HISTOGRAM` command.
      Using the cumulative distribution of latencies we can merge several stats from different cluster nodes
      to calculate aggregate metrics .
    
    By default, the extended latency monitoring is enabled since the overhead of keeping track of the
    command latency is very small.
    
    If you don't want to track extended latency metrics, you can easily disable it at runtime using the command:
     - `CONFIG SET latency-tracking no`
    
    By default, the exported latency percentiles are the p50, p99, and p999.
    You can alter them at runtime using the command:
    - `CONFIG SET latency-tracking-info-percentiles "0.0 50.0 100.0"`
    
    
    ## Some details:
    - The total size per histogram should sit around 40 KiB. We only allocate those 40KiB when a command
      was called for the first time.
    - With regards to the WRITE overhead As seen below, there is no measurable overhead on the achievable
      ops/sec or full latency spectrum on the client. Including also the measured redis-benchmark for unstable
      vs this branch.
    - We track from 1 nanosecond to 1 second ( everything above 1 second is considered +Inf )
    
    ## `INFO LATENCYSTATS` exposition format
    
       - Format: `latency_percentiles_usec_<CMDNAME>:p0=XX,p50....`
    
    ## `LATENCY HISTOGRAM [command ...]` exposition format
    
    Return a cumulative distribution of latencies in the format of a histogram for the specified command names.
    
    The histogram is composed of a map of time buckets:
    - Each representing a latency range, between 1 nanosecond and roughly 1 second.
    - Each bucket covers twice the previous bucket's range.
    - Empty buckets are not printed.
    - Everything above 1 sec is considered +Inf.
    - At max there will be log2(1000000000)=30 buckets
    
    We reply a map for each command in the format:
    `<command name> : { `calls`: <total command calls> , `histogram` : { <bucket 1> : latency , < bucket 2> : latency, ...  } }`
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -184,1 +186,13 @@
+void *zcalloc_num(size_t num, size_t size) {
+    /* Ensure that the arguments to calloc(), when multiplied, do not wrap.
+     * Division operations are susceptible to divide-by-zero errors so we also check it. */
+    if ((size == 0) || (num > SIZE_MAX/size)) {
+        zmalloc_oom_handler(SIZE_MAX);
+        return NULL;
+    }
+    void *ptr = ztrycalloc_usable(num*size, NULL);
+    if (!ptr) zmalloc_oom_handler(num*size);
+    return ptr;
+}
+
 /* Allocate memory and zero it or panic */
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -168,20 +167,21 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) return NULL;
     void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
 /* Allocate memory and zero it or panic.
  * We need this wrapper to have a calloc compatible signature */

commit 5dd15443ac755d9ad2a22aa8c341b25d3de82eb4
Date:   Wed Jan 5 12:01:05 2022 +0000

    Added INFO LATENCYSTATS section: latency by percentile distribution/latency by cumulative distribution of latencies (#9462)
    
    # Short description
    
    The Redis extended latency stats track per command latencies and enables:
    - exporting the per-command percentile distribution via the `INFO LATENCYSTATS` command.
      **( percentile distribution is not mergeable between cluster nodes ).**
    - exporting the per-command cumulative latency distributions via the `LATENCY HISTOGRAM` command.
      Using the cumulative distribution of latencies we can merge several stats from different cluster nodes
      to calculate aggregate metrics .
    
    By default, the extended latency monitoring is enabled since the overhead of keeping track of the
    command latency is very small.
    
    If you don't want to track extended latency metrics, you can easily disable it at runtime using the command:
     - `CONFIG SET latency-tracking no`
    
    By default, the exported latency percentiles are the p50, p99, and p999.
    You can alter them at runtime using the command:
    - `CONFIG SET latency-tracking-info-percentiles "0.0 50.0 100.0"`
    
    
    ## Some details:
    - The total size per histogram should sit around 40 KiB. We only allocate those 40KiB when a command
      was called for the first time.
    - With regards to the WRITE overhead As seen below, there is no measurable overhead on the achievable
      ops/sec or full latency spectrum on the client. Including also the measured redis-benchmark for unstable
      vs this branch.
    - We track from 1 nanosecond to 1 second ( everything above 1 second is considered +Inf )
    
    ## `INFO LATENCYSTATS` exposition format
    
       - Format: `latency_percentiles_usec_<CMDNAME>:p0=XX,p50....`
    
    ## `LATENCY HISTOGRAM [command ...]` exposition format
    
    Return a cumulative distribution of latencies in the format of a histogram for the specified command names.
    
    The histogram is composed of a map of time buckets:
    - Each representing a latency range, between 1 nanosecond and roughly 1 second.
    - Each bucket covers twice the previous bucket's range.
    - Empty buckets are not printed.
    - Everything above 1 sec is considered +Inf.
    - At max there will be log2(1000000000)=30 buckets
    
    We reply a map for each command in the format:
    `<command name> : { `calls`: <total command calls> , `histogram` : { <bucket 1> : latency , < bucket 2> : latency, ...  } }`
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -166,18 +166,20 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
+/* Allocate memory and zero it or panic.
+ * We need this wrapper to have a calloc compatible signature */

commit 3ea4c43add4f6038830ae0a6e42821481f7ce9a0
Date:   Thu Feb 25 09:24:41 2021 +0200

    Cleanup usage of malloc_usable_size. (#8554)
    
    * Add better control of malloc_usable_size() usage.
    * Use malloc_usable_size on alpine libc daily job.
    * Add no-malloc-usable-size daily jobs.
    * Fix zmalloc(0) when HAVE_MALLOC_SIZE is undefined.
    
    In order to align with the jemalloc behavior, this should never return
    NULL or OOM panic.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -154,18 +159,18 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
     ASSERT_NO_SIZE_OVERFLOW(size);
-    void *ptr = calloc(1, size+PREFIX_SIZE);
+    void *ptr = calloc(1, MALLOC_MIN_SIZE(size)+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -149,17 +157,18 @@
 void *ztrycalloc_usable(size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
     void *ptr = calloc(1, size+PREFIX_SIZE);
     if (ptr == NULL) return NULL;
 
 #ifdef HAVE_MALLOC_SIZE
     size = zmalloc_size(ptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return ptr;
 #else
     *((size_t*)ptr) = size;
     update_zmalloc_stat_alloc(size+PREFIX_SIZE);
     if (usable) *usable = size;
     return (char*)ptr+PREFIX_SIZE;
 #endif
 }
 
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -223,49 +223,55 @@
 void *ztryrealloc_usable(void *ptr, size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
 #ifndef HAVE_MALLOC_SIZE
     void *realptr;
 #endif
     size_t oldsize;
     void *newptr;
 
     /* not allocating anything, just redirect to free. */
     if (size == 0 && ptr != NULL) {
         zfree(ptr);
         if (usable) *usable = 0;
         return NULL;
     }
     /* Not freeing anything, just redirect to malloc. */
     if (ptr == NULL)
         return ztrymalloc_usable(size, usable);
 
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) {
+        zfree(ptr);
+        if (usable) *usable = 0;
+        return NULL;
+    }
+
 #ifdef HAVE_MALLOC_SIZE
     oldsize = zmalloc_size(ptr);
     newptr = realloc(ptr,size);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     update_zmalloc_stat_free(oldsize);
     size = zmalloc_size(newptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return newptr;
 #else
     realptr = (char*)ptr-PREFIX_SIZE;
     oldsize = *((size_t*)realptr);
     newptr = realloc(realptr,size+PREFIX_SIZE);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     *((size_t*)newptr) = size;
     update_zmalloc_stat_free(oldsize);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return (char*)newptr+PREFIX_SIZE;
 #endif
 }
 
 /* Reallocate memory and zero it or panic */

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -189,48 +198,49 @@
 void *ztryrealloc_usable(void *ptr, size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
 #ifndef HAVE_MALLOC_SIZE
     void *realptr;
 #endif
     size_t oldsize;
     void *newptr;
 
     /* not allocating anything, just redirect to free. */
     if (size == 0 && ptr != NULL) {
         zfree(ptr);
         if (usable) *usable = 0;
         return NULL;
     }
     /* Not freeing anything, just redirect to malloc. */
     if (ptr == NULL)
         return ztrymalloc_usable(size, usable);
 
 #ifdef HAVE_MALLOC_SIZE
     oldsize = zmalloc_size(ptr);
     newptr = realloc(ptr,size);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     update_zmalloc_stat_free(oldsize);
     size = zmalloc_size(newptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return newptr;
 #else
     realptr = (char*)ptr-PREFIX_SIZE;
     oldsize = *((size_t*)realptr);
     newptr = realloc(realptr,size+PREFIX_SIZE);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     *((size_t*)newptr) = size;
     update_zmalloc_stat_free(oldsize);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return (char*)newptr+PREFIX_SIZE;
 #endif
 }
 
 /* Reallocate memory and zero it or panic */
commit 599e59ebc57283f52c60a8de56ec5f44d053109a
Date:   Wed Jul 13 09:14:38 2022 +0300

    Avoid valgrind fishy value warning on corrupt restore payloads (#10937)
    
    The corrupt dump fuzzer uncovered a valgrind warning saying:
    ```
    ==76370== Argument 'size' of function malloc has a fishy (possibly negative) value: -3744781444216323815
    ```
    This allocation would have failed (returning NULL) and being handled properly by redis (even before this change), but we also want to silence the valgrind warnings (which are checking that casting to ssize_t produces a non-negative value).
    
    The solution i opted for is to explicitly fail these allocations (returning NULL), before even reaching `malloc` (which would have failed and return NULL too).
    
    The implication is that we will not be able to support a single allocation of more than 2GB on a 32bit system (which i don't think is a realistic scenario).
    i.e. i do think we could be facing cases were redis consumes more than 2gb on a 32bit system, but not in a single allocation.
    
    The byproduct of this, is that i dropped the overflow assertions, since these will now lead to the same OOM panic we have for failed allocations.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -223,49 +223,55 @@
 void *ztryrealloc_usable(void *ptr, size_t size, size_t *usable) {
-    ASSERT_NO_SIZE_OVERFLOW(size);
 #ifndef HAVE_MALLOC_SIZE
     void *realptr;
 #endif
     size_t oldsize;
     void *newptr;
 
     /* not allocating anything, just redirect to free. */
     if (size == 0 && ptr != NULL) {
         zfree(ptr);
         if (usable) *usable = 0;
         return NULL;
     }
     /* Not freeing anything, just redirect to malloc. */
     if (ptr == NULL)
         return ztrymalloc_usable(size, usable);
 
+    /* Possible overflow, return NULL, so that the caller can panic or handle a failed allocation. */
+    if (size >= SIZE_MAX/2) {
+        zfree(ptr);
+        if (usable) *usable = 0;
+        return NULL;
+    }
+
 #ifdef HAVE_MALLOC_SIZE
     oldsize = zmalloc_size(ptr);
     newptr = realloc(ptr,size);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     update_zmalloc_stat_free(oldsize);
     size = zmalloc_size(newptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return newptr;
 #else
     realptr = (char*)ptr-PREFIX_SIZE;
     oldsize = *((size_t*)realptr);
     newptr = realloc(realptr,size+PREFIX_SIZE);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     *((size_t*)newptr) = size;
     update_zmalloc_stat_free(oldsize);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return (char*)newptr+PREFIX_SIZE;
 #endif
 }
 
 /* Reallocate memory and zero it or panic */

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/zmalloc.c b/src/zmalloc.c
--- a/src/zmalloc.c
+++ b/src/zmalloc.c
@@ -189,48 +198,49 @@
 void *ztryrealloc_usable(void *ptr, size_t size, size_t *usable) {
+    ASSERT_NO_SIZE_OVERFLOW(size);
 #ifndef HAVE_MALLOC_SIZE
     void *realptr;
 #endif
     size_t oldsize;
     void *newptr;
 
     /* not allocating anything, just redirect to free. */
     if (size == 0 && ptr != NULL) {
         zfree(ptr);
         if (usable) *usable = 0;
         return NULL;
     }
     /* Not freeing anything, just redirect to malloc. */
     if (ptr == NULL)
         return ztrymalloc_usable(size, usable);
 
 #ifdef HAVE_MALLOC_SIZE
     oldsize = zmalloc_size(ptr);
     newptr = realloc(ptr,size);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     update_zmalloc_stat_free(oldsize);
     size = zmalloc_size(newptr);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return newptr;
 #else
     realptr = (char*)ptr-PREFIX_SIZE;
     oldsize = *((size_t*)realptr);
     newptr = realloc(realptr,size+PREFIX_SIZE);
     if (newptr == NULL) {
         if (usable) *usable = 0;
         return NULL;
     }
 
     *((size_t*)newptr) = size;
     update_zmalloc_stat_free(oldsize);
     update_zmalloc_stat_alloc(size);
     if (usable) *usable = size;
     return (char*)newptr+PREFIX_SIZE;
 #endif
 }
 
 /* Reallocate memory and zero it or panic */
[FUNC] **new** commit b60d33c91eef09aea34cecad789c552405737c55
Date:   Sun Nov 20 23:23:54 2022 +0100

    Remove the bucket-cb from dictScan and move dictEntry defrag to dictScanDefrag
    
    This change deletes the dictGetNext and dictGetNextRef functions, so the
    dict API doesn't expose the next field at all.
    
    The bucket function in dictScan is deleted. A separate dictScanDefrag function
    is added which takes a defrag alloc function to defrag-reallocate the dict entries.
    
    "Dirty" code accessing the dict internals in active defrag is removed.
    
    An 'afterReplaceEntry' is added to dictType, which allows the dict user
    to keep the dictEntry metadata up to date after reallocation/defrag/move.
    
    Additionally, for updating the cluster slot-to-key mapping, after a dictEntry
    has been reallocated, we need to know which db a dict belongs to, so we store
    a pointer to the db in a new metadata section in the dict struct, which is
    a new mechanism similar to dictEntry metadata. This adds some complexity but
    provides better isolation.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -121,9 +121,13 @@
 dict *dictCreate(dictType *type)
 {
-    dict *d = zmalloc(sizeof(*d));
+    size_t metasize = type->dictMetadataBytes ? type->dictMetadataBytes() : 0;
+    dict *d = zmalloc(sizeof(*d) + metasize);
+    if (metasize) {
+        memset(dictMetadata(d), 0, metasize);
+    }
 
     _dictInit(d,type);
     return d;
 }
 
 /* Initialize the hash table */

[PERF] **new** commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -107,10 +106,9 @@
-dict *dictCreate(dictType *type,
-        void *privDataPtr)
+dict *dictCreate(dictType *type)
 {
     dict *d = zmalloc(sizeof(*d));
 
-    _dictInit(d,type,privDataPtr);
+    _dictInit(d,type);
     return d;
 }
 
 /* Initialize the hash table */
commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -63,4 +63,1 @@
-static int _dictExpandIfNeeded(dict *ht);
-static unsigned long _dictNextPower(unsigned long size);
-static long _dictKeyIndex(dict *ht, const void *key, uint64_t hash, dictEntry **existing);
-static int _dictInit(dict *ht, dictType *type, void *privDataPtr);
+static int _dictExpandIfNeeded(dict *d);
[FUNC] **new** commit fb1d56bc2ae6466f4f6eac5a966936b904b5dbdc
Date:   Thu Sep 8 04:57:43 2022 +0300

    Added API to initialize dictionary iterators without memory allocation (#11245)
    
    * Added api to use dictionary iterators without calling malloc.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -585,3 +601,7 @@
+dictIterator *dictGetIterator(dict *d)
+{
+    dictIterator *iter = zmalloc(sizeof(*iter));
+    dictInitIterator(iter, d);
     return iter;
 }
 
commit b60d33c91eef09aea34cecad789c552405737c55
Date:   Sun Nov 20 23:23:54 2022 +0100

    Remove the bucket-cb from dictScan and move dictEntry defrag to dictScanDefrag
    
    This change deletes the dictGetNext and dictGetNextRef functions, so the
    dict API doesn't expose the next field at all.
    
    The bucket function in dictScan is deleted. A separate dictScanDefrag function
    is added which takes a defrag alloc function to defrag-reallocate the dict entries.
    
    "Dirty" code accessing the dict internals in active defrag is removed.
    
    An 'afterReplaceEntry' is added to dictType, which allows the dict user
    to keep the dictEntry metadata up to date after reallocation/defrag/move.
    
    Additionally, for updating the cluster slot-to-key mapping, after a dictEntry
    has been reallocated, we need to know which db a dict belongs to, so we store
    a pointer to the db in a new metadata section in the dict struct, which is
    a new mechanism similar to dictEntry metadata. This adds some complexity but
    provides better isolation.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -350,37 +359,37 @@
 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)
 {
     long index;
     dictEntry *entry;
     int htidx;
 
     if (dictIsRehashing(d)) _dictRehashStep(d);
 
     /* Get the index of the new element, or -1 if
      * the element already exists. */
     if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
         return NULL;
 
     /* Allocate the memory and store the new entry.
      * Insert the element in top, with the assumption that in a database
      * system it is more likely that recently added entries are accessed
      * more frequently. */
     htidx = dictIsRehashing(d) ? 1 : 0;
-    size_t metasize = dictMetadataSize(d);
+    size_t metasize = dictEntryMetadataSize(d);
     entry = zmalloc(sizeof(*entry) + metasize);
     if (metasize > 0) {
-        memset(dictMetadata(entry), 0, metasize);
+        memset(dictEntryMetadata(entry), 0, metasize);
     }
     entry->next = d->ht_table[htidx][index];
     d->ht_table[htidx][index] = entry;
     d->ht_used[htidx]++;
 
     /* Set the hash entry fields. */
     dictSetKey(d, entry, key);
     return entry;
 }
 
 /* Add or Overwrite:
  * Add an element, discarding the old value if the key already exists.
  * Return 1 if the key was added from scratch, 0 if there was already an
  * element with such key and dictReplace() just performed a value update
  * operation. */

[FUNC] **new** commit f24c63a292e045d4b14b82b25981f00a95c1767a
Date:   Tue Aug 31 08:25:36 2021 +0200

    Slot-to-keys using dict entry metadata (#9356)
    
    * Enhance dict to support arbitrary metadata carried in dictEntry
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor.soderqvist@est.tech>
    
    * Rewrite slot-to-keys mapping to linked lists using dict entry metadata
    
    This is a memory enhancement for Redis Cluster.
    
    The radix tree slots_to_keys (which duplicates all key names prefixed with their
    slot number) is replaced with a linked list for each slot. The dict entries of
    the same cluster slot form a linked list and the pointers are stored as metadata
    in each dict entry of the main DB dict.
    
    This commit also moves the slot-to-key API from db.c to cluster.c.
    
    Co-authored-by: Jim Brunner <brunnerj@amazon.com>

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -323,33 +323,37 @@
 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)
 {
     long index;
     dictEntry *entry;
     int htidx;
 
     if (dictIsRehashing(d)) _dictRehashStep(d);
 
     /* Get the index of the new element, or -1 if
      * the element already exists. */
     if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
         return NULL;
 
     /* Allocate the memory and store the new entry.
      * Insert the element in top, with the assumption that in a database
      * system it is more likely that recently added entries are accessed
      * more frequently. */
     htidx = dictIsRehashing(d) ? 1 : 0;
-    entry = zmalloc(sizeof(*entry));
+    size_t metasize = dictMetadataSize(d);
+    entry = zmalloc(sizeof(*entry) + metasize);
+    if (metasize > 0) {
+        memset(dictMetadata(entry), 0, metasize);
+    }
     entry->next = d->ht_table[htidx][index];
     d->ht_table[htidx][index] = entry;
     d->ht_used[htidx]++;
 
     /* Set the hash entry fields. */
     dictSetKey(d, entry, key);
     return entry;
 }
 
 /* Add or Overwrite:
  * Add an element, discarding the old value if the key already exists.
  * Return 1 if the key was added from scratch, 0 if there was already an
  * element with such key and dictReplace() just performed a value update
  * operation. */

commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -315,33 +318,33 @@
 dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)
 {
     long index;
     dictEntry *entry;
-    dictht *ht;
+    int htidx;
 
     if (dictIsRehashing(d)) _dictRehashStep(d);
 
     /* Get the index of the new element, or -1 if
      * the element already exists. */
     if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
         return NULL;
 
     /* Allocate the memory and store the new entry.
      * Insert the element in top, with the assumption that in a database
      * system it is more likely that recently added entries are accessed
      * more frequently. */
-    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
+    htidx = dictIsRehashing(d) ? 1 : 0;
     entry = zmalloc(sizeof(*entry));
-    entry->next = ht->table[index];
-    ht->table[index] = entry;
-    ht->used++;
+    entry->next = d->ht_table[htidx][index];
+    d->ht_table[htidx][index] = entry;
+    d->ht_used[htidx]++;
 
     /* Set the hash entry fields. */
     dictSetKey(d, entry, key);
     return entry;
 }
 
 /* Add or Overwrite:
  * Add an element, discarding the old value if the key already exists.
  * Return 1 if the key was added from scratch, 0 if there was already an
  * element with such key and dictReplace() just performed a value update
  * operation. */
[NA] **new** commit 303465af35c13691f989b3400b028a94df1235d4
Date:   Wed Feb 17 23:13:50 2021 +0100

    Remove redundant pubsub list to store the patterns. (#8472)
    
    Remove redundant pubsub list to store the patterns.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -292,27 +292,27 @@
 int dictAdd(dict *d, void *key, void *val)
 {
     dictEntry *entry = dictAddRaw(d,key,NULL);
 
     if (!entry) return DICT_ERR;
     dictSetVal(d, entry, val);
     return DICT_OK;
 }
 
 /* Low level add or find:
  * This function adds the entry but instead of setting a value returns the
  * dictEntry structure to the user, that will make sure to fill the value
- * field as he wishes.
+ * field as they wish.
  *
  * This function is also directly exposed to the user API to be called
  * mainly in order to store non-pointers inside the hash value, example:
  *
  * entry = dictAddRaw(dict,mykey,NULL);
  * if (entry != NULL) dictSetSignedIntegerVal(entry,1000);
  *
  * Return values:
  *
  * If key already exists NULL is returned, and "*existing" is populated
  * with the existing entry if existing is not NULL.
  *
  * If key was added, the hash entry is returned to be manipulated by the caller.
  */
commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -103,64 +103,65 @@
 sds _sdsnewlen(const void *init, size_t initlen, int trymalloc) {
     void *sh;
     sds s;
     char type = sdsReqType(initlen);
     /* Empty strings are usually created in order to append. Use type 8
      * since type 5 is not good at this. */
     if (type == SDS_TYPE_5 && initlen == 0) type = SDS_TYPE_8;
     int hdrlen = sdsHdrSize(type);
     unsigned char *fp; /* flags pointer. */
     size_t usable;
 
+    assert(initlen + hdrlen + 1 > initlen); /* Catch size_t overflow */
     sh = trymalloc?
         s_trymalloc_usable(hdrlen+initlen+1, &usable) :
         s_malloc_usable(hdrlen+initlen+1, &usable);
     if (sh == NULL) return NULL;
     if (init==SDS_NOINIT)
         init = NULL;
     else if (!init)
         memset(sh, 0, hdrlen+initlen+1);
     s = (char*)sh+hdrlen;
     fp = ((unsigned char*)s)-1;
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     switch(type) {
         case SDS_TYPE_5: {
             *fp = type | (initlen << SDS_TYPE_BITS);
             break;
         }
         case SDS_TYPE_8: {
             SDS_HDR_VAR(8,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_16: {
             SDS_HDR_VAR(16,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_32: {
             SDS_HDR_VAR(32,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_64: {
             SDS_HDR_VAR(64,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
     }
     if (initlen && init)
         memcpy(s, init, initlen);
     s[initlen] = '\0';
     return s;
 }
 
commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -103,64 +103,65 @@
 sds _sdsnewlen(const void *init, size_t initlen, int trymalloc) {
     void *sh;
     sds s;
     char type = sdsReqType(initlen);
     /* Empty strings are usually created in order to append. Use type 8
      * since type 5 is not good at this. */
     if (type == SDS_TYPE_5 && initlen == 0) type = SDS_TYPE_8;
     int hdrlen = sdsHdrSize(type);
     unsigned char *fp; /* flags pointer. */
     size_t usable;
 
+    assert(initlen + hdrlen + 1 > initlen); /* Catch size_t overflow */
     sh = trymalloc?
         s_trymalloc_usable(hdrlen+initlen+1, &usable) :
         s_malloc_usable(hdrlen+initlen+1, &usable);
     if (sh == NULL) return NULL;
     if (init==SDS_NOINIT)
         init = NULL;
     else if (!init)
         memset(sh, 0, hdrlen+initlen+1);
     s = (char*)sh+hdrlen;
     fp = ((unsigned char*)s)-1;
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     switch(type) {
         case SDS_TYPE_5: {
             *fp = type | (initlen << SDS_TYPE_BITS);
             break;
         }
         case SDS_TYPE_8: {
             SDS_HDR_VAR(8,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_16: {
             SDS_HDR_VAR(16,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_32: {
             SDS_HDR_VAR(32,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_64: {
             SDS_HDR_VAR(64,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
     }
     if (initlen && init)
         memcpy(s, init, initlen);
     s[initlen] = '\0';
     return s;
 }
 
commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -103,64 +103,65 @@
 sds _sdsnewlen(const void *init, size_t initlen, int trymalloc) {
     void *sh;
     sds s;
     char type = sdsReqType(initlen);
     /* Empty strings are usually created in order to append. Use type 8
      * since type 5 is not good at this. */
     if (type == SDS_TYPE_5 && initlen == 0) type = SDS_TYPE_8;
     int hdrlen = sdsHdrSize(type);
     unsigned char *fp; /* flags pointer. */
     size_t usable;
 
+    assert(initlen + hdrlen + 1 > initlen); /* Catch size_t overflow */
     sh = trymalloc?
         s_trymalloc_usable(hdrlen+initlen+1, &usable) :
         s_malloc_usable(hdrlen+initlen+1, &usable);
     if (sh == NULL) return NULL;
     if (init==SDS_NOINIT)
         init = NULL;
     else if (!init)
         memset(sh, 0, hdrlen+initlen+1);
     s = (char*)sh+hdrlen;
     fp = ((unsigned char*)s)-1;
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     switch(type) {
         case SDS_TYPE_5: {
             *fp = type | (initlen << SDS_TYPE_BITS);
             break;
         }
         case SDS_TYPE_8: {
             SDS_HDR_VAR(8,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_16: {
             SDS_HDR_VAR(16,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_32: {
             SDS_HDR_VAR(32,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
         case SDS_TYPE_64: {
             SDS_HDR_VAR(64,s);
             sh->len = initlen;
             sh->alloc = usable;
             *fp = type;
             break;
         }
     }
     if (initlen && init)
         memcpy(s, init, initlen);
     s[initlen] = '\0';
     return s;
 }
 
[SEC] **new** commit 24cc0b984d4ed5045c6ff125b0e619b6ce5ea9c6
Date:   Mon Oct 4 16:11:09 2021 +0800

    Fix integer overflow in _sdsMakeRoomFor (CVE-2021-41099) (#9558)
    
    The existing overflow checks handled the greedy growing, but didn't handle
    a case where the addition of the header size is what causes the overflow.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -239,55 +239,55 @@
 sds _sdsMakeRoomFor(sds s, size_t addlen, int greedy) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
-    size_t len, newlen;
+    size_t len, newlen, reqlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
-    newlen = (len+addlen);
+    reqlen = newlen = (len+addlen);
     assert(newlen > len);   /* Catch size_t overflow */
     if (greedy == 1) {
         if (newlen < SDS_MAX_PREALLOC)
             newlen *= 2;
         else
             newlen += SDS_MAX_PREALLOC;
     }
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
-    assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
+    assert(hdrlen + newlen + 1 > reqlen);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
 /* Enlarge the free space at the end of the sds string more than needed,
  * This is useful to avoid repeated re-allocations when repeatedly appending to the sds. */

[CORR] **new** commit e5d8a5eb85b50ee7da1bf652c7d67e8e5b757ec9
Date:   Tue Jun 15 19:46:19 2021 +0800

    Fix the wrong reisze of querybuf (#9003)
    
    The initialize memory of `querybuf` is `PROTO_IOBUF_LEN(1024*16) * 2` (due to sdsMakeRoomFor being greedy), under `jemalloc`, the allocated memory will be 40k.
    This will most likely result in the `querybuf` being resized when call `clientsCronResizeQueryBuffer` unless the client requests it fast enough.
    
    Note that this bug existed even before #7875, since the condition for resizing includes the sds headers (32k+6).
    
    ## Changes
    1. Use non-greedy sdsMakeRoomFor when allocating the initial query buffer (of 16k).
    1. Also use non-greedy allocation when working with BIG_ARG (we won't use that extra space anyway)
    2. in case we did use a greedy allocation, read as much as we can into the buffer we got (including internal frag), to reduce system calls.
    3. introduce a dedicated constant for the shrinking (same value as before)
    3. Add test for querybuf.
    4. improve a maxmemory test by ignoring the effect of replica query buffers (can accumulate many ACKs on slow env)
    5. improve a maxmemory by disabling slowlog (it will cause slight memory growth on slow env).

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -233,51 +239,55 @@
-sds sdsMakeRoomFor(sds s, size_t addlen) {
+sds _sdsMakeRoomFor(sds s, size_t addlen, int greedy) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
     size_t len, newlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
     newlen = (len+addlen);
     assert(newlen > len);   /* Catch size_t overflow */
-    if (newlen < SDS_MAX_PREALLOC)
-        newlen *= 2;
-    else
-        newlen += SDS_MAX_PREALLOC;
+    if (greedy == 1) {
+        if (newlen < SDS_MAX_PREALLOC)
+            newlen *= 2;
+        else
+            newlen += SDS_MAX_PREALLOC;
+    }
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
     assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
+/* Enlarge the free space at the end of the sds string more than needed,
+ * This is useful to avoid repeated re-allocations when repeatedly appending to the sds. */

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -232,49 +233,51 @@
 sds sdsMakeRoomFor(sds s, size_t addlen) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
     size_t len, newlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
     newlen = (len+addlen);
+    assert(newlen > len);   /* Catch size_t overflow */
     if (newlen < SDS_MAX_PREALLOC)
         newlen *= 2;
     else
         newlen += SDS_MAX_PREALLOC;
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
+    assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
commit 24cc0b984d4ed5045c6ff125b0e619b6ce5ea9c6
Date:   Mon Oct 4 16:11:09 2021 +0800

    Fix integer overflow in _sdsMakeRoomFor (CVE-2021-41099) (#9558)
    
    The existing overflow checks handled the greedy growing, but didn't handle
    a case where the addition of the header size is what causes the overflow.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -239,55 +239,55 @@
 sds _sdsMakeRoomFor(sds s, size_t addlen, int greedy) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
-    size_t len, newlen;
+    size_t len, newlen, reqlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
-    newlen = (len+addlen);
+    reqlen = newlen = (len+addlen);
     assert(newlen > len);   /* Catch size_t overflow */
     if (greedy == 1) {
         if (newlen < SDS_MAX_PREALLOC)
             newlen *= 2;
         else
             newlen += SDS_MAX_PREALLOC;
     }
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
-    assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
+    assert(hdrlen + newlen + 1 > reqlen);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
 /* Enlarge the free space at the end of the sds string more than needed,
  * This is useful to avoid repeated re-allocations when repeatedly appending to the sds. */

commit e5d8a5eb85b50ee7da1bf652c7d67e8e5b757ec9
Date:   Tue Jun 15 19:46:19 2021 +0800

    Fix the wrong reisze of querybuf (#9003)
    
    The initialize memory of `querybuf` is `PROTO_IOBUF_LEN(1024*16) * 2` (due to sdsMakeRoomFor being greedy), under `jemalloc`, the allocated memory will be 40k.
    This will most likely result in the `querybuf` being resized when call `clientsCronResizeQueryBuffer` unless the client requests it fast enough.
    
    Note that this bug existed even before #7875, since the condition for resizing includes the sds headers (32k+6).
    
    ## Changes
    1. Use non-greedy sdsMakeRoomFor when allocating the initial query buffer (of 16k).
    1. Also use non-greedy allocation when working with BIG_ARG (we won't use that extra space anyway)
    2. in case we did use a greedy allocation, read as much as we can into the buffer we got (including internal frag), to reduce system calls.
    3. introduce a dedicated constant for the shrinking (same value as before)
    3. Add test for querybuf.
    4. improve a maxmemory test by ignoring the effect of replica query buffers (can accumulate many ACKs on slow env)
    5. improve a maxmemory by disabling slowlog (it will cause slight memory growth on slow env).

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -233,51 +239,55 @@
-sds sdsMakeRoomFor(sds s, size_t addlen) {
+sds _sdsMakeRoomFor(sds s, size_t addlen, int greedy) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
     size_t len, newlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
     newlen = (len+addlen);
     assert(newlen > len);   /* Catch size_t overflow */
-    if (newlen < SDS_MAX_PREALLOC)
-        newlen *= 2;
-    else
-        newlen += SDS_MAX_PREALLOC;
+    if (greedy == 1) {
+        if (newlen < SDS_MAX_PREALLOC)
+            newlen *= 2;
+        else
+            newlen += SDS_MAX_PREALLOC;
+    }
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
     assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
+/* Enlarge the free space at the end of the sds string more than needed,
+ * This is useful to avoid repeated re-allocations when repeatedly appending to the sds. */

commit d32f2e9999ce003bad0bd2c3bca29f64dcce4433
Date:   Mon Feb 22 15:41:32 2021 +0200

    Fix integer overflow (CVE-2021-21309). (#8522)
    
    On 32-bit systems, setting the proto-max-bulk-len config parameter to a high value may result with integer overflow and a subsequent heap overflow when parsing an input bulk (CVE-2021-21309).
    
    This fix has two parts:
    
    Set a reasonable limit to the config parameter.
    Add additional checks to prevent the problem in other potential but unknown code paths.

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -232,49 +233,51 @@
 sds sdsMakeRoomFor(sds s, size_t addlen) {
     void *sh, *newsh;
     size_t avail = sdsavail(s);
     size_t len, newlen;
     char type, oldtype = s[-1] & SDS_TYPE_MASK;
     int hdrlen;
     size_t usable;
 
     /* Return ASAP if there is enough space left. */
     if (avail >= addlen) return s;
 
     len = sdslen(s);
     sh = (char*)s-sdsHdrSize(oldtype);
     newlen = (len+addlen);
+    assert(newlen > len);   /* Catch size_t overflow */
     if (newlen < SDS_MAX_PREALLOC)
         newlen *= 2;
     else
         newlen += SDS_MAX_PREALLOC;
 
     type = sdsReqType(newlen);
 
     /* Don't use type 5: the user is appending to the string and type 5 is
      * not able to remember empty space, so sdsMakeRoomFor() must be called
      * at every appending operation. */
     if (type == SDS_TYPE_5) type = SDS_TYPE_8;
 
     hdrlen = sdsHdrSize(type);
+    assert(hdrlen + newlen + 1 > len);  /* Catch size_t overflow */
     if (oldtype==type) {
         newsh = s_realloc_usable(sh, hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         s = (char*)newsh+hdrlen;
     } else {
         /* Since the header size changes, need to move the string forward,
          * and can't use realloc */
         newsh = s_malloc_usable(hdrlen+newlen+1, &usable);
         if (newsh == NULL) return NULL;
         memcpy((char*)newsh+hdrlen, s, len+1);
         s_free(sh);
         s = (char*)newsh+hdrlen;
         s[-1] = type;
         sdssetlen(s, len);
     }
     usable = usable-hdrlen-1;
     if (usable > sdsTypeMaxSize(type))
         usable = sdsTypeMaxSize(type);
     sdssetalloc(s, usable);
     return s;
 }
 
commit e5d8a5eb85b50ee7da1bf652c7d67e8e5b757ec9
Date:   Tue Jun 15 19:46:19 2021 +0800

    Fix the wrong reisze of querybuf (#9003)
    
    The initialize memory of `querybuf` is `PROTO_IOBUF_LEN(1024*16) * 2` (due to sdsMakeRoomFor being greedy), under `jemalloc`, the allocated memory will be 40k.
    This will most likely result in the `querybuf` being resized when call `clientsCronResizeQueryBuffer` unless the client requests it fast enough.
    
    Note that this bug existed even before #7875, since the condition for resizing includes the sds headers (32k+6).
    
    ## Changes
    1. Use non-greedy sdsMakeRoomFor when allocating the initial query buffer (of 16k).
    1. Also use non-greedy allocation when working with BIG_ARG (we won't use that extra space anyway)
    2. in case we did use a greedy allocation, read as much as we can into the buffer we got (including internal frag), to reduce system calls.
    3. introduce a dedicated constant for the shrinking (same value as before)
    3. Add test for querybuf.
    4. improve a maxmemory test by ignoring the effect of replica query buffers (can accumulate many ACKs on slow env)
    5. improve a maxmemory by disabling slowlog (it will cause slight memory growth on slow env).

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -284,6 +299,10 @@
+sds sdsMakeRoomForNonGreedy(sds s, size_t addlen) {
+    return _sdsMakeRoomFor(s, addlen, 0);
+}
+
 /* Reallocate the sds string so that it has no free space at the end. The
  * contained string remains not altered, but next concatenation operations
  * will require a reallocation.
  *
  * After the call, the passed sds string is no longer valid and all the
  * references must be substituted with the new pointer returned by the call. */
[FUNC] **new** commit ec582cc7ad0706e252bc905822226e49f4c4d0e4
Date:   Mon Jul 5 09:02:54 2021 +0300

    Query buffer shrinking improvements (#5013)
    
    when tracking the peak, don't reset the peak to 0, reset it to the
    maximum of the current used, and the planned to be used by the current
    arg.
    
    when shrining, split the two separate conditions.
    the idle time shrinking will remove all free space.
    but the peak based shrinking will keep room for the current arg.
    
    when we resize due to a peak (rahter than idle time), don't trim all
    unused space, let the qbuf keep a size that's sufficient for the
    currently process bulklen, and the current peak.
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: yoav-steinberg <yoav@monfort.co.il>

diff --git a/src/sds.c b/src/sds.c
--- a/src/sds.c
+++ b/src/sds.c
@@ -346,7 +348,50 @@
+sds sdsResize(sds s, size_t size) {
+    void *sh, *newsh;
+    char type, oldtype = s[-1] & SDS_TYPE_MASK;
+    int hdrlen, oldhdrlen = sdsHdrSize(oldtype);
+    size_t len = sdslen(s);
+    sh = (char*)s-oldhdrlen;
+
+    /* Return ASAP if the size is already good. */
+    if (sdsalloc(s) == size) return s;
+
+    /* Truncate len if needed. */
+    if (size < len) len = size;
+
+    /* Check what would be the minimum SDS header that is just good enough to
+     * fit this string. */
+    type = sdsReqType(size);
+    /* Don't use type 5, it is not good for strings that are resized. */
+    if (type == SDS_TYPE_5) type = SDS_TYPE_8;
+    hdrlen = sdsHdrSize(type);
+
+    /* If the type is the same, or can hold the size in it with low overhead
+     * (larger than SDS_TYPE_8), we just realloc(), letting the allocator
+     * to do the copy only if really needed. Otherwise if the change is
+     * huge, we manually reallocate the string to use the different header
+     * type. */
+    if (oldtype==type || (type < oldtype && type > SDS_TYPE_8)) {
+        newsh = s_realloc(sh, oldhdrlen+size+1);
+        if (newsh == NULL) return NULL;
+        s = (char*)newsh+oldhdrlen;
+    } else {
+        newsh = s_malloc(hdrlen+size+1);
+        if (newsh == NULL) return NULL;
+        memcpy((char*)newsh+hdrlen, s, len);
+        s_free(sh);
+        s = (char*)newsh+hdrlen;
+        s[-1] = type;
+    }
+    s[len] = 0;
+    sdssetlen(s, len);
+    sdssetalloc(s, size);
+    return s;
+}
+
 /* Return the total size of the allocation of the specified sds string,
  * including:
  * 1) The sds header before the pointer.
  * 2) The string.
  * 3) The free buffer at the end if any.
  * 4) The implicit null term.
  */
[FUNC] **new** commit eeb0f1426c3a32c4278136bbbf24118c787f8714
Date:   Sun Apr 10 10:43:59 2022 +0200

    Add RM_TryAlloc (#10541)
    
    Similarly to LCS, some modules would want to try to allocate memory, and
    fail gracefully if the allocation fails

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -468,4 +469,6 @@
 void *RM_Alloc(size_t bytes) {
     return zmalloc(bytes);
 }
 
+/* Similar to RM_Alloc, but returns NULL in case of allocation failure, instead
+ * of panicking. */
[FUNC] **new** commit bda9d74dad15fbc99a84a4f86c5a3cfc9252548f
Date:   Wed Mar 30 05:47:06 2022 -0700

    Module Configurations (#10285)
    
    This feature adds the ability to add four different types (Bool, Numeric,
    String, Enum) of configurations to a module to be accessed via the redis
    config file, and the CONFIG command.
    
    **Configuration Names**:
    
    We impose a restriction that a module configuration always starts with the
    module name and contains a '.' followed by the config name. If a module passes
    "config1" as the name to a register function, it will be registered as MODULENAME.config1.
    
    **Configuration Persistence**:
    
    Module Configurations exist only as long as a module is loaded. If a module is
    unloaded, the configurations are removed.
    There is now also a minimal core API for removal of standardConfig objects
    from configs by name.
    
    **Get and Set Callbacks**:
    
    Storage of config values is owned by the module that registers them, and provides
    callbacks for Redis to access and manipulate the values.
    This is exposed through a GET and SET callback.
    
    The get callback returns a typed value of the config to redis. The callback takes
    the name of the configuration, and also a privdata pointer. Note that these only
    take the CONFIGNAME portion of the config, not the entire MODULENAME.CONFIGNAME.
    
    ```
     typedef RedisModuleString * (*RedisModuleConfigGetStringFunc)(const char *name, void *privdata);
     typedef long long (*RedisModuleConfigGetNumericFunc)(const char *name, void *privdata);
     typedef int (*RedisModuleConfigGetBoolFunc)(const char *name, void *privdata);
     typedef int (*RedisModuleConfigGetEnumFunc)(const char *name, void *privdata);
    ```
    
    Configs must also must specify a set callback, i.e. what to do on a CONFIG SET XYZ 123
    or when loading configurations from cli/.conf file matching these typedefs. *name* is
    again just the CONFIGNAME portion, *val* is the parsed value from the core,
    *privdata* is the registration time privdata pointer, and *err* is for providing errors to a client.
    
    ```
    typedef int (*RedisModuleConfigSetStringFunc)(const char *name, RedisModuleString *val, void *privdata, RedisModuleString **err);
    typedef int (*RedisModuleConfigSetNumericFunc)(const char *name, long long val, void *privdata, RedisModuleString **err);
    typedef int (*RedisModuleConfigSetBoolFunc)(const char *name, int val, void *privdata, RedisModuleString **err);
    typedef int (*RedisModuleConfigSetEnumFunc)(const char *name, int val, void *privdata, RedisModuleString **err);
    ```
    
    Modules can also specify an optional apply callback that will be called after
    value(s) have been set via CONFIG SET:
    
    ```
    typedef int (*RedisModuleConfigApplyFunc)(RedisModuleCtx *ctx, void *privdata, RedisModuleString **err);
    ```
    
    **Flags:**
    We expose 7 new flags to the module, which are used as part of the config registration.
    
    ```
    #define REDISMODULE_CONFIG_MODIFIABLE 0 /* This is the default for a module config. */
    #define REDISMODULE_CONFIG_IMMUTABLE (1ULL<<0) /* Can this value only be set at startup? */
    #define REDISMODULE_CONFIG_SENSITIVE (1ULL<<1) /* Does this value contain sensitive information */
    #define REDISMODULE_CONFIG_HIDDEN (1ULL<<4) /* This config is hidden in `config get <pattern>` (used for tests/debugging) */
    #define REDISMODULE_CONFIG_PROTECTED (1ULL<<5) /* Becomes immutable if enable-protected-configs is enabled. */
    #define REDISMODULE_CONFIG_DENY_LOADING (1ULL<<6) /* This config is forbidden during loading. */
    /* Numeric Specific Configs */
    #define REDISMODULE_CONFIG_MEMORY (1ULL<<7) /* Indicates if this value can be set as a memory value */
    ```
    
    **Module Registration APIs**:
    
    ```
    int (*RedisModule_RegisterBoolConfig)(RedisModuleCtx *ctx, char *name, int default_val, unsigned int flags, RedisModuleConfigGetBoolFunc getfn, RedisModuleConfigSetBoolFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata);
    int (*RedisModule_RegisterNumericConfig)(RedisModuleCtx *ctx, const char *name, long long default_val, unsigned int flags, long long min, long long max, RedisModuleConfigGetNumericFunc getfn, RedisModuleConfigSetNumericFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata);
    int (*RedisModule_RegisterStringConfig)(RedisModuleCtx *ctx, const char *name, const char *default_val, unsigned int flags, RedisModuleConfigGetStringFunc getfn, RedisModuleConfigSetStringFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata);
    int (*RedisModule_RegisterEnumConfig)(RedisModuleCtx *ctx, const char *name, int default_val, unsigned int flags, const char **enum_values, const int *int_values, int num_enum_vals, RedisModuleConfigGetEnumFunc getfn, RedisModuleConfigSetEnumFunc setfn, RedisModuleConfigApplyFunc applyfn, void *privdata);
    int (*RedisModule_LoadConfigs)(RedisModuleCtx *ctx);
    ```
    
    The module name will be auto appended along with a "." to the front of the name of the config.
    
    **What RM_Register[...]Config does**:
    
    A RedisModule struct now keeps a list of ModuleConfig objects which look like:
    ```
    typedef struct ModuleConfig {
        sds name; /* Name of config without the module name appended to the front */
        void *privdata; /* Optional data passed into the module config callbacks */
        union get_fn { /* The get callback specificed by the module */
            RedisModuleConfigGetStringFunc get_string;
            RedisModuleConfigGetNumericFunc get_numeric;
            RedisModuleConfigGetBoolFunc get_bool;
            RedisModuleConfigGetEnumFunc get_enum;
        } get_fn;
        union set_fn { /* The set callback specified by the module */
            RedisModuleConfigSetStringFunc set_string;
            RedisModuleConfigSetNumericFunc set_numeric;
            RedisModuleConfigSetBoolFunc set_bool;
            RedisModuleConfigSetEnumFunc set_enum;
        } set_fn;
        RedisModuleConfigApplyFunc apply_fn;
        RedisModule *module;
    } ModuleConfig;
    ```
    It also registers a standardConfig in the configs array, with a pointer to the
    ModuleConfig object associated with it.
    
    **What happens on a CONFIG GET/SET MODULENAME.MODULECONFIG:**
    
    For CONFIG SET, we do the same parsing as is done in config.c and pass that
    as the argument to the module set callback. For CONFIG GET, we call the
    module get callback and return that value to config.c to return to a client.
    
    **CONFIG REWRITE**:
    
    Starting up a server with module configurations in a .conf file but no module load
    directive will fail. The flip side is also true, specifying a module load and a bunch
    of module configurations will load those configurations in using the module defined
    set callbacks on a RM_LoadConfigs call. Configs being rewritten works the same
    way as it does for standard configs, as the module has the ability to specify a
    default value. If a module is unloaded with configurations specified in the .conf file
    those configurations will be commented out from the .conf file on the next config rewrite.
    
    **RM_LoadConfigs:**
    
    `RedisModule_LoadConfigs(RedisModuleCtx *ctx);`
    
    This last API is used to make configs available within the onLoad() after they have
    been registered. The expected usage is that a module will register all of its configs,
    then call LoadConfigs to trigger all of the set callbacks, and then can error out if any
    of them were malformed. LoadConfigs will attempt to set all configs registered to
    either a .conf file argument/loadex argument or their default value if an argument is
    not specified. **LoadConfigs is a required function if configs are registered.
    ** Also note that LoadConfigs **does not** call the apply callbacks, but a module
    can do that directly after the LoadConfigs call.
    
    **New Command: MODULE LOADEX [CONFIG NAME VALUE] [ARGS ...]:**
    
    This command provides the ability to provide startup context information to a module.
    LOADEX stands for "load extended" similar to GETEX. Note that provided config
    names need the full MODULENAME.MODULECONFIG name. Any additional
    arguments a module might want are intended to be specified after ARGS.
    Everything after ARGS is passed to onLoad as RedisModuleString **argv.
    
    Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>
    Co-authored-by: Madelyn Olson <matolson@amazon.com>
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Madelyn Olson <34459052+madolson@users.noreply.github.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>
    Co-authored-by: Yossi Gottlieb <yossigo@gmail.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -1944,27 +1988,31 @@
 void RM_SetModuleAttribs(RedisModuleCtx *ctx, const char *name, int ver, int apiver) {
     /* Called by RM_Init() to setup the `ctx->module` structure.
      *
      * This is an internal function, Redis modules developers don't need
      * to use it. */
     RedisModule *module;
 
     if (ctx->module != NULL) return;
     module = zmalloc(sizeof(*module));
     module->name = sdsnew(name);
     module->ver = ver;
     module->apiver = apiver;
     module->types = listCreate();
     module->usedby = listCreate();
     module->using = listCreate();
     module->filters = listCreate();
+    module->module_configs = listCreate();
+    listSetMatchMethod(module->module_configs, moduleListConfigMatch);
+    listSetFreeMethod(module->module_configs, moduleListFree);
     module->in_call = 0;
+    module->configs_initialized = 0;
     module->in_hook = 0;
     module->options = 0;
     module->info_cb = 0;
     module->defrag_cb = 0;
     module->loadmod = NULL;
     ctx->module = module;
 }
 
 /* Return non-zero if the module name is busy.
  * Otherwise zero is returned. */


[NA] **new** commit d7920ff9b16b1b3cec5838581d8499d0d50dc935
Date:   Tue Apr 13 23:58:05 2021 +0200

    Modules API docs: Sections and links (#8442)
    
    * Modules API docs: Link API function names to their definitions
    
    Occurrences of API functions are linked to their definition.
    
    A function index with links to all functions is added on the bottom
    of the page.
    
    Comment blocks in module.c starting with a markdown h2 heading are
    used as sections. A table of contents is generated from these
    headings.
    
    The functions names are changed from h2 to h3, since they are now
    rendered as sub-headings within each section.
    
    Existing sections in module.c are used with some minor changes.
    Some documentation text is added or sligtly modified.
    
    The markdown renderer will add IDs which may clash with our
    generated IDs. By prefixing section IDs with "section-" we make
    them different.
    
    Replace double dashes with a unicode long ndash

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -894,22 +929,26 @@
 void RM_SetModuleAttribs(RedisModuleCtx *ctx, const char *name, int ver, int apiver) {
+    /* Called by RM_Init() to setup the `ctx->module` structure.
+     *
+     * This is an internal function, Redis modules developers don't need
+     * to use it. */
     RedisModule *module;
 
     if (ctx->module != NULL) return;
     module = zmalloc(sizeof(*module));
     module->name = sdsnew((char*)name);
     module->ver = ver;
     module->apiver = apiver;
     module->types = listCreate();
     module->usedby = listCreate();
     module->using = listCreate();
     module->filters = listCreate();
     module->in_call = 0;
     module->in_hook = 0;
     module->options = 0;
     module->info_cb = 0;
     module->defrag_cb = 0;
     ctx->module = module;
 }
 
 /* Return non-zero if the module name is busy.
  * Otherwise zero is returned. */
[INCR] **new** commit 02acb8fd3a6ec38cabad8dde520ccf0f359bd6ec
Date:   Tue Jun 21 16:00:24 2022 +0200

    Module API docs corrections (#10890)
    
    * Fix typo `RedisModule_CreatString` -> `RedisModule_CreateString` (multiple occurrences)
    * Make the markdown gen script change all `RM_` to `RedisModule_` even in code examples, etc.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2285,23 +2285,23 @@
 RedisModuleString *RM_CreateStringPrintf(RedisModuleCtx *ctx, const char *fmt, ...) {
     sds s = sdsempty();
 
     va_list ap;
     va_start(ap, fmt);
     s = sdscatvprintf(s, fmt, ap);
     va_end(ap);
 
     RedisModuleString *o = createObject(OBJ_STRING, s);
     if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_STRING,o);
 
     return o;
 }
 
 
-/* Like RedisModule_CreatString(), but creates a string starting from a `long long`
+/* Like RedisModule_CreateString(), but creates a string starting from a `long long`
  * integer instead of taking a buffer and its length.
  *
  * The returned string must be released with RedisModule_FreeString() or by
  * enabling automatic memory management.
  *
  * The passed context 'ctx' may be NULL if necessary, see the
  * RedisModule_CreateString() documentation for more info. */

[INCR] **new** commit 247e792bde45ab36cbbaecad5c7f9d5660bbff01
Date:   Fri Jun 3 18:36:35 2022 -0400

    some minor spelling/grammatical fixes to module.c (#10812)

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2291,23 +2291,23 @@
 RedisModuleString *RM_CreateStringPrintf(RedisModuleCtx *ctx, const char *fmt, ...) {
     sds s = sdsempty();
 
     va_list ap;
     va_start(ap, fmt);
     s = sdscatvprintf(s, fmt, ap);
     va_end(ap);
 
     RedisModuleString *o = createObject(OBJ_STRING, s);
     if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_STRING,o);
 
     return o;
 }
 
 
-/* Like RedisModule_CreatString(), but creates a string starting from a long long
+/* Like RedisModule_CreatString(), but creates a string starting from a `long long`
  * integer instead of taking a buffer and its length.
  *
  * The returned string must be released with RedisModule_FreeString() or by
  * enabling automatic memory management.
  *
  * The passed context 'ctx' may be NULL if necessary, see the
  * RedisModule_CreateString() documentation for more info. */
[FUNC] **new** commit 2854637385f6f44661ebd8833d852c068039e641
Date:   Sun Jun 26 20:02:52 2022 +0800

    Support conversion between `RedisModuleString` and `unsigned long long` (#10889)
    
    Since the ranges of `unsigned long long` and `long long` are different, we cannot read an
    `unsigned long long` integer from a `RedisModuleString` by `RedisModule_StringToLongLong` .
    
    So I added two new Redis Module APIs to support the conversion between these two types:
    * `RedisModule_StringToULongLong`
    * `RedisModule_CreateStringFromULongLong`
    
    Signed-off-by: RinChanNOWWW <hzy427@gmail.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2308,6 +2308,14 @@
 RedisModuleString *RM_CreateStringFromLongLong(RedisModuleCtx *ctx, long long ll) {
     char buf[LONG_STR_SIZE];
     size_t len = ll2string(buf,sizeof(buf),ll);
     return RM_CreateString(ctx,buf,len);
 }
 
+/* Like RedisModule_CreateString(), but creates a string starting from a `unsigned long long`
+ * integer instead of taking a buffer and its length.
+ *
+ * The returned string must be released with RedisModule_FreeString() or by
+ * enabling automatic memory management.
+ *
+ * The passed context 'ctx' may be NULL if necessary, see the
+ * RedisModule_CreateString() documentation for more info. */
commit 02acb8fd3a6ec38cabad8dde520ccf0f359bd6ec
Date:   Tue Jun 21 16:00:24 2022 +0200

    Module API docs corrections (#10890)
    
    * Fix typo `RedisModule_CreatString` -> `RedisModule_CreateString` (multiple occurrences)
    * Make the markdown gen script change all `RM_` to `RedisModule_` even in code examples, etc.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2319,14 +2319,14 @@
 RedisModuleString *RM_CreateStringFromDouble(RedisModuleCtx *ctx, double d) {
     char buf[MAX_D2STRING_CHARS];
     size_t len = d2string(buf,sizeof(buf),d);
     return RM_CreateString(ctx,buf,len);
 }
 
-/* Like RedisModule_CreatString(), but creates a string starting from a long
+/* Like RedisModule_CreateString(), but creates a string starting from a long
  * double.
  *
  * The returned string must be released with RedisModule_FreeString() or by
  * enabling automatic memory management.
  *
  * The passed context 'ctx' may be NULL if necessary, see the
  * RedisModule_CreateString() documentation for more info. */

[FUNC] **new** commit 14b198868fd8f8c7cbd319bec369fbc3fb24aff6
Date:   Mon Mar 28 18:35:56 2022 +0300

    introduce MAX_D2STRING_CHARS instead of 128 const (#10487)
    
    There are a few places that use a hard coded const of 128 to allocate a buffer for d2string.
    Replace these with a clear macro.
    Note that In theory, converting double into string could take as much as nearly 400 chars,
    but since d2string uses `%g` and not `%f`, it won't pass some 40 chars.
    
    unrelated:
    restore some changes to auto generated commands.c that got accidentally reverted in #10293

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2258,14 +2258,14 @@
 RedisModuleString *RM_CreateStringFromDouble(RedisModuleCtx *ctx, double d) {
-    char buf[128];
+    char buf[MAX_D2STRING_CHARS];
     size_t len = d2string(buf,sizeof(buf),d);
     return RM_CreateString(ctx,buf,len);
 }
 
 /* Like RedisModule_CreatString(), but creates a string starting from a long
  * double.
  *
  * The returned string must be released with RedisModule_FreeString() or by
  * enabling automatic memory management.
  *
  * The passed context 'ctx' may be NULL if necessary, see the
  * RedisModule_CreateString() documentation for more info. */
commit 02acb8fd3a6ec38cabad8dde520ccf0f359bd6ec
Date:   Tue Jun 21 16:00:24 2022 +0200

    Module API docs corrections (#10890)
    
    * Fix typo `RedisModule_CreatString` -> `RedisModule_CreateString` (multiple occurrences)
    * Make the markdown gen script change all `RM_` to `RedisModule_` even in code examples, etc.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -2333,15 +2333,15 @@
 RedisModuleString *RM_CreateStringFromLongDouble(RedisModuleCtx *ctx, long double ld, int humanfriendly) {
     char buf[MAX_LONG_DOUBLE_CHARS];
     size_t len = ld2string(buf,sizeof(buf),ld,
         (humanfriendly ? LD_STR_HUMAN : LD_STR_AUTO));
     return RM_CreateString(ctx,buf,len);
 }
 
-/* Like RedisModule_CreatString(), but creates a string starting from another
+/* Like RedisModule_CreateString(), but creates a string starting from another
  * RedisModuleString.
  *
  * The returned string must be released with RedisModule_FreeString() or by
  * enabling automatic memory management.
  *
  * The passed context 'ctx' may be NULL if necessary, see the
  * RedisModule_CreateString() documentation for more info. */
[FUNC] **new** commit 2e1bc942aa00a76ed3b0e5e2678da4ac90071d19
Date:   Tue Feb 8 06:14:42 2022 -0500

    Make INFO command variadic  (#6891)
    
    This is an enhancement for INFO command, previously INFO only support one argument
    for different info section , if user want to get more categories information, either perform
    INFO all / default or calling INFO for multiple times.
    
    **Description of the feature**
    
    The goal of adding this feature is to let the user retrieve multiple categories via the INFO
    command, and still avoid emitting the same section twice.
    
    A use case for this is like Redis Sentinel, which periodically calling INFO command to refresh
    info from monitored Master/Slaves, only Server and Replication part categories are used for
    parsing information. If the INFO command can return just enough categories that client side
    needs, it can save a lot of time for client side parsing it as well as network bandwidth.
    
    **Implementation**
    To share code between redis, sentinel, and other users of INFO (DEBUG and modules),
    we have a new `genInfoSectionDict` function that returns a dict and some boolean flags
    (e.g. `all`) to the caller (built from user input).
    Sentinel is later purging unwanted sections from that, and then it is forwarded to the info `genRedisInfoString`.
    
    **Usage Examples**
    INFO Server Replication
    INFO CPU Memory
    INFO default commandstats
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -8971,26 +8972,32 @@
 RedisModuleServerInfoData *RM_GetServerInfo(RedisModuleCtx *ctx, const char *section) {
     struct RedisModuleServerInfoData *d = zmalloc(sizeof(*d));
     d->rax = raxNew();
     if (ctx != NULL) autoMemoryAdd(ctx,REDISMODULE_AM_INFO,d);
-    sds info = genRedisInfoString(section);
+    int all = 0, everything = 0;
+    robj *argv[1];
+    argv[0] = section ? createStringObject(section, strlen(section)) : NULL;
+    dict *section_dict = genInfoSectionDict(argv, section ? 1 : 0, NULL, &all, &everything);
+    sds info = genRedisInfoString(section_dict, all, everything);
     int totlines, i;
     sds *lines = sdssplitlen(info, sdslen(info), "\r\n", 2, &totlines);
     for(i=0; i<totlines; i++) {
         sds line = lines[i];
         if (line[0]=='#') continue;
         char *sep = strchr(line, ':');
         if (!sep) continue;
         unsigned char *key = (unsigned char*)line;
         size_t keylen = (intptr_t)sep-(intptr_t)line;
         sds val = sdsnewlen(sep+1,sdslen(line)-((intptr_t)sep-(intptr_t)line)-1);
         if (!raxTryInsert(d->rax,key,keylen,val,NULL))
             sdsfree(val);
     }
     sdsfree(info);
     sdsfreesplitres(lines,totlines);
+    releaseInfoSectionDict(section_dict);
+    if(argv[0]) decrRefCount(argv[0]);
     return d;
 }
 
 /* Free data created with RM_GetServerInfo(). You need to pass the
  * context pointer 'ctx' only if the dictionary was created using the
  * context instead of passing NULL. */
[PERF] **new** commit 6790d848c5cf76ad5833d155fc4debc50b9ef2c4
Date:   Tue Jan 11 20:00:56 2022 +0300

    Reuse temporary client objects for blocked clients by module (#9940)
    
    Added a pool for temporary client objects to reuse in module operations.
    By reusing temporary clients, we are avoiding expensive createClient()/freeClient()
    calls and improving performance of RM_BlockClient() and  RM_GetThreadSafeContext() calls.
    
    This commit contains two optimizations:
    
    1 - RM_BlockClient() and RM_GetThreadSafeContext() calls create temporary clients and they are freed in
    RM_UnblockClient() and RM_FreeThreadSafeContext() calls respectively. Creating/destroying client object
    takes quite time. To avoid that, added a pool of temporary clients. Pool expands when more clients are needed.
    Also, added a cron function to shrink the pool and free unused clients after some time. Pool starts with zero
    clients in it. It does not have max size and can grow unbounded as we need it. We will keep minimum of 8
    temporary clients in the pool once created. Keeping small amount of clients to avoid client allocation costs
    if temporary clients are required after some idle period.
    
    2 - After unblocking a client (RM_UnblockClient()), one byte is written to pipe to wake up Redis main thread.
    If there are many clients that will be unblocked, each operation requires one write() call which is quite expensive.
    Changed code to avoid subsequent calls if possible.
    
    There are a few more places that need temporary client objects (e.g RM_Call()). These are now using the same
    temporary client pool to make things more centralized.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -6649,8 +6691,10 @@
 RedisModuleCtx *RM_GetDetachedThreadSafeContext(RedisModuleCtx *ctx) {
     RedisModuleCtx *new_ctx = zmalloc(sizeof(*new_ctx));
-    moduleCreateContext(new_ctx, ctx->module, REDISMODULE_CTX_THREAD_SAFE);
-    new_ctx->client = createClient(NULL);
+    /* We create a new client object for the detached context.
+     * See RM_GetThreadSafeContext() for more information */
+    moduleCreateContext(new_ctx, ctx->module,
+                        REDISMODULE_CTX_THREAD_SAFE|REDISMODULE_CTX_NEW_CLIENT);
     return new_ctx;
 }
 
 /* Release a thread safe context. */

[FUNC] **new** commit 7ac213079cd9afc49f87f08362155aa447c95c4f
Date:   Wed Dec 22 23:03:48 2021 +0100

    Sort out mess around propagation and MULTI/EXEC (#9890)
    
    The mess:
    Some parts use alsoPropagate for late propagation, others using an immediate one (propagate()),
    causing edge cases, ugly/hacky code, and the tendency for bugs
    
    The basic idea is that all commands are propagated via alsoPropagate (i.e. added to a list) and the
    top-most call() is responsible for going over that list and actually propagating them (and wrapping
    them in MULTI/EXEC if there's more than one command). This is done in the new function,
    propagatePendingCommands.
    
    Callers to propagatePendingCommands:
    1. top-most call() (we want all nested call()s to add to the also_propagate array and just the top-most
       one to propagate them) - via `afterCommand`
    2. handleClientsBlockedOnKeys: it is out of call() context and it may propagate stuff - via `afterCommand`.
    3. handleClientsBlockedOnKeys edge case: if the looked-up key is already expired, we will propagate the
       expire but will not unblock any client so `afterCommand` isn't called. in that case, we have to propagate
       the deletion explicitly.
    4. cron stuff: active-expire and eviction may also propagate stuff
    5. modules: the module API allows to propagate stuff from just about anywhere (timers, keyspace notifications,
       threads). I could have tried to catch all the out-of-call-context places but it seemed easier to handle it in one
       place: when we free the context. in the spirit of what was done in call(), only the top-most freeing of a module
       context may cause propagation.
    6. modules: when using a thread-safe ctx it's not clear when/if the ctx will be freed. we do know that the module
       must lock the GIL before calling RM_Replicate/RM_Call so we propagate the pending commands when
       releasing the GIL.
    
    A "known limitation", which were actually a bug, was fixed because of this commit (see propagate.tcl):
       When using a mix of RM_Call with `!` and RM_Replicate, the command would propagate out-of-order:
       first all the commands from RM_Call, and then the ones from RM_Replicate
    
    Another thing worth mentioning is that if, in the past, a client would issue a MULTI/EXEC with just one
    write command the server would blindly propagate the MULTI/EXEC too, even though it's redundant.
    not anymore.
    
    This commit renames propagate() to propagateNow() in order to cause conflicts in pending PRs.
    propagatePendingCommands is the only caller of propagateNow, which is now a static, internal helper function.
    
    Optimizations:
    1. alsoPropagate will not add stuff to also_propagate if there's no AOF and replicas
    2. alsoPropagate reallocs also_propagagte exponentially, to save calls to memmove
    
    Bugfixes:
    1. CONFIG SET can create evictions, sending notifications which can cause to dirty++ with modules.
       we need to prevent it from propagating to AOF/replicas
    2. We need to set current_client in RM_Call. buggy scenario:
       - CONFIG SET maxmemory, eviction notifications, module hook calls RM_Call
       - assertion in lookupKey crashes, because current_client has CONFIG SET, which isn't CMD_WRITE
    3. minor: in eviction, call propagateDeletion after notification, like active-expire and all commands
       (we always send a notification before propagating the command)

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -6724,11 +6646,8 @@
 RedisModuleCtx *RM_GetDetachedThreadSafeContext(RedisModuleCtx *ctx) {
     RedisModuleCtx *new_ctx = zmalloc(sizeof(*new_ctx));
-    RedisModuleCtx empty = REDISMODULE_CTX_INIT;
-    memcpy(new_ctx,&empty,sizeof(empty));
-    new_ctx->module = ctx->module;
-    new_ctx->flags |= REDISMODULE_CTX_THREAD_SAFE;
+    moduleCreateContext(new_ctx, ctx->module, REDISMODULE_CTX_THREAD_SAFE);
     new_ctx->client = createClient(NULL);
     return new_ctx;
 }
 
 /* Release a thread safe context. */
[FUNC] **new** commit a56d4533b72db8aa147be090c4c1d2bc548b9408
Date:   Thu Sep 23 08:52:56 2021 +0300

    Adding ACL support for modules (#9309)
    
    This commit introduced a new flag to the RM_Call:
    'C' - Check if the command can be executed according to the ACLs associated with it.
    
    Also, three new API's added to check if a command, key, or channel can be executed or accessed
    by a user, according to the ACLs associated with it.
    - RM_ACLCheckCommandPerm
    - RM_ACLCheckKeyPerm
    - RM_ACLCheckChannelPerm
    
    The user for these API's is a RedisModuleUser object, that for a Module user returned by the RM_CreateModuleUser API, or for a general ACL user can be retrieved by these two new API's:
    - RM_GetCurrentUserName - Retrieve the user name of the client connection behind the current context.
    - RM_GetModuleUserFromUserName - Get a RedisModuleUser from a user name
    
    As a result of getting a RedisModuleUser from name, it can now also access the general ACL users (not just ones created by the module).
    This mean the already existing API RM_SetModuleUserACL(), can be used to change the ACL rules for such users.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -7197,12 +7225,13 @@
 RedisModuleUser *RM_CreateModuleUser(const char *name) {
     RedisModuleUser *new_user = zmalloc(sizeof(RedisModuleUser));
     new_user->user = ACLCreateUnlinkedUser();
+    new_user->free_user = 1;
 
     /* Free the previous temporarily assigned name to assign the new one */
     sdsfree(new_user->user->name);
     new_user->user->name = sdsnew(name);
     return new_user;
 }
 
 /* Frees a given user and disconnects all of the clients that have been
  * authenticated with it. See RM_CreateModuleUser for detailed usage.*/
[NR] **new** commit 8764611c8a28420b8c9827e87169b9c1bd4489c9
Date:   Thu Nov 3 19:19:49 2022 +0800

    Block some specific characters in module command names (#11434)
    
    Today we don't place any specific restrictions on module command names.
    This can cause ambiguous scenarios. For example, someone might name a
    command like "module|feature" which would be incorrectly parsed by the
    ACL system as a subcommand.
    
    In this PR, we will block some chars that we know can mess things up.
    Specifically ones that can appear ok at first and cause problems in some
    cases (we rather surface the issue right away).
    
    There are these characters:
     * ` ` (space) - issues with old inline protocol.
     * `\r`, `\n` (newline) - can mess up the protocol on acl error replies.
     * `|` - sub-commands.
     * `@` - ACL categories
     * `=`, `,` - info and client list fields.
    
    note that we decided to leave `:` out as it's handled by `getSafeInfoString`
    and is more likely to already been used by existing modules.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -1018,91 +1039,96 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, sds declared_name, sds fullname, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
- * convention. The function returns REDISMODULE_ERR if the specified command
- * name is already busy or a set of invalid flags were passed, otherwise
- * REDISMODULE_OK is returned and the new command is registered.
+ * convention.
+ *
+ * The function returns REDISMODULE_ERR in these cases:
+ * - The specified command is already busy.
+ * - The command name contains some chars that are not allowed.
+ * - A set of invalid flags were passed.
+ *
+ * Otherwise REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  *                    Starting from Redis 7.0 this flag has been deprecated.
  *                    Declaring a command as "random" can be done using
  *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensitive data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensitive data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
  * * **"getchannels-api"**: The command implements the interface to return
  *                          the arguments that are channels.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_SetCommandInfo to set key specs using a more advanced scheme. */

[NR] **new** commit 119ec91a5aa9b655d700d911eae68e8a5fa694d4
Date:   Mon Apr 25 22:59:39 2022 +0800

    Fix typos and limit unknown command error message (#10634)
    
    minor cleanup for recent changes.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -1008,91 +1008,91 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, sds declared_name, sds fullname, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  *                    Starting from Redis 7.0 this flag has been deprecated.
  *                    Declaring a command as "random" can be done using
  *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
- *                     the command has sensible data among the arguments.
+ *                     the command has sensitive data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
- *                     the command has sensible data among the arguments.
+ *                     the command has sensitive data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
  * * **"getchannels-api"**: The command implements the interface to return
  *                          the arguments that are channels.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_SetCommandInfo to set key specs using a more advanced scheme. */

[NA] **new** commit 71204f9632591dd6525cf5325ac2c661ba3ad3f0
Date:   Tue Feb 22 01:00:03 2022 -0800

    Implemented module getchannels api and renamed channel keyspec (#10299)
    
    This implements the following main pieces of functionality:
    * Renames key spec "CHANNEL" to be "NOT_KEY", and update the documentation to
      indicate it's for cluster routing and not for any other key related purpose.
    * Add the getchannels-api, so that modules can now define commands that are subject to
      ACL channel permission checks.
    * Add 4 new flags that describe how a module interacts with a command (SUBSCRIBE, PUBLISH,
      UNSUBSCRIBE, and PATTERN). They are all technically composable, however not sure how a
      command could both subscribe and unsubscribe from a command at once, but didn't see
      a reason to add explicit validation there.
    * Add two new module apis RM_ChannelAtPosWithFlags and RM_IsChannelsPositionRequest to
      duplicate the functionality provided by the keys position APIs.
    * The RM_ACLCheckChannelPermissions (only released in 7.0 RC1) was changed to take flags
      rather than a boolean literal.
    * The RM_ACLCheckKeyPermissions (only released in 7.0 RC1) was changed to take flags
      corresponding to keyspecs instead of custom permission flags. These keyspec flags mimic
      the flags for ACLCheckChannelPermissions.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -881,89 +959,91 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, sds declared_name, sds fullname, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  *                    Starting from Redis 7.0 this flag has been deprecated.
  *                    Declaring a command as "random" can be done using
  *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
+ * * **"getchannels-api"**: The command implements the interface to return
+ *                          the arguments that are channels.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_SetCommandInfo to set key specs using a more advanced scheme. */

[NR] **new** commit 0a82fe844765e3c49d4807fcb8562342f88dffaf
Date:   Fri Feb 4 20:09:36 2022 +0100

    Command info module API (#10108)
    
    Adds RM_SetCommandInfo, allowing modules to provide the following command info:
    
    * summary
    * complexity
    * since
    * history
    * hints
    * arity
    * key specs
    * args
    
    This information affects the output of `COMMAND`, `COMMAND INFO` and `COMMAND DOCS`,
    Cluster, ACL and is used to filter commands with the wrong number of arguments before
    the call reaches the module code.
    
    The recently added API functions for key specs (never released) are removed.
    
    A minimalist example would look like so:
    ```c
        RedisModuleCommand *mycmd = RedisModule_GetCommand(ctx,"mymodule.mycommand");
        RedisModuleCommandInfo mycmd_info = {
            .version = REDISMODULE_COMMAND_INFO_VERSION,
            .arity = -5,
            .summary = "some description",
        };
        if (RedisModule_SetCommandInfo(mycmd, &mycmd_info) == REDISMODULE_ERR)
            return REDISMODULE_ERR;
    ````
    
    Notes:
    * All the provided information (including strings) is copied, not keeping references to the API input data.
    * The version field is actually a static struct that contains the sizes of the the structs used in arrays,
      so we can extend these in the future and old version will still be able to take the part they can support.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -880,91 +853,89 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, sds declared_name, sds fullname, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  *                    Starting from Redis 7.0 this flag has been deprecated.
  *                    Declaring a command as "random" can be done using
  *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
- * RedisModule_AddCommandKeySpec (see documentation).
- *
- */
+ * RedisModule_SetCommandInfo to set key specs using a more advanced scheme. */

[NA] **new** commit 23325c135f08365d1b7d4bf4fb1c9187fc7374b9
Date:   Sun Jan 23 16:05:06 2022 +0800

    sub-command support for ACL CAT and COMMAND LIST. redisCommand always stores fullname (#10127)
    
    Summary of changes:
    1. Rename `redisCommand->name` to `redisCommand->declared_name`, it is a
      const char * for native commands and SDS for module commands.
    2. Store the [sub]command fullname in `redisCommand->fullname` (sds).
    3. List subcommands in `ACL CAT`
    4. List subcommands in `COMMAND LIST`
    5. `moduleUnregisterCommands` now will also free the module subcommands.
    6. RM_GetCurrentCommandName returns full command name
    
    Other changes:
    1. Add `addReplyErrorArity` and `addReplyErrorExpireTime`
    2. Remove `getFullCommandName` function that now is useless.
    3. Some cleanups about `fullname` since now it is SDS.
    4. Delete `populateSingleCommand` function from server.h that is useless.
    5. Added tests to cover this change.
    6. Add some module unload tests and fix the leaks
    7. Make error messages uniform, make sure they always contain the full command
      name and that it's quoted.
    7. Fixes some typos
    
    see the history in #9504, fixes #10124
    
    Co-authored-by: Oran Agra <oran@redislabs.com>
    Co-authored-by: guybe7 <guy.benoish@redislabs.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -880,91 +880,91 @@
-RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
+RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, sds declared_name, sds fullname, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  *                    Starting from Redis 7.0 this flag has been deprecated.
  *                    Declaring a command as "random" can be done using
  *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit 10bbeb68377bc2b20442e6578183dbc61fb57ec3
Date:   Thu Jan 20 10:32:11 2022 +0100

    Add command tips to COMMAND DOCS (#10104)
    
    Adding command tips (see https://redis.io/topics/command-tips) to commands.
    
    Breaking changes:
    1. Removed the "random" and "sort_for_script" flags. They are now command tips.
    (this isn't affecting redis behavior since #9812, but could affect some client applications
    that's relying on COMMAND command flags)
    
    Summary of changes:
    1. add BLOCKING flag (new flag) for all commands that could block. The ACL category with
      the same name is now implicit.
    2. move RANDOM flag to a `nondeterministic_output` tip
    3. move SORT_FOR_SCRIPT flag to `nondeterministic_output_order` tip
    3. add REQUEST_POLICY and RESPONSE_POLICY where appropriate as documented in the tips
    4. deprecate (ignore) the `random` flag for RM_CreateCommand
    
    Other notes:
    1. Proxies need to send `RANDOMKEY` to all shards and then select one key randomly.
      The other option is to pick a random shard and transfer `RANDOMKEY `to it, but that scheme
      fails if this specific shard is empty
    2. Remove CMD_RANDOM from `XACK` (i.e. XACK does not have RANDOM_OUTPUT)
       It was added in 9e4fb96ca12476b1c7468b143efca86b478bfb4a, I guess by mistake.
       Also from `(P)EXPIRETIME` (new command, was flagged "random" by mistake).
    3. Add `nondeterministic_output` to `OBJECT ENCODING` (for the same reason `XTRIM` has it:
       the reply may differ depending on the internal representation in memory)
    4. RANDOM on `HGETALL` was wrong (there due to a limitation of the old script sorting logic), now
      it's `nondeterministic_output_order`
    5. Unrelated: Hide CMD_PROTECTED from COMMAND

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -879,87 +880,91 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
+ *                    Starting from Redis 7.0 this flag has been deprecated.
+ *                    Declaring a command as "random" can be done using
+ *                    command tips, see https://redis.io/topics/command-tips.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
+ * * **"blocking"**: The command has the potential to block the client.
  * * **"allow-busy"**: Permit the command while the server is blocked either by
  *                     a script or by a slow module command, see
  *                     RM_Yield.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit c4b788230ca034761a0e9f6ca35b4aee4b15d340
Date:   Thu Jan 20 09:05:53 2022 +0200

    Adding module api for processing commands during busy jobs and allow flagging the commands that should be handled at this status (#9963)
    
    Some modules might perform a long-running logic in different stages of Redis lifetime, for example:
    * command execution
    * RDB loading
    * thread safe context
    
    During this long-running logic Redis is not responsive.
    
    This PR offers
    1. An API to process events while a busy command is running (`RM_Yield`)
    2. A new flag (`ALLOW_BUSY`) to mark the commands that should be handled during busy
      jobs which can also be used by modules (`allow-busy`)
    3. In slow commands and thread safe contexts, this flag will start rejecting commands with -BUSY only
      after `busy-reply-threshold`
    4. During loading (`rdb_load` callback), it'll process events right away (not wait for `busy-reply-threshold`),
      but either way, the processing is throttled to the server hz rate.
    5. Allow modules to Yield to redis background tasks, but not to client commands
    
    * rename `script-time-limit` to `busy-reply-threshold` (an alias to the pre-7.0 `lua-time-limit`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -858,84 +879,87 @@
 RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
+ * * **"allow-busy"**: Permit the command while the server is blocked either by
+ *                     a script or by a slow module command, see
+ *                     RM_Yield.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit 867816003ec214840c18754be9840f1ddf4192d1
Date:   Wed Dec 15 20:23:15 2021 +0100

    Auto-generate the command table from JSON files (#9656)
    
    Delete the hardcoded command table and replace it with an auto-generated table, based
    on a JSON file that describes the commands (each command must have a JSON file).
    
    These JSON files are the SSOT of everything there is to know about Redis commands,
    and it is reflected fully in COMMAND INFO.
    
    These JSON files are used to generate commands.c (using a python script), which is then
    committed to the repo and compiled.
    
    The purpose is:
    * Clients and proxies will be able to get much more info from redis, instead of relying on hard coded logic.
    * drop the dependency between Redis-user and the commands.json in redis-doc.
    * delete help.h and have redis-cli learn everything it needs to know just by issuing COMMAND (will be
      done in a separate PR)
    * redis.io should stop using commands.json and learn everything from Redis (ultimately one of the release
      artifacts should be a large JSON, containing all the information about all of the commands, which will be
      generated from COMMAND's reply)
    * the byproduct of this is:
      * module commands will be able to provide that info and possibly be more of a first-class citizens
      * in theory, one may be able to generate a redis client library for a strictly typed language, by using this info.
    
    ### Interface changes
    
    #### COMMAND INFO's reply change (and arg-less COMMAND)
    
    Before this commit the reply at index 7 contained the key-specs list
    and reply at index 8 contained the sub-commands list (Both unreleased).
    Now, reply at index 7 is a map of:
    - summary - short command description
    - since - debut version
    - group - command group
    - complexity - complexity string
    - doc-flags - flags used for documentation (e.g. "deprecated")
    - deprecated-since - if deprecated, from which version?
    - replaced-by - if deprecated, which command replaced it?
    - history - a list of (version, what-changed) tuples
    - hints - a list of strings, meant to provide hints for clients/proxies. see https://github.com/redis/redis/issues/9876
    - arguments - an array of arguments. each element is a map, with the possibility of nesting (sub-arguments)
    - key-specs - an array of keys specs (already in unstable, just changed location)
    - subcommands - a list of sub-commands (already in unstable, just changed location)
    - reply-schema - will be added in the future (see https://github.com/redis/redis/issues/9845)
    
    more details on these can be found in https://github.com/redis/redis-doc/pull/1697
    
    only the first three fields are mandatory
    
    #### API changes (unreleased API obviously)
    
    now they take RedisModuleCommand opaque pointer instead of looking up the command by name
    
    - RM_CreateSubcommand
    - RM_AddCommandKeySpec
    - RM_SetCommandKeySpecBeginSearchIndex
    - RM_SetCommandKeySpecBeginSearchKeyword
    - RM_SetCommandKeySpecFindKeysRange
    - RM_SetCommandKeySpecFindKeysKeynum
    
    Currently, we did not add module API to provide additional information about their commands because
    we couldn't agree on how the API should look like, see https://github.com/redis/redis/issues/9944.
    
    ### Somehow related changes
    1. Literals should be in uppercase while placeholder in lowercase. Now all the GEO* command
       will be documented with M|KM|FT|MI and can take both lowercase and uppercase
    
    ### Unrelated changes
    1. Bugfix: no_madaory_keys was absent in COMMAND's reply
    2. expose CMD_MODULE as "module" via COMMAND
    3. have a dedicated uint64 for ACL categories (instead of having them in the same uint64 as command flags)
    
    Co-authored-by: Itamar Haber <itamar@garantiadata.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -834,84 +834,84 @@
-RedisModuleCommandProxy *moduleCreateCommandProxy(RedisModuleCtx *ctx, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
+RedisModuleCommand *moduleCreateCommandProxy(struct RedisModule *module, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
  * * **"no-mandatory-keys"**: All the keys this command may take are optional
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
- * * 'firstkey': One-based index of the first argument that's a key.
+ * * `firstkey`: One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
- * * 'lastkey':  One-based index of the last argument that's a key.
+ * * `lastkey`:  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
- * * 'keystep':  Step between first and last key indexes.
+ * * `keystep`:  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
- * This information is used by ACL, Cluster and the 'COMMAND' command.
+ * This information is used by ACL, Cluster and the `COMMAND` command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit f11a2d4dd764c996b2d0c0cb5abde13f2445b40c
Date:   Wed Nov 3 13:38:26 2021 +0100

    Fix COMMAND GETKEYS on EVAL without keys (#9733)
    
    Add new no-mandatory-keys flag to support COMMAND GETKEYS of commands
    which have no mandatory keys.
    
    In the past we would have got this error:
    ```
    127.0.0.1:6379> command getkeys eval "return 1" 0
    (error) ERR Invalid arguments specified for command
    ```

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -833,83 +834,84 @@
 RedisModuleCommandProxy *moduleCreateCommandProxy(RedisModuleCtx *ctx, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
 
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.
+ * * **"no-mandatory-keys"**: All the keys this command may take are optional
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * 'firstkey': One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * 'lastkey':  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * 'keystep':  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the 'COMMAND' command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit 43e736f79b7663f6095377506a24f47718056cb7
Date:   Wed Oct 20 10:52:57 2021 +0200

    Treat subcommands as commands (#9504)
    
    ## Intro
    
    The purpose is to allow having different flags/ACL categories for
    subcommands (Example: CONFIG GET is ok-loading but CONFIG SET isn't)
    
    We create a small command table for every command that has subcommands
    and each subcommand has its own flags, etc. (same as a "regular" command)
    
    This commit also unites the Redis and the Sentinel command tables
    
    ## Affected commands
    
    CONFIG
    Used to have "admin ok-loading ok-stale no-script"
    Changes:
    1. Dropped "ok-loading" in all except GET (this doesn't change behavior since
    there were checks in the code doing that)
    
    XINFO
    Used to have "read-only random"
    Changes:
    1. Dropped "random" in all except CONSUMERS
    
    XGROUP
    Used to have "write use-memory"
    Changes:
    1. Dropped "use-memory" in all except CREATE and CREATECONSUMER
    
    COMMAND
    No changes.
    
    MEMORY
    Used to have "random read-only"
    Changes:
    1. Dropped "random" in PURGE and USAGE
    
    ACL
    Used to have "admin no-script ok-loading ok-stale"
    Changes:
    1. Dropped "admin" in WHOAMI, GENPASS, and CAT
    
    LATENCY
    No changes.
    
    MODULE
    No changes.
    
    SLOWLOG
    Used to have "admin random ok-loading ok-stale"
    Changes:
    1. Dropped "random" in RESET
    
    OBJECT
    Used to have "read-only random"
    Changes:
    1. Dropped "random" in ENCODING and REFCOUNT
    
    SCRIPT
    Used to have "may-replicate no-script"
    Changes:
    1. Dropped "may-replicate" in all except FLUSH and LOAD
    
    CLIENT
    Used to have "admin no-script random ok-loading ok-stale"
    Changes:
    1. Dropped "random" in all except INFO and LIST
    2. Dropped "admin" in ID, TRACKING, CACHING, GETREDIR, INFO, SETNAME, GETNAME, and REPLY
    
    STRALGO
    No changes.
    
    PUBSUB
    No changes.
    
    CLUSTER
    Changes:
    1. Dropped "admin in countkeysinslots, getkeysinslot, info, nodes, keyslot, myid, and slots
    
    SENTINEL
    No changes.
    
    (note that DEBUG also fits, but we decided not to convert it since it's for
    debugging and anyway undocumented)
    
    ## New sub-command
    This commit adds another element to the per-command output of COMMAND,
    describing the list of subcommands, if any (in the same structure as "regular" commands)
    Also, it adds a new subcommand:
    ```
    COMMAND LIST [FILTERBY (MODULE <module-name>|ACLCAT <cat>|PATTERN <pattern>)]
    ```
    which returns a set of all commands (unless filters), but excluding subcommands.
    
    ## Module API
    A new module API, RM_CreateSubcommand, was added, in order to allow
    module writer to define subcommands
    
    ## ACL changes:
    1. Now, that each subcommand is actually a command, each has its own ACL id.
    2. The old mechanism of allowed_subcommands is redundant
    (blocking/allowing a subcommand is the same as blocking/allowing a regular command),
    but we had to keep it, to support the widespread usage of allowed_subcommands
    to block commands with certain args, that aren't subcommands (e.g. "-select +select|0").
    3. I have renamed allowed_subcommands to allowed_firstargs to emphasize the difference.
    4. Because subcommands are commands in ACL too, you can now use "-" to block subcommands
    (e.g. "+client -client|kill"), which wasn't possible in the past.
    5. It is also possible to use the allowed_firstargs mechanism with subcommand.
    For example: `+config -config|set +config|set|loglevel` will block all CONFIG SET except
    for setting the log level.
    6. All of the ACL changes above required some amount of refactoring.
    
    ## Misc
    1. There are two approaches: Either each subcommand has its own function or all
       subcommands use the same function, determining what to do according to argv[0].
       For now, I took the former approaches only with CONFIG and COMMAND,
       while other commands use the latter approach (for smaller blamelog diff).
    2. Deleted memoryGetKeys: It is no longer needed because MEMORY USAGE now uses the "range" key spec.
    4. Bugfix: GETNAME was missing from CLIENT's help message.
    5. Sentinel and Redis now use the same table, with the same function pointer.
       Some commands have a different implementation in Sentinel, so we redirect
       them (these are ROLE, PUBLISH, and INFO).
    6. Command stats now show the stats per subcommand (e.g. instead of stats just
       for "config" you will have stats for "config|set", "config|get", etc.)
    7. It is now possible to use COMMAND directly on subcommands:
       COMMAND INFO CONFIG|GET (The pipeline syntax was inspired from ACL, and
       can be used in functions lookupCommandBySds and lookupCommandByCString)
    8. STRALGO is now a container command (has "help")
    
    ## Breaking changes:
    1. Command stats now show the stats per subcommand (see (5) above)

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -833,81 +833,83 @@
+RedisModuleCommandProxy *moduleCreateCommandProxy(RedisModuleCtx *ctx, const char *name, RedisModuleCmdFunc cmdfunc, int64_t flags, int firstkey, int lastkey, int keystep);
+
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
- *                        though it's not a write command.  
+ *                        though it's not a write command.
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * 'firstkey': One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * 'lastkey':  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * 'keystep':  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the 'COMMAND' command.
  *
  * NOTE: The scheme described above serves a limited purpose and can
  * only be used to find keys that exist at constant indices.
  * For non-trivial key arguments, you may pass 0,0,0 and use
  * RedisModule_AddCommandKeySpec (see documentation).
  *
  */

[NA] **new** commit 03fcc211de4cf7874c6eff58da3c6f67626ada5a
Date:   Wed Sep 15 10:10:29 2021 +0200

    A better approach for COMMAND INFO for movablekeys commands (#8324)
    
    Fix #7297
    
    The problem:
    
    Today, there is no way for a client library or app to know the key name indexes for commands such as
    ZUNIONSTORE/EVAL and others with "numkeys", since COMMAND INFO returns no useful info for them.
    
    For cluster-aware redis clients, this requires to 'patch' the client library code specifically for each of these commands or to
    resolve each execution of these commands with COMMAND GETKEYS.
    
    The solution:
    
    Introducing key specs other than the legacy "range" (first,last,step)
    
    The 8th element of the command info array, if exists, holds an array of key specs. The array may be empty, which indicates
    the command doesn't take any key arguments or may contain one or more key-specs, each one may leads to the discovery
    of 0 or more key arguments.
    
    A client library that doesn't support this key-spec feature will keep using the first,last,step and movablekeys flag which will
    obviously remain unchanged.
    
    A client that supports this key-specs feature needs only to look at the key-specs array. If it finds an unrecognized spec, it
    must resort to using COMMAND GETKEYS if it wishes to get all key name arguments, but if all it needs is one key in order
    to know which cluster node to use, then maybe another spec (if the command has several) can supply that, and there's no
    need to use GETKEYS.
    
    Each spec is an array of arguments, first one is the spec name, the second is an array of flags, and the third is an array
    containing details about the spec (specific meaning for each spec type)
    The initial flags we support are "read" and "write" indicating if the keys that this key-spec finds are used for read or for write.
    clients should ignore any unfamiliar flags.
    
    In order to easily find the positions of keys in a given array of args we introduce keys specs. There are two logical steps of
    key specs:
    1. `start_search`: Given an array of args, indicate where we should start searching for keys
    2. `find_keys`: Given the output of start_search and an array of args, indicate all possible indices of keys.
    
    ### start_search step specs
    - `index`: specify an argument index explicitly
      - `index`: 0 based index (1 means the first command argument)
    - `keyword`: specify a string to match in `argv`. We should start searching for keys just after the keyword appears.
      - `keyword`: the string to search for
      - `start_search`: an index from which to start the keyword search (can be negative, which means to search from the end)
    
    Examples:
    - `SET` has start_search of type `index` with value `1`
    - `XREAD` has start_search of type `keyword` with value `[âSTREAMSâ,1]`
    - `MIGRATE` has start_search of type `keyword` with value `[âKEYSâ,-2]`
    
    ### find_keys step specs
    - `range`: specify `[count, step, limit]`.
      - `lastkey`: index of the last key. relative to the index returned from begin_search. -1 indicating till the last argument, -2 one before the last
      - `step`: how many args should we skip after finding a key, in order to find the next one
      - `limit`: if count is -1, we use limit to stop the search by a factor. 0 and 1 mean no limit. 2 means Â½ of the remaining args, 3 means â, and so on.
    - âkeynumâ: specify `[keynum_index, first_key_index, step]`.
      - `keynum_index`: is relative to the return of the `start_search` spec.
      - `first_key_index`: is relative to `keynum_index`.
      - `step`: how many args should we skip after finding a key, in order to find the next one
    
    Examples:
    - `SET` has `range` of `[0,1,0]`
    - `MSET` has `range` of `[-1,2,0]`
    - `XREAD` has `range` of `[-1,1,2]`
    - `ZUNION` has `start_search` of type `index` with value `1` and `find_keys` of type `keynum` with value `[0,1,1]`
    - `AI.DAGRUN` has `start_search` of type `keyword` with value `[âLOADâ,1]` and `find_keys` of type `keynum` with value
      `[0,1,1]` (see https://oss.redislabs.com/redisai/master/commands/#aidagrun)
    
    Note: this solution is not perfect as the module writers can come up with anything, but at least we will be able to find the key
    args of the vast majority of commands.
    If one of the above specs canât describe the key positions, the module writer can always fall back to the `getkeys-api` option.
    
    Some keys cannot be found easily (`KEYS` in `MIGRATE`: Imagine the argument for `AUTH` is the string âKEYSâ - we will
    start searching in the wrong index).
    The guarantee is that the specs may be incomplete (`incomplete` will be specified in the spec to denote that) but we never
    report false information (assuming the command syntax is correct).
    For `MIGRATE` we start searching from the end - `startfrom=-1` - and if one of the keys is actually called "keys" we will
    report only a subset of all keys - hence the `incomplete` flag.
    Some `incomplete` specs can be completely empty (i.e. UNKNOWN begin_search) which should tell the client that
    COMMAND GETKEYS (or any other way to get the keys) must be used (Example: For `SORT` there is no way to describe
    the STORE keyword spec, as the word "store" can appear anywhere in the command).
    
    We will expose these key specs in the `COMMAND` command so that clients can learn, on startup, where the keys are for
    all commands instead of holding hardcoded tables or use `COMMAND GETKEYS` in runtime.
    
    Comments:
    1. Redis doesn't internally use the new specs, they are only used for COMMAND output.
    2. In order to support the current COMMAND INFO format (reply array indices 4, 5, 6) we created a synthetic range, called
       legacy_range, that, if possible, is built according to the new specs.
    3. Redis currently uses only getkeys_proc or the legacy_range to get the keys indices (in COMMAND GETKEYS for
       example).
    
    "incomplete" specs:
    the command we have issues with are MIGRATE, STRALGO, and SORT
    for MIGRATE, because the token KEYS, if exists, must be the last token, we can search in reverse. it one of the keys is
    actually the string "keys" will return just a subset of the keys (hence, it's "incomplete")
    for SORT and STRALGO we can use this heuristic (the keys can be anywhere in the command) and therefore we added a
    key spec that is both "incomplete" and of "unknown type"
    
    if a client encounters an "incomplete" spec it means that it must find a different way (either COMMAND GETKEYS or have
    its own parser) to retrieve the keys.
    please note that all commands, apart from the three mentioned above, have "complete" key specs

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -811,75 +831,81 @@
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.  
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * 'firstkey': One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * 'lastkey':  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * 'keystep':  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the 'COMMAND' command.
+ *
+ * NOTE: The scheme described above serves a limited purpose and can
+ * only be used to find keys that exist at constant indices.
+ * For non-trivial key arguments, you may pass 0,0,0 and use
+ * RedisModule_AddCommandKeySpec (see documentation).
+ *
  */

[NA] **new** commit 0bfccc55e2df349104b34608365dc17db8e0a749
Date:   Thu Jun 10 20:39:33 2021 +0800

    Fixed some typos, add a spell check ci and others minor fix (#8890)
    
    This PR adds a spell checker CI action that will fail future PRs if they introduce typos and spelling mistakes.
    This spell checker is based on blacklist of common spelling mistakes, so it will not catch everything,
    but at least it is also unlikely to cause false positives.
    
    Besides that, the PR also fixes many spelling mistakes and types, not all are a result of the spell checker we use.
    
    Here's a summary of other changes:
    1. Scanned the entire source code and fixes all sorts of typos and spelling mistakes (including missing or extra spaces).
    2. Outdated function / variable / argument names in comments
    3. Fix outdated keyspace masks error log when we check `config.notify-keyspace-events` in loadServerConfigFromString.
    4. Trim the white space at the end of line in `module.c`. Check: https://github.com/redis/redis/pull/7751
    5. Some outdated https link URLs.
    6. Fix some outdated comment. Such as:
        - In README: about the rdb, we used to said create a `thread`, change to `process`
        - dbRandomKey function coment (about the dictGetRandomKey, change to dictGetFairRandomKey)
        - notifyKeyspaceEvent fucntion comment (add type arg)
        - Some others minor fix in comment (Most of them are incorrectly quoted by variable names)
    7. Modified the error log so that users can easily distinguish between TCP and TLS in `changeBindAddr`

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -798,75 +798,75 @@
 /* Register a new command in the Redis server, that will be handled by
  * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
- *                     to authenticate a client. 
+ *                     to authenticate a client.
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.  
  *
  * The last three parameters specify which arguments of the new command are
  * Redis keys. See https://redis.io/commands/command for more information.
  *
  * * 'firstkey': One-based index of the first argument that's a key.
  *               Position 0 is always the command name itself.
  *               0 for commands with no keys.
  * * 'lastkey':  One-based index of the last argument that's a key.
  *               Negative numbers refer to counting backwards from the last
  *               argument (-1 means the last argument provided)
  *               0 for commands with no keys.
  * * 'keystep':  Step between first and last key indexes.
  *               0 for commands with no keys.
  *
  * This information is used by ACL, Cluster and the 'COMMAND' command.
  */

[NA] **new** commit 25d827d949b2388bbdf459ba1b3ff0cb12ac6af6
Date:   Tue May 18 11:19:30 2021 -0300

    Add documentation for `firstkey`, `lastkey` and `keystep` parameters of `RedisModule_CreateCommand` (#8883)
    
    These parameters of RedisModule_CreateCommand were previously
    undocumented but they are needed for ACL to check permission on keys and
    by Redis Cluster to figure our how to route the command.
    
    Co-authored-by: Eduardo Felipe Castegnaro <edufelipe@onsign.tv>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -820,60 +820,75 @@
 /* Register a new command in the Redis server, that will be handled by
- * calling the function pointer 'func' using the RedisModule calling
+ * calling the function pointer 'cmdfunc' using the RedisModule calling
  * convention. The function returns REDISMODULE_ERR if the specified command
  * name is already busy or a set of invalid flags were passed, otherwise
  * REDISMODULE_OK is returned and the new command is registered.
  *
  * This function must be called during the initialization of the module
  * inside the RedisModule_OnLoad() function. Calling this function outside
  * of the initialization function is not defined.
  *
  * The command function type is the following:
  *
  *      int MyCommand_RedisCommand(RedisModuleCtx *ctx, RedisModuleString **argv, int argc);
  *
  * And is supposed to always return REDISMODULE_OK.
  *
  * The set of flags 'strflags' specify the behavior of the command, and should
  * be passed as a C string composed of space separated words, like for
  * example "write deny-oom". The set of flags are:
  *
  * * **"write"**:     The command may modify the data set (it may also read
  *                    from it).
  * * **"readonly"**:  The command returns data from keys but never writes.
  * * **"admin"**:     The command is an administrative command (may change
  *                    replication or perform similar tasks).
  * * **"deny-oom"**:  The command may use additional memory and should be
  *                    denied during out of memory conditions.
  * * **"deny-script"**:   Don't allow this command in Lua scripts.
  * * **"allow-loading"**: Allow this command while the server is loading data.
  *                        Only commands not interacting with the data set
  *                        should be allowed to run in this mode. If not sure
  *                        don't use this flag.
  * * **"pubsub"**:    The command publishes things on Pub/Sub channels.
  * * **"random"**:    The command may have different outputs even starting
  *                    from the same input arguments and key values.
  * * **"allow-stale"**: The command is allowed to run on slaves that don't
  *                      serve stale data. Don't use if you don't know what
  *                      this means.
  * * **"no-monitor"**: Don't propagate the command on monitor. Use this if
  *                     the command has sensible data among the arguments.
  * * **"no-slowlog"**: Don't log this command in the slowlog. Use this if
  *                     the command has sensible data among the arguments.
  * * **"fast"**:      The command time complexity is not greater
  *                    than O(log(N)) where N is the size of the collection or
  *                    anything else representing the normal scalability
  *                    issue with the command.
  * * **"getkeys-api"**: The command implements the interface to return
  *                      the arguments that are keys. Used when start/stop/step
  *                      is not enough because of the command syntax.
  * * **"no-cluster"**: The command should not register in Redis Cluster
  *                     since is not designed to work with it because, for
  *                     example, is unable to report the position of the
  *                     keys, programmatically creates key names, or any
  *                     other reason.
  * * **"no-auth"**:    This command can be run by an un-authenticated client.
  *                     Normally this is used by a command that is used
  *                     to authenticate a client. 
  * * **"may-replicate"**: This command may generate replication traffic, even
  *                        though it's not a write command.  
+ *
+ * The last three parameters specify which arguments of the new command are
+ * Redis keys. See https://redis.io/commands/command for more information.
+ *
+ * * 'firstkey': One-based index of the first argument that's a key.
+ *               Position 0 is always the command name itself.
+ *               0 for commands with no keys.
+ * * 'lastkey':  One-based index of the last argument that's a key.
+ *               Negative numbers refer to counting backwards from the last
+ *               argument (-1 means the last argument provided)
+ *               0 for commands with no keys.
+ * * 'keystep':  Step between first and last key indexes.
+ *               0 for commands with no keys.
+ *
+ * This information is used by ACL, Cluster and the 'COMMAND' command.
  */
[PERF] **new** commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -619,31 +619,29 @@
 int moduleCreateEmptyKey(RedisModuleKey *key, int type) {
     robj *obj;
 
     /* The key must be open for writing and non existing to proceed. */
     if (!(key->mode & REDISMODULE_WRITE) || key->value)
         return REDISMODULE_ERR;
 
     switch(type) {
     case REDISMODULE_KEYTYPE_LIST:
-        obj = createQuicklistObject();
-        quicklistSetOptions(obj->ptr, server.list_max_listpack_size,
-                            server.list_compress_depth);
+        obj = createListListpackObject();
         break;
     case REDISMODULE_KEYTYPE_ZSET:
         obj = createZsetListpackObject();
         break;
     case REDISMODULE_KEYTYPE_HASH:
         obj = createHashObject();
         break;
     case REDISMODULE_KEYTYPE_STREAM:
         obj = createStreamObject();
         break;
     default: return REDISMODULE_ERR;
     }
     dbAdd(key->db,key->key,obj);
     key->value = obj;
     moduleInitKeyTypeSpecific(key);
     return REDISMODULE_OK;
 }
 
 /* Frees key->iter and sets it to NULL. */

[FUNC] **new** commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -519,31 +519,31 @@
 int moduleCreateEmptyKey(RedisModuleKey *key, int type) {
     robj *obj;
 
     /* The key must be open for writing and non existing to proceed. */
     if (!(key->mode & REDISMODULE_WRITE) || key->value)
         return REDISMODULE_ERR;
 
     switch(type) {
     case REDISMODULE_KEYTYPE_LIST:
         obj = createQuicklistObject();
-        quicklistSetOptions(obj->ptr, server.list_max_ziplist_size,
+        quicklistSetOptions(obj->ptr, server.list_max_listpack_size,
                             server.list_compress_depth);
         break;
     case REDISMODULE_KEYTYPE_ZSET:
         obj = createZsetListpackObject();
         break;
     case REDISMODULE_KEYTYPE_HASH:
         obj = createHashObject();
         break;
     case REDISMODULE_KEYTYPE_STREAM:
         obj = createStreamObject();
         break;
     default: return REDISMODULE_ERR;
     }
     dbAdd(key->db,key->key,obj);
     key->value = obj;
     moduleInitKeyTypeSpecific(key);
     return REDISMODULE_OK;
 }
 
 /* Frees key->iter and sets it to NULL. */

[FUNC] **new** commit ea36d4de17101f05b03d267a4afbae0f7b33a27c
Date:   Tue Sep 14 16:48:06 2021 +0200

    Modules: Add remaining list API functions (#8439)
    
    List functions operating on elements by index:
    
    * RM_ListGet
    * RM_ListSet
    * RM_ListInsert
    * RM_ListDelete
    
    Iteration is done using a simple for loop over indices.
    The index based functions use an internal iterator as an optimization.
    This is explained in the docs:
    
    ```
     * Many of the list functions access elements by index. Since a list is in
     * essence a doubly-linked list, accessing elements by index is generally an
     * O(N) operation. However, if elements are accessed sequentially or with
     * indices close together, the functions are optimized to seek the index from
     * the previous index, rather than seeking from the ends of the list.
     *
     * This enables iteration to be done efficiently using a simple for loop:
     *
     *     long n = RM_ValueLength(key);
     *     for (long i = 0; i < n; i++) {
     *         RedisModuleString *elem = RedisModule_ListGet(key, i);
     *         // Do stuff...
     *     }
    ```

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -511,30 +516,31 @@
 int moduleCreateEmptyKey(RedisModuleKey *key, int type) {
     robj *obj;
 
     /* The key must be open for writing and non existing to proceed. */
     if (!(key->mode & REDISMODULE_WRITE) || key->value)
         return REDISMODULE_ERR;
 
     switch(type) {
     case REDISMODULE_KEYTYPE_LIST:
         obj = createQuicklistObject();
         quicklistSetOptions(obj->ptr, server.list_max_ziplist_size,
                             server.list_compress_depth);
         break;
     case REDISMODULE_KEYTYPE_ZSET:
         obj = createZsetListpackObject();
         break;
     case REDISMODULE_KEYTYPE_HASH:
         obj = createHashObject();
         break;
     case REDISMODULE_KEYTYPE_STREAM:
         obj = createStreamObject();
         break;
     default: return REDISMODULE_ERR;
     }
     dbAdd(key->db,key->key,obj);
     key->value = obj;
     moduleInitKeyTypeSpecific(key);
     return REDISMODULE_OK;
 }
 
+/* Frees key->iter and sets it to NULL. */

[PERF] **new** commit 3ca6972ecd3e9963f65b9cb1ff050ad60f03563e
Date:   Thu Sep 9 23:18:53 2021 +0800

    Replace all usage of ziplist with listpack for t_zset (#9366)
    
    Part two of implementing #8702 (zset), after #8887.
    
    ## Description of the feature
    Replaced all uses of ziplist with listpack in t_zset, and optimized some of the code to optimize performance.
    
    ## Rdb format changes
    New `RDB_TYPE_ZSET_LISTPACK` rdb type.
    
    ## Rdb loading improvements:
    1) Pre-expansion of dict for validation of duplicate data for listpack and ziplist.
    2) Simplifying the release of empty key objects when RDB loading.
    3) Unify ziplist and listpack data verify methods for zset and hash, and move code to rdb.c.
    
    ## Interface changes
    1) New `zset-max-listpack-entries` config is an alias for `zset-max-ziplist-entries` (same with `zset-max-listpack-value`).
    2) OBJECT ENCODING will return listpack instead of ziplist.
    
    ## Listpack improvements:
    1) Add `lpDeleteRange` and `lpDeleteRangeWithEntry` functions to delete a range of entries from listpack.
    2) Improve the performance of `lpCompare`, converting from string to integer is faster than converting from integer to string.
    3) Replace `snprintf` with `ll2string` to improve performance in converting numbers to strings in `lpGet()`.
    
    ## Zset improvements:
    1) Improve the performance of `zzlFind` method, use `lpFind` instead of `lpCompare` in a loop.
    2) Use `lpDeleteRangeWithEntry` instead of `lpDelete` twice to delete a element of zset.
    
    ## Tests
    1) Add some unittests for `lpDeleteRange` and `lpDeleteRangeWithEntry` function.
    2) Add zset RDB loading test.
    3) Add benchmark test for `lpCompare` and `ziplsitCompare`.
    4) Add empty listpack zset corrupt dump test.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -511,30 +511,30 @@
 int moduleCreateEmptyKey(RedisModuleKey *key, int type) {
     robj *obj;
 
     /* The key must be open for writing and non existing to proceed. */
     if (!(key->mode & REDISMODULE_WRITE) || key->value)
         return REDISMODULE_ERR;
 
     switch(type) {
     case REDISMODULE_KEYTYPE_LIST:
         obj = createQuicklistObject();
         quicklistSetOptions(obj->ptr, server.list_max_ziplist_size,
                             server.list_compress_depth);
         break;
     case REDISMODULE_KEYTYPE_ZSET:
-        obj = createZsetZiplistObject();
+        obj = createZsetListpackObject();
         break;
     case REDISMODULE_KEYTYPE_HASH:
         obj = createHashObject();
         break;
     case REDISMODULE_KEYTYPE_STREAM:
         obj = createStreamObject();
         break;
     default: return REDISMODULE_ERR;
     }
     dbAdd(key->db,key->key,obj);
     key->value = obj;
     moduleInitKeyTypeSpecific(key);
     return REDISMODULE_OK;
 }
 
[FUNC] **new** commit 574ed6b0ceb3a180e29f231a4ca047dec8dc39b9
Date:   Mon Apr 11 01:34:43 2022 -0400

    modules: add RedisModuleKey* return type to RM_OpenKey (#3719)
    
    Change `RM_OpenKey` to return `RedisModuleKey*` instead of `void*`.
    Which is the input type of other APIs that take the value from RM_OpenKey.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -3633,22 +3633,22 @@
-void *RM_OpenKey(RedisModuleCtx *ctx, robj *keyname, int mode) {
+RedisModuleKey *RM_OpenKey(RedisModuleCtx *ctx, robj *keyname, int mode) {
     RedisModuleKey *kp;
     robj *value;
     int flags = mode & REDISMODULE_OPEN_KEY_NOTOUCH? LOOKUP_NOTOUCH: 0;
 
     if (mode & REDISMODULE_WRITE) {
         value = lookupKeyWriteWithFlags(ctx->client->db,keyname, flags);
     } else {
         value = lookupKeyReadWithFlags(ctx->client->db,keyname, flags);
         if (value == NULL) {
             return NULL;
         }
     }
 
     /* Setup the key handle. */
     kp = zmalloc(sizeof(*kp));
     moduleInitKey(kp, ctx, keyname, value, mode);
     autoMemoryAdd(ctx,REDISMODULE_AM_KEY,kp);
-    return (void*)kp;
+    return kp;
 }
 
 /* Destroy a RedisModuleKey struct (freeing is the responsibility of the caller). */
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -86,21 +235,22 @@
 listTypeIterator *listTypeInitIterator(robj *subject, long index,
                                        unsigned char direction) {
     listTypeIterator *li = zmalloc(sizeof(listTypeIterator));
     li->subject = subject;
     li->encoding = subject->encoding;
     li->direction = direction;
     li->iter = NULL;
     /* LIST_HEAD means start at TAIL and move *towards* head.
      * LIST_TAIL means start at HEAD and move *towards tail. */
-    int iter_direction =
-        direction == LIST_HEAD ? AL_START_TAIL : AL_START_HEAD;
     if (li->encoding == OBJ_ENCODING_QUICKLIST) {
+        int iter_direction = direction == LIST_HEAD ? AL_START_TAIL : AL_START_HEAD;
         li->iter = quicklistGetIteratorAtIdx(li->subject->ptr,
                                              iter_direction, index);
+    } else if (li->encoding == OBJ_ENCODING_LISTPACK) {
+        li->lpi = lpSeek(subject->ptr, index);
     } else {
         serverPanic("Unknown list encoding");
     }
     return li;
 }
 
 /* Sets the direction of an iterator. */

commit ea36d4de17101f05b03d267a4afbae0f7b33a27c
Date:   Tue Sep 14 16:48:06 2021 +0200

    Modules: Add remaining list API functions (#8439)
    
    List functions operating on elements by index:
    
    * RM_ListGet
    * RM_ListSet
    * RM_ListInsert
    * RM_ListDelete
    
    Iteration is done using a simple for loop over indices.
    The index based functions use an internal iterator as an optimization.
    This is explained in the docs:
    
    ```
     * Many of the list functions access elements by index. Since a list is in
     * essence a doubly-linked list, accessing elements by index is generally an
     * O(N) operation. However, if elements are accessed sequentially or with
     * indices close together, the functions are optimized to seek the index from
     * the previous index, rather than seeking from the ends of the list.
     *
     * This enables iteration to be done efficiently using a simple for loop:
     *
     *     long n = RM_ValueLength(key);
     *     for (long i = 0; i < n; i++) {
     *         RedisModuleString *elem = RedisModule_ListGet(key, i);
     *         // Do stuff...
     *     }
    ```

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -86,20 +86,21 @@
 listTypeIterator *listTypeInitIterator(robj *subject, long index,
                                        unsigned char direction) {
     listTypeIterator *li = zmalloc(sizeof(listTypeIterator));
     li->subject = subject;
     li->encoding = subject->encoding;
     li->direction = direction;
     li->iter = NULL;
     /* LIST_HEAD means start at TAIL and move *towards* head.
      * LIST_TAIL means start at HEAD and move *towards tail. */
     int iter_direction =
         direction == LIST_HEAD ? AL_START_TAIL : AL_START_HEAD;
     if (li->encoding == OBJ_ENCODING_QUICKLIST) {
         li->iter = quicklistGetIteratorAtIdx(li->subject->ptr,
                                              iter_direction, index);
     } else {
         serverPanic("Unknown list encoding");
     }
     return li;
 }
 
+/* Sets the direction of an iterator. */
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -204,18 +449,21 @@
 robj *listTypeDup(robj *o) {
     robj *lobj;
 
     serverAssert(o->type == OBJ_LIST);
 
     switch (o->encoding) {
+        case OBJ_ENCODING_LISTPACK:
+            lobj = createObject(OBJ_LIST, lpDup(o->ptr));
+            break;
         case OBJ_ENCODING_QUICKLIST:
             lobj = createObject(OBJ_LIST, quicklistDup(o->ptr));
-            lobj->encoding = o->encoding;
             break;
         default:
             serverPanic("Unknown list encoding");
             break;
     }
+    lobj->encoding = o->encoding;
     return lobj;
 }
 
 /* Delete a range of elements from the list. */

[FUNC] **new** commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -224,18 +222,18 @@
 robj *listTypeDup(robj *o) {
     robj *lobj;
 
     serverAssert(o->type == OBJ_LIST);
 
     switch (o->encoding) {
         case OBJ_ENCODING_QUICKLIST:
             lobj = createObject(OBJ_LIST, quicklistDup(o->ptr));
-            lobj->encoding = OBJ_ENCODING_QUICKLIST;
+            lobj->encoding = o->encoding;
             break;
         default:
             serverPanic("Unknown list encoding");
             break;
     }
     return lobj;
 }
 
 /* Delete a range of elements from the list. */

[NA] **new** commit c50af0aeba693bf93e5c471cff08d8ccde0f5213
Date:   Thu Sep 9 17:02:33 2021 +0800

    Add LMPOP/BLMPOP commands. (#9373)
    
    We want to add COUNT option for BLPOP.
    But we can't do it without breaking compatibility due to the command arguments syntax.
    So this commit introduce two new commands.
    
    Syntax for the new LMPOP command:
    `LMPOP numkeys [<key> ...] LEFT|RIGHT [COUNT count]`
    
    Syntax for the new BLMPOP command:
    `BLMPOP timeout numkeys [<key> ...] LEFT|RIGHT [COUNT count]`
    
    Some background:
    - LPOP takes one key, and can return multiple elements.
    - BLPOP takes multiple keys, but returns one element from just one key.
    - LMPOP can take multiple keys and return multiple elements from just one key.
    
    Note that LMPOP/BLMPOP  can take multiple keys, it eventually operates on just one key.
    And it will propagate as LPOP or RPOP with the COUNT option.
    
    As a new command, it still return NIL if we can't pop any elements.
    For the normal response is nested arrays in RESP2 and RESP3, like:
    ```
    LMPOP/BLMPOP
    1) keyname
    2) 1) element1
       2) element2
    ```
    I.e. unlike BLPOP that returns a key name and one element so it uses a flat array,
    and LPOP that returns multiple elements with no key name, and again uses a flat array,
    this one has to return a nested array, and it does for for both RESP2 and RESP3 (like SCAN does)
    
    Some discuss can see: #766 #8824

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -201,17 +201,18 @@
 robj *listTypeDup(robj *o) {
     robj *lobj;
 
     serverAssert(o->type == OBJ_LIST);
 
     switch (o->encoding) {
         case OBJ_ENCODING_QUICKLIST:
             lobj = createObject(OBJ_LIST, quicklistDup(o->ptr));
             lobj->encoding = OBJ_ENCODING_QUICKLIST;
             break;
         default:
             serverPanic("Unknown list encoding");
             break;
     }
     return lobj;
 }
 
+/* Delete a range of elements from the list. */
[CORR] **new** commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1304,108 +1374,40 @@
 quicklist *quicklistDup(quicklist *orig) {
     quicklist *copy;
 
     copy = quicklistNew(orig->fill, orig->compress);
 
     for (quicklistNode *current = orig->head; current;
          current = current->next) {
         quicklistNode *node = quicklistCreateNode();
 
         if (current->encoding == QUICKLIST_NODE_ENCODING_LZF) {
             quicklistLZF *lzf = (quicklistLZF *)current->entry;
             size_t lzf_sz = sizeof(*lzf) + lzf->sz;
             node->entry = zmalloc(lzf_sz);
             memcpy(node->entry, current->entry, lzf_sz);
         } else if (current->encoding == QUICKLIST_NODE_ENCODING_RAW) {
             node->entry = zmalloc(current->sz);
             memcpy(node->entry, current->entry, current->sz);
         }
 
         node->count = current->count;
         copy->count += node->count;
         node->sz = current->sz;
         node->encoding = current->encoding;
         node->container = current->container;
 
         _quicklistInsertNodeAfter(copy, copy->tail, node);
     }
 
     /* copy->count must equal orig->count here */
     return copy;
 }
 
 /* Populate 'entry' with the element at the specified zero-based index
  * where 0 is the head, 1 is the element next to head
  * and so on. Negative integers are used in order to count
  * from the tail, -1 is the last element, -2 the penultimate
  * and so on. If the index is out of range 0 is returned.
  *
- * Returns 1 if element found
- * Returns 0 if element not found */
-int quicklistIndex(const quicklist *quicklist, const long long idx,
-                   quicklistEntry *entry) {
-    quicklistNode *n;
-    unsigned long long accum = 0;
-    unsigned long long index;
-    int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
-
-    initEntry(entry);
-    entry->quicklist = quicklist;
-
-    index = forward ? idx : (-idx) - 1;
-    if (index >= quicklist->count)
-        return 0;
-
-    /* Seek in the other direction if that way is shorter. */
-    int seek_forward = forward;
-    unsigned long long seek_index = index;
-    if (index > (quicklist->count - 1) / 2) {
-        seek_forward = !forward;
-        seek_index = quicklist->count - 1 - index;
-    }
-
-    n = seek_forward ? quicklist->head : quicklist->tail;
-    while (likely(n)) {
-        if ((accum + n->count) > seek_index) {
-            break;
-        } else {
-            D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
-              accum);
-            accum += n->count;
-            n = seek_forward ? n->next : n->prev;
-        }
-    }
-
-    if (!n)
-        return 0;
-
-    /* Fix accum so it looks like we seeked in the other direction. */
-    if (seek_forward != forward) accum = quicklist->count - n->count - accum;
-
-    D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
-      accum, index, index - accum, (-index) - 1 + accum);
-
-    entry->node = n;
-    if (forward) {
-        /* forward = normal head-to-tail offset. */
-        entry->offset = index - accum;
-    } else {
-        /* reverse = need negative offset for tail-to-head, so undo
-         * the result of the original index = (-idx) - 1 above. */
-        entry->offset = (-index) - 1 + accum;
-    }
-
-    quicklistDecompressNodeForUse(entry->node);
-
-    if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
-        entry->value = entry->node->entry;
-        entry->sz = entry->node->sz;
-        return 1;
-    }
-
-    entry->zi = lpSeek(entry->node->entry, entry->offset);
-    unsigned int sz = 0;
-    entry->value = lpGetValue(entry->zi, &sz, &entry->longval);
-    /* The caller will use our result, so we don't re-compress here.
-     * The caller can recompress or delete the node as needed. */
-    entry->sz = sz;
-    return 1;
+ * Returns an iterator at a specific offset 'idx' if element found
+ * Returns NULL if element not found */

commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1371,109 +1304,108 @@
 quicklist *quicklistDup(quicklist *orig) {
     quicklist *copy;
 
     copy = quicklistNew(orig->fill, orig->compress);
 
     for (quicklistNode *current = orig->head; current;
          current = current->next) {
         quicklistNode *node = quicklistCreateNode();
 
         if (current->encoding == QUICKLIST_NODE_ENCODING_LZF) {
             quicklistLZF *lzf = (quicklistLZF *)current->entry;
             size_t lzf_sz = sizeof(*lzf) + lzf->sz;
             node->entry = zmalloc(lzf_sz);
             memcpy(node->entry, current->entry, lzf_sz);
         } else if (current->encoding == QUICKLIST_NODE_ENCODING_RAW) {
             node->entry = zmalloc(current->sz);
             memcpy(node->entry, current->entry, current->sz);
         }
 
         node->count = current->count;
         copy->count += node->count;
         node->sz = current->sz;
         node->encoding = current->encoding;
         node->container = current->container;
 
         _quicklistInsertNodeAfter(copy, copy->tail, node);
     }
 
     /* copy->count must equal orig->count here */
     return copy;
 }
 
 /* Populate 'entry' with the element at the specified zero-based index
  * where 0 is the head, 1 is the element next to head
  * and so on. Negative integers are used in order to count
  * from the tail, -1 is the last element, -2 the penultimate
  * and so on. If the index is out of range 0 is returned.
  *
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
     index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
     /* Seek in the other direction if that way is shorter. */
     int seek_forward = forward;
     unsigned long long seek_index = index;
     if (index > (quicklist->count - 1) / 2) {
         seek_forward = !forward;
         seek_index = quicklist->count - 1 - index;
     }
 
     n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
         if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
             n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
     /* Fix accum so it looks like we seeked in the other direction. */
     if (seek_forward != forward) accum = quicklist->count - n->count - accum;
 
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
          * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
 
     if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
         entry->value = entry->node->entry;
         entry->sz = entry->node->sz;
         return 1;
     }
 
-    entry->zi = ziplistIndex(entry->node->entry, entry->offset);
+    entry->zi = lpSeek(entry->node->entry, entry->offset);
     unsigned int sz = 0;
-    if (!ziplistGet(entry->zi, &entry->value, &sz, &entry->longval))
-        assert(0); /* This can happen on corrupt ziplist with fake entry count. */
+    entry->value = lpGetValue(entry->zi, &sz, &entry->longval);
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
     entry->sz = sz;
     return 1;

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1221,99 +1361,109 @@
 quicklist *quicklistDup(quicklist *orig) {
     quicklist *copy;
 
     copy = quicklistNew(orig->fill, orig->compress);
 
     for (quicklistNode *current = orig->head; current;
          current = current->next) {
         quicklistNode *node = quicklistCreateNode();
 
         if (current->encoding == QUICKLIST_NODE_ENCODING_LZF) {
-            quicklistLZF *lzf = (quicklistLZF *)current->zl;
+            quicklistLZF *lzf = (quicklistLZF *)current->entry;
             size_t lzf_sz = sizeof(*lzf) + lzf->sz;
-            node->zl = zmalloc(lzf_sz);
-            memcpy(node->zl, current->zl, lzf_sz);
+            node->entry = zmalloc(lzf_sz);
+            memcpy(node->entry, current->entry, lzf_sz);
         } else if (current->encoding == QUICKLIST_NODE_ENCODING_RAW) {
-            node->zl = zmalloc(current->sz);
-            memcpy(node->zl, current->zl, current->sz);
+            node->entry = zmalloc(current->sz);
+            memcpy(node->entry, current->entry, current->sz);
         }
 
         node->count = current->count;
         copy->count += node->count;
         node->sz = current->sz;
         node->encoding = current->encoding;
+        node->container = current->container;
 
         _quicklistInsertNodeAfter(copy, copy->tail, node);
     }
 
     /* copy->count must equal orig->count here */
     return copy;
 }
 
 /* Populate 'entry' with the element at the specified zero-based index
  * where 0 is the head, 1 is the element next to head
  * and so on. Negative integers are used in order to count
  * from the tail, -1 is the last element, -2 the penultimate
  * and so on. If the index is out of range 0 is returned.
  *
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
     index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
     /* Seek in the other direction if that way is shorter. */
     int seek_forward = forward;
     unsigned long long seek_index = index;
     if (index > (quicklist->count - 1) / 2) {
         seek_forward = !forward;
         seek_index = quicklist->count - 1 - index;
     }
 
     n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
         if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
             n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
     /* Fix accum so it looks like we seeked in the other direction. */
     if (seek_forward != forward) accum = quicklist->count - n->count - accum;
 
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
          * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
-    entry->zi = ziplistIndex(entry->node->zl, entry->offset);
-    if (!ziplistGet(entry->zi, &entry->value, &entry->sz, &entry->longval))
+
+    if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
+        entry->value = entry->node->entry;
+        entry->sz = entry->node->sz;
+        return 1;
+    }
+
+    entry->zi = ziplistIndex(entry->node->entry, entry->offset);
+    unsigned int sz = 0;
+    if (!ziplistGet(entry->zi, &entry->value, &sz, &entry->longval))
         assert(0); /* This can happen on corrupt ziplist with fake entry count. */
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
+    entry->sz = sz;
     return 1;

[PERF] **new** commit 547c3405d4d5cdb38ea598c07286c26688824f0a
Date:   Mon Sep 6 08:12:38 2021 +0200

    Optimize quicklistIndex to seek from the nearest end (#9454)
    
    Until now, giving a negative index seeks from the end of a list and a
    positive seeks from the beginning. This change makes it seek from
    the nearest end, regardless of the sign of the given index.
    
    quicklistIndex is used by all list commands which operate by index.
    
    LINDEX key 999999 in a list if 1M elements is greately optimized by
    this change. Latency is cut by 75%.
    
    LINDEX key -1000000 in a list of 1M elements, likewise.
    
    LRANGE key -1 -1 is affected by this, since LRANGE converts the
    indices to positive numbers before seeking.
    
    The tests for corrupt dumps are updated to make sure the corrup
    data is seeked in the same direction as before.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1198,94 +1198,99 @@
 quicklist *quicklistDup(quicklist *orig) {
     quicklist *copy;
 
     copy = quicklistNew(orig->fill, orig->compress);
 
     for (quicklistNode *current = orig->head; current;
          current = current->next) {
         quicklistNode *node = quicklistCreateNode();
 
         if (current->encoding == QUICKLIST_NODE_ENCODING_LZF) {
             quicklistLZF *lzf = (quicklistLZF *)current->zl;
             size_t lzf_sz = sizeof(*lzf) + lzf->sz;
             node->zl = zmalloc(lzf_sz);
             memcpy(node->zl, current->zl, lzf_sz);
         } else if (current->encoding == QUICKLIST_NODE_ENCODING_RAW) {
             node->zl = zmalloc(current->sz);
             memcpy(node->zl, current->zl, current->sz);
         }
 
         node->count = current->count;
         copy->count += node->count;
         node->sz = current->sz;
         node->encoding = current->encoding;
 
         _quicklistInsertNodeAfter(copy, copy->tail, node);
     }
 
     /* copy->count must equal orig->count here */
     return copy;
 }
 
 /* Populate 'entry' with the element at the specified zero-based index
  * where 0 is the head, 1 is the element next to head
  * and so on. Negative integers are used in order to count
  * from the tail, -1 is the last element, -2 the penultimate
  * and so on. If the index is out of range 0 is returned.
  *
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
-    if (!forward) {
-        index = (-idx) - 1;
-        n = quicklist->tail;
-    } else {
-        index = idx;
-        n = quicklist->head;
-    }
-
+    index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
+    /* Seek in the other direction if that way is shorter. */
+    int seek_forward = forward;
+    unsigned long long seek_index = index;
+    if (index > (quicklist->count - 1) / 2) {
+        seek_forward = !forward;
+        seek_index = quicklist->count - 1 - index;
+    }
+
+    n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
-        if ((accum + n->count) > index) {
+        if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
-            n = forward ? n->next : n->prev;
+            n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
+    /* Fix accum so it looks like we seeked in the other direction. */
+    if (seek_forward != forward) accum = quicklist->count - n->count - accum;
+
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
-         * the result of the original if (index < 0) above. */
+         * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
     entry->zi = ziplistIndex(entry->node->zl, entry->offset);
     if (!ziplistGet(entry->zi, &entry->value, &entry->sz, &entry->longval))
         assert(0); /* This can happen on corrupt ziplist with fake entry count. */
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
     return 1;
[FUNC] **new** commit 13d25dd95eec5e21925ef474b5d43f2acb23e54e
Date:   Mon Sep 19 14:47:52 2022 +0800

    Fix crash due to delete entry from compress quicklistNode and wrongly split quicklistNode (#11242)
    
    This PR mainly deals with 2 crashes introduced in #9357,
    and fix the QUICKLIST-PACKED-THRESHOLD mess in external test mode.
    
    1. Fix crash due to deleting an entry from a compress quicklistNode
       When inserting a large element, we need to create a new quicklistNode first,
       and then delete its previous element, if the node where the deleted element is
       located is compressed, it will cause a crash.
       Now add `dont_compress` to quicklistNode, if we want to use a quicklistNode
       after some operation, we can use this flag like following:
    
        ```c
        node->dont_compress = 1; /* Prevent to be compressed */
        some_operation(node); /* This operation might try to compress this node */
        some_other_operation(node); /* We can use this node without decompress it */
        node->dont_compress = 0; /* Re-able compression */
        quicklistCompressNode(node);
        ```
    
       Perhaps in the future, we could just disable the current entry from being
       compressed during the iterator loop, but that would require more work.
    
    2. Fix crash due to wrongly split quicklist
       before #9357, the offset param of _quicklistSplitNode() will not negative.
       For now, when offset is negative, the split extent will be wrong.
       following example:
        ```c
        int orig_start = after ? offset + 1 : 0;
        int orig_extent = after ? -1 : offset;
        int new_start = after ? 0 : offset;
        int new_extent = after ? offset + 1 : -1;
        # offset: -2, after: 1, node->count: 2
        # current wrong range: [-1,-1] [0,-1]
        # correct range: [1,-1] [0, 1]
        ```
    
       Because only `_quicklistInsert()` splits the quicklistNode and only
       `quicklistInsertAfter()`, `quicklistInsertBefore()` call _quicklistInsert(),
       so `quicklistReplaceEntry()` and `listTypeInsert()` might occur this crash.
       But the iterator of `listTypeInsert()` is alway from head to tail(iter->offset is
       always positive), so it is not affected.
       The final conclusion is this crash only occur when we insert a large element
       with negative index into a list, that affects `LSET` command and `RM_ListSet`
       module api.
    
    3. In external test mode, we need to restore quicklist packed threshold after
       when the end of test.
    4. Show `node->count` in quicklistRepr().
    5. Add new tcl proc `config_get_set` to support restoring config in tests.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -170,14 +172,15 @@
 REDIS_STATIC quicklistNode *quicklistCreateNode(void) {
     quicklistNode *node;
     node = zmalloc(sizeof(*node));
     node->entry = NULL;
     node->count = 0;
     node->sz = 0;
     node->next = node->prev = NULL;
     node->encoding = QUICKLIST_NODE_ENCODING_RAW;
     node->container = QUICKLIST_NODE_CONTAINER_PACKED;
     node->recompress = 0;
+    node->dont_compress = 0;
     return node;
 }
 
 /* Return cached quicklist count */

commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -156,14 +162,14 @@
 REDIS_STATIC quicklistNode *quicklistCreateNode(void) {
     quicklistNode *node;
     node = zmalloc(sizeof(*node));
     node->entry = NULL;
     node->count = 0;
     node->sz = 0;
     node->next = node->prev = NULL;
     node->encoding = QUICKLIST_NODE_ENCODING_RAW;
-    node->container = QUICKLIST_NODE_CONTAINER_ZIPLIST;
+    node->container = QUICKLIST_NODE_CONTAINER_PACKED;
     node->recompress = 0;
     return node;
 }
 
 /* Return cached quicklist count */

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -144,14 +156,14 @@
 REDIS_STATIC quicklistNode *quicklistCreateNode(void) {
     quicklistNode *node;
     node = zmalloc(sizeof(*node));
-    node->zl = NULL;
+    node->entry = NULL;
     node->count = 0;
     node->sz = 0;
     node->next = node->prev = NULL;
     node->encoding = QUICKLIST_NODE_ENCODING_RAW;
     node->container = QUICKLIST_NODE_CONTAINER_ZIPLIST;
     node->recompress = 0;
     return node;
 }
 
 /* Return cached quicklist count */
commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -488,0 +536,10 @@
+static quicklistNode* __quicklistCreatePlainNode(void *value, size_t sz) {
+    quicklistNode *new_node = quicklistCreateNode();
+    new_node->entry = zmalloc(sz);
+    new_node->container = QUICKLIST_NODE_CONTAINER_PLAIN;
+    memcpy(new_node->entry, value, sz);
+    new_node->sz = sz;
+    new_node->count++;
+    return new_node;
+}
+
commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -622,15 +585,15 @@
-void quicklistAppendZiplist(quicklist *quicklist, unsigned char *zl) {
+void quicklistAppendListpack(quicklist *quicklist, unsigned char *zl) {
     quicklistNode *node = quicklistCreateNode();
 
     node->entry = zl;
-    node->count = ziplistLen(node->entry);
-    node->sz = ziplistBlobLen(zl);
+    node->count = lpLength(node->entry);
+    node->sz = lpBytes(zl);
 
     _quicklistInsertNodeAfter(quicklist, quicklist->tail, node);
     quicklist->count += node->count;
 }
 
 /* Create new node consisting of a pre-formed plain node.
  * Used for loading RDBs where entire plain node has been stored
  * to be retrieved later.
  * data - the data to add (pointer becomes the responsibility of quicklist) */

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -539,11 +612,15 @@
 void quicklistAppendZiplist(quicklist *quicklist, unsigned char *zl) {
     quicklistNode *node = quicklistCreateNode();
 
-    node->zl = zl;
-    node->count = ziplistLen(node->zl);
+    node->entry = zl;
+    node->count = ziplistLen(node->entry);
     node->sz = ziplistBlobLen(zl);
 
     _quicklistInsertNodeAfter(quicklist, quicklist->tail, node);
     quicklist->count += node->count;
 }
 
+/* Create new node consisting of a pre-formed plain node.
+ * Used for loading RDBs where entire plain node has been stored
+ * to be retrieved later.
+ * data - the data to add (pointer becomes the responsibility of quicklist) */
commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -637,47 +600,20 @@
 void quicklistAppendPlainNode(quicklist *quicklist, unsigned char *data, size_t sz) {
-    __quicklistInsertPlainNode(quicklist, quicklist->tail, data, sz, 1);
-}
-
-/* Append all values of ziplist 'zl' individually into 'quicklist'.
- *
- * This allows us to restore old RDB ziplists into new quicklists
- * with smaller ziplist sizes than the saved RDB ziplist.
- *
- * Returns 'quicklist' argument. Frees passed-in ziplist 'zl' */
-quicklist *quicklistAppendValuesFromZiplist(quicklist *quicklist,
-                                            unsigned char *zl) {
-    unsigned char *value;
-    unsigned int sz;
-    long long longval;
-    char longstr[32] = {0};
+    quicklistNode *node = quicklistCreateNode();
 
-    unsigned char *p = ziplistIndex(zl, 0);
-    while (ziplistGet(p, &value, &sz, &longval)) {
-        if (!value) {
-            /* Write the longval as a string so we can re-add it */
-            sz = ll2string(longstr, sizeof(longstr), longval);
-            value = (unsigned char *)longstr;
-        }
-        quicklistPushTail(quicklist, value, sz);
-        p = ziplistNext(zl, p);
-    }
-    zfree(zl);
-    return quicklist;
-}
+    node->entry = data;
+    node->count = 1;
+    node->sz = sz;
+    node->container = QUICKLIST_NODE_CONTAINER_PLAIN;
 
-/* Create new (potentially multi-node) quicklist from a single existing ziplist.
- *
- * Returns new quicklist.  Frees passed-in ziplist 'zl'. */
-quicklist *quicklistCreateFromZiplist(int fill, int compress,
-                                      unsigned char *zl) {
-    return quicklistAppendValuesFromZiplist(quicklistNew(fill, compress), zl);
+    _quicklistInsertNodeAfter(quicklist, quicklist->tail, node);
+    quicklist->count += node->count;
 }
 
 #define quicklistDeleteIfEmpty(ql, n)                                          \
     do {                                                                       \
         if ((n)->count == 0) {                                                 \
             __quicklistDelNode((ql), (n));                                     \
             (n) = NULL;                                                        \
         }                                                                      \
     } while (0)
 

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -550,43 +627,47 @@
+void quicklistAppendPlainNode(quicklist *quicklist, unsigned char *data, size_t sz) {
+    __quicklistInsertPlainNode(quicklist, quicklist->tail, data, sz, 1);
+}
+
 /* Append all values of ziplist 'zl' individually into 'quicklist'.
  *
  * This allows us to restore old RDB ziplists into new quicklists
  * with smaller ziplist sizes than the saved RDB ziplist.
  *
  * Returns 'quicklist' argument. Frees passed-in ziplist 'zl' */
 quicklist *quicklistAppendValuesFromZiplist(quicklist *quicklist,
                                             unsigned char *zl) {
     unsigned char *value;
     unsigned int sz;
     long long longval;
     char longstr[32] = {0};
 
     unsigned char *p = ziplistIndex(zl, 0);
     while (ziplistGet(p, &value, &sz, &longval)) {
         if (!value) {
             /* Write the longval as a string so we can re-add it */
             sz = ll2string(longstr, sizeof(longstr), longval);
             value = (unsigned char *)longstr;
         }
         quicklistPushTail(quicklist, value, sz);
         p = ziplistNext(zl, p);
     }
     zfree(zl);
     return quicklist;
 }
 
 /* Create new (potentially multi-node) quicklist from a single existing ziplist.
  *
  * Returns new quicklist.  Frees passed-in ziplist 'zl'. */
 quicklist *quicklistCreateFromZiplist(int fill, int compress,
                                       unsigned char *zl) {
     return quicklistAppendValuesFromZiplist(quicklistNew(fill, compress), zl);
 }
 
 #define quicklistDeleteIfEmpty(ql, n)                                          \
     do {                                                                       \
         if ((n)->count == 0) {                                                 \
             __quicklistDelNode((ql), (n));                                     \
             (n) = NULL;                                                        \
         }                                                                      \
     } while (0)
 
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1148,23 +1177,23 @@
-quicklistIter *quicklistGetIterator(const quicklist *quicklist, int direction) {
+quicklistIter *quicklistGetIterator(quicklist *quicklist, int direction) {
     quicklistIter *iter;
 
     iter = zmalloc(sizeof(*iter));
 
     if (direction == AL_START_HEAD) {
         iter->current = quicklist->head;
         iter->offset = 0;
     } else if (direction == AL_START_TAIL) {
         iter->current = quicklist->tail;
         iter->offset = -1;
     }
 
     iter->direction = direction;
     iter->quicklist = quicklist;
 
     iter->zi = NULL;
 
     return iter;
 }
 
 /* Initialize an iterator at a specific offset 'idx' and make the iterator
  * return nodes in 'direction' direction. */
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1171,18 +1200,58 @@
-quicklistIter *quicklistGetIteratorAtIdx(const quicklist *quicklist,
+quicklistIter *quicklistGetIteratorAtIdx(quicklist *quicklist,
                                          const int direction,
-                                         const long long idx) {
-    quicklistEntry entry;
+                                         const long long idx)
+{
+    quicklistNode *n;
+    unsigned long long accum = 0;
+    unsigned long long index;
+    int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
-    if (quicklistIndex(quicklist, idx, &entry)) {
-        quicklistIter *base = quicklistGetIterator(quicklist, direction);
-        base->zi = NULL;
-        base->current = entry.node;
-        base->offset = entry.offset;
-        return base;
-    } else {
+    index = forward ? idx : (-idx) - 1;
+    if (index >= quicklist->count)
+        return NULL;
+
+    /* Seek in the other direction if that way is shorter. */
+    int seek_forward = forward;
+    unsigned long long seek_index = index;
+    if (index > (quicklist->count - 1) / 2) {
+        seek_forward = !forward;
+        seek_index = quicklist->count - 1 - index;
+    }
+
+    n = seek_forward ? quicklist->head : quicklist->tail;
+    while (likely(n)) {
+        if ((accum + n->count) > seek_index) {
+            break;
+        } else {
+            D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
+              accum);
+            accum += n->count;
+            n = seek_forward ? n->next : n->prev;
+        }
+    }
+
+    if (!n)
         return NULL;
+
+    /* Fix accum so it looks like we seeked in the other direction. */
+    if (seek_forward != forward) accum = quicklist->count - n->count - accum;
+
+    D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
+      accum, index, index - accum, (-index) - 1 + accum);
+
+    quicklistIter *iter = quicklistGetIterator(quicklist, direction);
+    iter->current = n;
+    if (forward) {
+        /* forward = normal head-to-tail offset. */
+        iter->offset = index - accum;
+    } else {
+        /* reverse = need negative offset for tail-to-head, so undo
+         * the result of the original index = (-idx) - 1 above. */
+        iter->offset = (-index) - 1 + accum;
     }
+
+    return iter;
 }
 
 /* Release iterator.
  * If we still have a valid current node, then re-encode current node. */
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1342,72 +1414,9 @@
- * Returns 1 if element found
- * Returns 0 if element not found */
-int quicklistIndex(const quicklist *quicklist, const long long idx,
-                   quicklistEntry *entry) {
-    quicklistNode *n;
-    unsigned long long accum = 0;
-    unsigned long long index;
-    int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
-
-    initEntry(entry);
-    entry->quicklist = quicklist;
-
-    index = forward ? idx : (-idx) - 1;
-    if (index >= quicklist->count)
-        return 0;
-
-    /* Seek in the other direction if that way is shorter. */
-    int seek_forward = forward;
-    unsigned long long seek_index = index;
-    if (index > (quicklist->count - 1) / 2) {
-        seek_forward = !forward;
-        seek_index = quicklist->count - 1 - index;
-    }
-
-    n = seek_forward ? quicklist->head : quicklist->tail;
-    while (likely(n)) {
-        if ((accum + n->count) > seek_index) {
-            break;
-        } else {
-            D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
-              accum);
-            accum += n->count;
-            n = seek_forward ? n->next : n->prev;
-        }
-    }
-
-    if (!n)
-        return 0;
-
-    /* Fix accum so it looks like we seeked in the other direction. */
-    if (seek_forward != forward) accum = quicklist->count - n->count - accum;
-
-    D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
-      accum, index, index - accum, (-index) - 1 + accum);
-
-    entry->node = n;
-    if (forward) {
-        /* forward = normal head-to-tail offset. */
-        entry->offset = index - accum;
-    } else {
-        /* reverse = need negative offset for tail-to-head, so undo
-         * the result of the original index = (-idx) - 1 above. */
-        entry->offset = (-index) - 1 + accum;
-    }
-
-    quicklistDecompressNodeForUse(entry->node);
-
-    if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
-        entry->value = entry->node->entry;
-        entry->sz = entry->node->sz;
-        return 1;
-    }
-
-    entry->zi = lpSeek(entry->node->entry, entry->offset);
-    unsigned int sz = 0;
-    entry->value = lpGetValue(entry->zi, &sz, &entry->longval);
-    /* The caller will use our result, so we don't re-compress here.
-     * The caller can recompress or delete the node as needed. */
-    entry->sz = sz;
-    return 1;
+quicklistIter *quicklistGetIteratorEntryAtIdx(quicklist *quicklist, const long long idx,
+                                              quicklistEntry *entry)
+{
+    quicklistIter *iter = quicklistGetIteratorAtIdx(quicklist, AL_START_TAIL, idx);
+    if (!iter) return NULL;
+    assert(quicklistNext(iter, entry));
+    return iter;
 }
 

commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1409,73 +1342,72 @@
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
     index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
     /* Seek in the other direction if that way is shorter. */
     int seek_forward = forward;
     unsigned long long seek_index = index;
     if (index > (quicklist->count - 1) / 2) {
         seek_forward = !forward;
         seek_index = quicklist->count - 1 - index;
     }
 
     n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
         if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
             n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
     /* Fix accum so it looks like we seeked in the other direction. */
     if (seek_forward != forward) accum = quicklist->count - n->count - accum;
 
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
          * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
 
     if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
         entry->value = entry->node->entry;
         entry->sz = entry->node->sz;
         return 1;
     }
 
-    entry->zi = ziplistIndex(entry->node->entry, entry->offset);
+    entry->zi = lpSeek(entry->node->entry, entry->offset);
     unsigned int sz = 0;
-    if (!ziplistGet(entry->zi, &entry->value, &sz, &entry->longval))
-        assert(0); /* This can happen on corrupt ziplist with fake entry count. */
+    entry->value = lpGetValue(entry->zi, &sz, &entry->longval);
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
     entry->sz = sz;
     return 1;
 }
 

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1258,64 +1399,73 @@
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
     index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
     /* Seek in the other direction if that way is shorter. */
     int seek_forward = forward;
     unsigned long long seek_index = index;
     if (index > (quicklist->count - 1) / 2) {
         seek_forward = !forward;
         seek_index = quicklist->count - 1 - index;
     }
 
     n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
         if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
             n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
     /* Fix accum so it looks like we seeked in the other direction. */
     if (seek_forward != forward) accum = quicklist->count - n->count - accum;
 
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
          * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
-    entry->zi = ziplistIndex(entry->node->zl, entry->offset);
-    if (!ziplistGet(entry->zi, &entry->value, &entry->sz, &entry->longval))
+
+    if (unlikely(QL_NODE_IS_PLAIN(entry->node))) {
+        entry->value = entry->node->entry;
+        entry->sz = entry->node->sz;
+        return 1;
+    }
+
+    entry->zi = ziplistIndex(entry->node->entry, entry->offset);
+    unsigned int sz = 0;
+    if (!ziplistGet(entry->zi, &entry->value, &sz, &entry->longval))
         assert(0); /* This can happen on corrupt ziplist with fake entry count. */
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
+    entry->sz = sz;
     return 1;
 }
 

commit 547c3405d4d5cdb38ea598c07286c26688824f0a
Date:   Mon Sep 6 08:12:38 2021 +0200

    Optimize quicklistIndex to seek from the nearest end (#9454)
    
    Until now, giving a negative index seeks from the end of a list and a
    positive seeks from the beginning. This change makes it seek from
    the nearest end, regardless of the sign of the given index.
    
    quicklistIndex is used by all list commands which operate by index.
    
    LINDEX key 999999 in a list if 1M elements is greately optimized by
    this change. Latency is cut by 75%.
    
    LINDEX key -1000000 in a list of 1M elements, likewise.
    
    LRANGE key -1 -1 is affected by this, since LRANGE converts the
    indices to positive numbers before seeking.
    
    The tests for corrupt dumps are updated to make sure the corrup
    data is seeked in the same direction as before.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1235,59 +1235,64 @@
  * Returns 1 if element found
  * Returns 0 if element not found */
 int quicklistIndex(const quicklist *quicklist, const long long idx,
                    quicklistEntry *entry) {
     quicklistNode *n;
     unsigned long long accum = 0;
     unsigned long long index;
     int forward = idx < 0 ? 0 : 1; /* < 0 -> reverse, 0+ -> forward */
 
     initEntry(entry);
     entry->quicklist = quicklist;
 
-    if (!forward) {
-        index = (-idx) - 1;
-        n = quicklist->tail;
-    } else {
-        index = idx;
-        n = quicklist->head;
-    }
-
+    index = forward ? idx : (-idx) - 1;
     if (index >= quicklist->count)
         return 0;
 
+    /* Seek in the other direction if that way is shorter. */
+    int seek_forward = forward;
+    unsigned long long seek_index = index;
+    if (index > (quicklist->count - 1) / 2) {
+        seek_forward = !forward;
+        seek_index = quicklist->count - 1 - index;
+    }
+
+    n = seek_forward ? quicklist->head : quicklist->tail;
     while (likely(n)) {
-        if ((accum + n->count) > index) {
+        if ((accum + n->count) > seek_index) {
             break;
         } else {
             D("Skipping over (%p) %u at accum %lld", (void *)n, n->count,
               accum);
             accum += n->count;
-            n = forward ? n->next : n->prev;
+            n = seek_forward ? n->next : n->prev;
         }
     }
 
     if (!n)
         return 0;
 
+    /* Fix accum so it looks like we seeked in the other direction. */
+    if (seek_forward != forward) accum = quicklist->count - n->count - accum;
+
     D("Found node: %p at accum %llu, idx %llu, sub+ %llu, sub- %llu", (void *)n,
       accum, index, index - accum, (-index) - 1 + accum);
 
     entry->node = n;
     if (forward) {
         /* forward = normal head-to-tail offset. */
         entry->offset = index - accum;
     } else {
         /* reverse = need negative offset for tail-to-head, so undo
-         * the result of the original if (index < 0) above. */
+         * the result of the original index = (-idx) - 1 above. */
         entry->offset = (-index) - 1 + accum;
     }
 
     quicklistDecompressNodeForUse(entry->node);
     entry->zi = ziplistIndex(entry->node->zl, entry->offset);
     if (!ziplistGet(entry->zi, &entry->value, &entry->sz, &entry->longval))
         assert(0); /* This can happen on corrupt ziplist with fake entry count. */
     /* The caller will use our result, so we don't re-compress here.
      * The caller can recompress or delete the node as needed. */
     return 1;
 }
 
commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1422,13 +1597,13 @@
-REDIS_STATIC void *_quicklistSaver(unsigned char *data, unsigned int sz) {
+REDIS_STATIC void *_quicklistSaver(unsigned char *data, size_t sz) {
     unsigned char *vstr;
     if (data) {
         vstr = zmalloc(sz);
         memcpy(vstr, data, sz);
         return vstr;
     }
     return NULL;
 }
 
 /* Default pop function
  *
  * Returns malloc'd value from quicklist */
[SEC] **new** commit 7cb89a5a1cc8ee0b003a36b2eba42573c09c45f9
Date:   Mon Oct 4 12:09:25 2021 +0300

    Fix Integer overflow issue with intsets (CVE-2021-32687) (#9586)
    
    The vulnerability involves changing the default set-max-intset-entries
    configuration parameter to a very large value and constructing specially
    crafted commands to manipulate sets

diff --git a/src/intset.c b/src/intset.c
--- a/src/intset.c
+++ b/src/intset.c
@@ -106,10 +106,11 @@
 static intset *intsetResize(intset *is, uint32_t len) {
-    uint32_t size = len*intrev32ifbe(is->encoding);
+    uint64_t size = (uint64_t)len*intrev32ifbe(is->encoding);
+    assert(size <= SIZE_MAX - sizeof(intset));
     is = zrealloc(is,sizeof(intset)+size);
     return is;
 }
 
 /* Search for the position of "value". Return 1 when the value was found and
  * sets "pos" to the position of the value within the intset. Return 0 when
  * the value is not present in the intset and sets "pos" to the position
  * where "value" can be inserted. */
[PERF] **new** commit aab479f8cfaa4493f5618ba05cfec0e2b406e77c
Date:   Tue Feb 16 22:17:38 2021 +0800

    Optimize listpack for stream usage to avoid repeated reallocs (#6281)
    
    Avoid repeated reallocs growing the listpack while entries are being added.
    This is done by pre-allocating the listpack to near maximum size, and using
    malloc_size to check if it needs realloc or not.
    When the listpack reaches the maximum number of entries, we shrink it to fit it's used size.
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor@zuiderkwast.se>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -222,11 +226,10 @@
- * On success the new listpack is returned, otherwise an error is returned. */
-unsigned char *lpNew(void) {
-    unsigned char *lp = lp_malloc(LP_HDR_SIZE+1);
+unsigned char *lpNew(size_t capacity) {
+    unsigned char *lp = lp_malloc(capacity > LP_HDR_SIZE+1 ? capacity : LP_HDR_SIZE+1);
     if (lp == NULL) return NULL;
     lpSetTotalBytes(lp,LP_HDR_SIZE+1);
     lpSetNumElements(lp,0);
     lp[LP_HDR_SIZE] = LP_EOF;
     return lp;
 }
 
 /* Free the specified listpack. */
[FUNC] **new** commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -240,9 +246,10 @@
 unsigned char* lpShrinkToFit(unsigned char *lp) {
     size_t size = lpGetTotalBytes(lp);
     if (size < lp_malloc_size(lp)) {
         return lp_realloc(lp, size);
     } else {
         return lp;
     }
 }
 
+/* Stores the integer encoded representation of 'v' in the 'intenc' buffer. */

commit aab479f8cfaa4493f5618ba05cfec0e2b406e77c
Date:   Tue Feb 16 22:17:38 2021 +0800

    Optimize listpack for stream usage to avoid repeated reallocs (#6281)
    
    Avoid repeated reallocs growing the listpack while entries are being added.
    This is done by pre-allocating the listpack to near maximum size, and using
    malloc_size to check if it needs realloc or not.
    When the listpack reaches the maximum number of entries, we shrink it to fit it's used size.
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor@zuiderkwast.se>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -237,0 +241,9 @@
+unsigned char* lpShrinkToFit(unsigned char *lp) {
+    size_t size = lpGetTotalBytes(lp);
+    if (size < lp_malloc_size(lp)) {
+        return lp_realloc(lp, size);
+    } else {
+        return lp;
+    }
+}
+
commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -963,0 +1289,9 @@
+static unsigned char *createList() {
+    unsigned char *lp = lpNew(0);
+    lp = lpAppend(lp, (unsigned char*)mixlist[1], strlen(mixlist[1]));
+    lp = lpAppend(lp, (unsigned char*)mixlist[2], strlen(mixlist[2]));
+    lp = lpPrepend(lp, (unsigned char*)mixlist[0], strlen(mixlist[0]));
+    lp = lpAppend(lp, (unsigned char*)mixlist[3], strlen(mixlist[3]));
+    return lp;
+}
+
commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -963,0 +1298,11 @@
+static unsigned char *createIntList() {
+    unsigned char *lp = lpNew(0);
+    lp = lpAppend(lp, (unsigned char*)intlist[2], strlen(intlist[2]));
+    lp = lpAppend(lp, (unsigned char*)intlist[3], strlen(intlist[3]));
+    lp = lpPrepend(lp, (unsigned char*)intlist[1], strlen(intlist[1]));
+    lp = lpPrepend(lp, (unsigned char*)intlist[0], strlen(intlist[0]));
+    lp = lpAppend(lp, (unsigned char*)intlist[4], strlen(intlist[4]));
+    lp = lpAppend(lp, (unsigned char*)intlist[5], strlen(intlist[5]));
+    return lp;
+}
+
[INCR] **new** commit 78259826cd35fd1b03cf0fce122c6e3e2fd69961
Date:   Wed Aug 24 20:07:43 2022 +0800

    Bump codespell from 2.1.0 to 2.2.1 in /.codespell (#11184)
    
    add a few terms to the white list, and fix a few newly detected typos

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -42,28 +42,28 @@
 robj *createObject(int type, void *ptr) {
     robj *o = zmalloc(sizeof(*o));
     o->type = type;
     o->encoding = OBJ_ENCODING_RAW;
     o->ptr = ptr;
     o->refcount = 1;
 
     /* Set the LRU to the current lruclock (minutes resolution), or
      * alternatively the LFU counter. */
     if (server.maxmemory_policy & MAXMEMORY_FLAG_LFU) {
         o->lru = (LFUGetTimeInMinutes()<<8) | LFU_INIT_VAL;
     } else {
         o->lru = LRU_CLOCK();
     }
     return o;
 }
 
 /* Set a special refcount in the object to make it "shared":
  * incrRefCount and decrRefCount() will test for this special refcount
  * and will not touch the object. This way it is free to access shared
  * objects such as small integers from different threads without any
  * mutex.
  *
- * A common patter to create shared objects:
+ * A common pattern to create shared objects:
  *
  * robj *myobject = makeObjectShared(createObject(...));
  *
  */
[SEC] **new** commit 0c90370e6d71cc68e4d9cc79a0d8b1e768712a5b
Date:   Thu Aug 5 22:56:14 2021 +0300

    Improvements to corrupt payload sanitization (#9321)
    
    Recently we found two issues in the fuzzer tester: #9302 #9285
    After fixing them, more problems surfaced and this PR (as well as #9297) aims to fix them.
    
    Here's a list of the fixes
    - Prevent an overflow when allocating a dict hashtable
    - Prevent OOM when attempting to allocate a huge string
    - Prevent a few invalid accesses in listpack
    - Improve sanitization of listpack first entry
    - Validate integrity of stream consumer groups PEL
    - Validate integrity of stream listpack entry IDs
    - Validate ziplist tail followed by extra data which start with 0xff
    
    Co-authored-by: sundb <sundbcn@gmail.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -119,7 +119,8 @@
 robj *createStringObject(const char *ptr, size_t len) {
     if (len <= OBJ_ENCODING_EMBSTR_SIZE_LIMIT)
         return createEmbeddedStringObject(ptr,len);
     else
         return createRawStringObject(ptr,len);
 }
 
+/* Same as CreateRawStringObject, can return NULL if allocation fails */
commit 0c90370e6d71cc68e4d9cc79a0d8b1e768712a5b
Date:   Thu Aug 5 22:56:14 2021 +0300

    Improvements to corrupt payload sanitization (#9321)
    
    Recently we found two issues in the fuzzer tester: #9302 #9285
    After fixing them, more problems surfaced and this PR (as well as #9297) aims to fix them.
    
    Here's a list of the fixes
    - Prevent an overflow when allocating a dict hashtable
    - Prevent OOM when attempting to allocate a huge string
    - Prevent a few invalid accesses in listpack
    - Improve sanitization of listpack first entry
    - Validate integrity of stream consumer groups PEL
    - Validate integrity of stream listpack entry IDs
    - Validate ziplist tail followed by extra data which start with 0xff
    
    Co-authored-by: sundb <sundbcn@gmail.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -126,0 +127,7 @@
+robj *tryCreateRawStringObject(const char *ptr, size_t len) {
+    sds str = sdstrynewlen(ptr,len);
+    if (!str) return NULL;
+    return createObject(OBJ_STRING, str);
+}
+
+/* Same as createStringObject, can return NULL if allocation fails */
commit 0c90370e6d71cc68e4d9cc79a0d8b1e768712a5b
Date:   Thu Aug 5 22:56:14 2021 +0300

    Improvements to corrupt payload sanitization (#9321)
    
    Recently we found two issues in the fuzzer tester: #9302 #9285
    After fixing them, more problems surfaced and this PR (as well as #9297) aims to fix them.
    
    Here's a list of the fixes
    - Prevent an overflow when allocating a dict hashtable
    - Prevent OOM when attempting to allocate a huge string
    - Prevent a few invalid accesses in listpack
    - Improve sanitization of listpack first entry
    - Validate integrity of stream consumer groups PEL
    - Validate integrity of stream listpack entry IDs
    - Validate ziplist tail followed by extra data which start with 0xff
    
    Co-authored-by: sundb <sundbcn@gmail.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -126,7 +134,14 @@
+robj *tryCreateStringObject(const char *ptr, size_t len) {
+    if (len <= OBJ_ENCODING_EMBSTR_SIZE_LIMIT)
+        return createEmbeddedStringObject(ptr,len);
+    else
+        return tryCreateRawStringObject(ptr,len);
+}
+
 /* Create a string object from a long long value. When possible returns a
  * shared integer object, or at least an integer encoded one.
  *
  * If valueobj is non zero, the function avoids returning a shared
  * integer, because the object is going to be used as value in the Redis key
  * space (for instance when the INCR command is used), so we want LFU/LRU
  * values specific for each key. */
[INCR] **new** commit 0cbe10e892045dc4cba8d1bf3a8193b2cd8506ae
Date:   Sun Nov 6 14:33:28 2022 +0800

    Remove redundant calls to update refcount of shared integers (#11479)
    
    Since they're created with makeObjectShared, then incrRefCount on them is a NOP.
    
    Signed-off-by: Hanif Bin Ariffin <hanif.ariffin.4326@gmail.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -149,28 +149,27 @@
 robj *createStringObjectFromLongLongWithOptions(long long value, int valueobj) {
     robj *o;
 
     if (server.maxmemory == 0 ||
         !(server.maxmemory_policy & MAXMEMORY_FLAG_NO_SHARED_INTEGERS))
     {
         /* If the maxmemory policy permits, we can still return shared integers
          * even if valueobj is true. */
         valueobj = 0;
     }
 
     if (value >= 0 && value < OBJ_SHARED_INTEGERS && valueobj == 0) {
-        incrRefCount(shared.integers[value]);
         o = shared.integers[value];
     } else {
         if (value >= LONG_MIN && value <= LONG_MAX) {
             o = createObject(OBJ_STRING, NULL);
             o->encoding = OBJ_ENCODING_INT;
             o->ptr = (void*)((long)value);
         } else {
             o = createObject(OBJ_STRING,sdsfromlonglong(value));
         }
     }
     return o;
 }
 
 /* Wrapper for createStringObjectFromLongLongWithOptions() always demanding
  * to create a shared object if possible. */
commit 0cbe10e892045dc4cba8d1bf3a8193b2cd8506ae
Date:   Sun Nov 6 14:33:28 2022 +0800

    Remove redundant calls to update refcount of shared integers (#11479)
    
    Since they're created with makeObjectShared, then incrRefCount on them is a NOP.
    
    Signed-off-by: Hanif Bin Ariffin <hanif.ariffin.4326@gmail.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -149,28 +149,27 @@
 robj *createStringObjectFromLongLongWithOptions(long long value, int valueobj) {
     robj *o;
 
     if (server.maxmemory == 0 ||
         !(server.maxmemory_policy & MAXMEMORY_FLAG_NO_SHARED_INTEGERS))
     {
         /* If the maxmemory policy permits, we can still return shared integers
          * even if valueobj is true. */
         valueobj = 0;
     }
 
     if (value >= 0 && value < OBJ_SHARED_INTEGERS && valueobj == 0) {
-        incrRefCount(shared.integers[value]);
         o = shared.integers[value];
     } else {
         if (value >= LONG_MIN && value <= LONG_MAX) {
             o = createObject(OBJ_STRING, NULL);
             o->encoding = OBJ_ENCODING_INT;
             o->ptr = (void*)((long)value);
         } else {
             o = createObject(OBJ_STRING,sdsfromlonglong(value));
         }
     }
     return o;
 }
 
 /* Wrapper for createStringObjectFromLongLongWithOptions() always demanding
  * to create a shared object if possible. */
commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -228,7 +228,7 @@
 robj *createSetObject(void) {
-    dict *d = dictCreate(&setDictType,NULL);
+    dict *d = dictCreate(&setDictType);
     robj *o = createObject(OBJ_SET,d);
     o->encoding = OBJ_ENCODING_HT;
     return o;
 }
 
commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -257,7 +257,7 @@
 robj *createHashObject(void) {
-    unsigned char *zl = ziplistNew();
+    unsigned char *zl = lpNew(0);
     robj *o = createObject(OBJ_HASH, zl);
-    o->encoding = OBJ_ENCODING_ZIPLIST;
+    o->encoding = OBJ_ENCODING_LISTPACK;
     return o;
 }
 
commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -249,11 +249,11 @@
 robj *createZsetObject(void) {
     zset *zs = zmalloc(sizeof(*zs));
     robj *o;
 
-    zs->dict = dictCreate(&zsetDictType,NULL);
+    zs->dict = dictCreate(&zsetDictType);
     zs->zsl = zslCreate();
     o = createObject(OBJ_ZSET,zs);
     o->encoding = OBJ_ENCODING_SKIPLIST;
     return o;
 }
 
commit 3ca6972ecd3e9963f65b9cb1ff050ad60f03563e
Date:   Thu Sep 9 23:18:53 2021 +0800

    Replace all usage of ziplist with listpack for t_zset (#9366)
    
    Part two of implementing #8702 (zset), after #8887.
    
    ## Description of the feature
    Replaced all uses of ziplist with listpack in t_zset, and optimized some of the code to optimize performance.
    
    ## Rdb format changes
    New `RDB_TYPE_ZSET_LISTPACK` rdb type.
    
    ## Rdb loading improvements:
    1) Pre-expansion of dict for validation of duplicate data for listpack and ziplist.
    2) Simplifying the release of empty key objects when RDB loading.
    3) Unify ziplist and listpack data verify methods for zset and hash, and move code to rdb.c.
    
    ## Interface changes
    1) New `zset-max-listpack-entries` config is an alias for `zset-max-ziplist-entries` (same with `zset-max-listpack-value`).
    2) OBJECT ENCODING will return listpack instead of ziplist.
    
    ## Listpack improvements:
    1) Add `lpDeleteRange` and `lpDeleteRangeWithEntry` functions to delete a range of entries from listpack.
    2) Improve the performance of `lpCompare`, converting from string to integer is faster than converting from integer to string.
    3) Replace `snprintf` with `ll2string` to improve performance in converting numbers to strings in `lpGet()`.
    
    ## Zset improvements:
    1) Improve the performance of `zzlFind` method, use `lpFind` instead of `lpCompare` in a loop.
    2) Use `lpDeleteRangeWithEntry` instead of `lpDelete` twice to delete a element of zset.
    
    ## Tests
    1) Add some unittests for `lpDeleteRange` and `lpDeleteRangeWithEntry` function.
    2) Add zset RDB loading test.
    3) Add benchmark test for `lpCompare` and `ziplsitCompare`.
    4) Add empty listpack zset corrupt dump test.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -275,7 +275,7 @@
-robj *createZsetZiplistObject(void) {
-    unsigned char *zl = ziplistNew();
-    robj *o = createObject(OBJ_ZSET,zl);
-    o->encoding = OBJ_ENCODING_ZIPLIST;
+robj *createZsetListpackObject(void) {
+    unsigned char *lp = lpNew(0);
+    robj *o = createObject(OBJ_ZSET,lp);
+    o->encoding = OBJ_ENCODING_LISTPACK;
     return o;
 }
 
commit b60d33c91eef09aea34cecad789c552405737c55
Date:   Sun Nov 20 23:23:54 2022 +0100

    Remove the bucket-cb from dictScan and move dictEntry defrag to dictScanDefrag
    
    This change deletes the dictGetNext and dictGetNextRef functions, so the
    dict API doesn't expose the next field at all.
    
    The bucket function in dictScan is deleted. A separate dictScanDefrag function
    is added which takes a defrag alloc function to defrag-reallocate the dict entries.
    
    "Dirty" code accessing the dict internals in active defrag is removed.
    
    An 'afterReplaceEntry' is added to dictType, which allows the dict user
    to keep the dictEntry metadata up to date after reallocation/defrag/move.
    
    Additionally, for updating the cluster slot-to-key mapping, after a dictEntry
    has been reallocated, we need to know which db a dict belongs to, so we store
    a pointer to the db in a new metadata section in the dict struct, which is
    a new mechanism similar to dictEntry metadata. This adds some complexity but
    provides better isolation.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1161,118 +1161,119 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemoryUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mh->cluster_links = server.stat_cluster_links_memory;
     mem_total += mh->cluster_links;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictMemUsage(db->dict) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictMemUsage(db->expires);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         /* Account for the slot to keys map in cluster mode */
-        mem = dictSize(db->dict) * dictMetadataSize(db->dict);
+        mem = dictSize(db->dict) * dictEntryMetadataSize(db->dict) +
+              dictMetadataSize(db->dict);
         mh->db[mh->num_dbs].overhead_ht_slot_to_keys = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */


[PERF] **new** commit c0267b3fa5808df475dec83c956b9a2bec112b90
Date:   Tue Dec 6 22:26:56 2022 -0800

    Optimize client memory usage tracking operation while client eviction is disabled (#11348)
    
    ## Issue
    During the client input/output buffer processing, the memory usage is
    incrementally updated to keep track of clients going beyond a certain
    threshold `maxmemory-clients` to be evicted. However, this additional
    tracking activity leads to unnecessary CPU cycles wasted when no
    client-eviction is required. It is applicable in two cases.
    
    * `maxmemory-clients` is set to `0` which equates to no client eviction
      (applicable to all clients)
    * `CLIENT NO-EVICT` flag is set to `ON` which equates to a particular
      client not applicable for eviction.
    
    ## Solution
    * Disable client memory usage tracking during the read/write flow when
      `maxmemory-clients` is set to `0` or `client no-evict` is `on`.
      The memory usage is tracked only during the `clientCron` i.e. it gets
      periodically updated.
    * Cleanup the clients from the memory usage bucket when client eviction
      is disabled.
    * When the maxmemory-clients config is enabled or disabled at runtime,
      we immediately update the memory usage buckets for all clients (tested
      scanning 80000 took some 20ms)
    
    Benchmark shown that this can improve performance by about 5% in
    certain situations.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1158,120 +1158,120 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
-     * updateClientMemUsage(). */
+     * updateClientMemoryUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mh->cluster_links = server.stat_cluster_links_memory;
     mem_total += mh->cluster_links;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         /* Account for the slot to keys map in cluster mode */
         mem = dictSize(db->dict) * dictMetadataSize(db->dict);
         mh->db[mh->num_dbs].overhead_ht_slot_to_keys = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[PERF] **new** commit 87789fae0b767e47fef78ee994434554f2bf2f31
Date:   Tue Jan 4 01:14:13 2022 +0800

    Implement Multi Part AOF mechanism to avoid AOFRW overheads. (#9788)
    
    Implement Multi-Part AOF mechanism to avoid overheads during AOFRW.
    Introducing a folder with multiple AOF files tracked by a manifest file.
    
    The main issues with the the original AOFRW mechanism are:
    * buffering of commands that are processed during rewrite (consuming a lot of RAM)
    * freezes of the main process when the AOFRW completes to drain the remaining part of the buffer and fsync it.
    * double disk IO for the data that arrives during AOFRW (had to be written to both the old and new AOF files)
    
    The main modifications of this PR:
    1. Remove the AOF rewrite buffer and related code.
    2. Divide the AOF into multiple files, they are classified as two types, one is the the `BASE` type,
      it represents the full amount of data (Maybe AOF or RDB format) after each AOFRW, there is only
      one `BASE` file at most. The second is `INCR` type, may have more than one. They represent the
      incremental commands since the last AOFRW.
    3. Use a AOF manifest file to record and manage these AOF files mentioned above.
    4. The original configuration of `appendfilename` will be the base part of the new file name, for example:
      `appendonly.aof.1.base.rdb` and `appendonly.aof.2.incr.aof`
    5. Add manifest-related TCL tests, and modified some existing tests that depend on the `appendfilename`
    6. Remove the `aof_rewrite_buffer_length` field in info.
    7. Add `aof-disable-auto-gc` configuration. By default we're automatically deleting HISTORY type AOFs.
      It also gives users the opportunity to preserve the history AOFs. just for testing use now.
    8. Add AOFRW limiting measure. When the AOFRW failures reaches the threshold (3 times now),
      we will delay the execution of the next AOFRW by 1 minute. If the next AOFRW also fails, it will be
      delayed by 2 minutes. The next is 4, 8, 16, the maximum delay is 60 minutes (1 hour). During the limit
      period, we can still use the 'bgrewriteaof' command to execute AOFRW immediately.
    9. Support upgrade (load) data from old version redis.
    10. Add `appenddirname` configuration, as the directory name of the append only files. All AOF files and
      manifest file will be placed in this directory.
    11. Only the last AOF file (BASE or INCR) can be truncated. Otherwise redis will exit even if
      `aof-load-truncated` is enabled.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1140,121 +1140,120 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mh->cluster_links = server.stat_cluster_links_memory;
     mem_total += mh->cluster_links;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
-        mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         /* Account for the slot to keys map in cluster mode */
         mem = dictSize(db->dict) * dictMetadataSize(db->dict);
         mh->db[mh->num_dbs].overhead_ht_slot_to_keys = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit 09c668f2208fef8594cca0675054f926bc7aa7a6
Date:   Sun Jan 2 00:39:59 2022 -0800

    Report slot to keys map size in MEMORY STATS in cluster mode (#10017)
    
    Report slot to keys map size in MEMORY STATS in cluster mode
    Report dictMetadataSize in MEMORY USAGE command as well

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1140,116 +1140,121 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mh->cluster_links = server.stat_cluster_links_memory;
     mem_total += mh->cluster_links;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
+        /* Account for the slot to keys map in cluster mode */
+        mem = dictSize(db->dict) * dictMetadataSize(db->dict);
+        mh->db[mh->num_dbs].overhead_ht_slot_to_keys = mem;
+        mem_total+=mem;
+
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit 1b0968df46f9f838e7daa540675b29073a00cf30
Date:   Tue Dec 21 14:32:42 2021 +0800

    Remove EVAL script verbatim replication, propagation, and deterministic execution logic (#9812)
    
    # Background
    
    The main goal of this PR is to remove relevant logics on Lua script verbatim replication,
    only keeping effects replication logic, which has been set as default since Redis 5.0.
    As a result, Lua in Redis 7.0 would be acting the same as Redis 6.0 with default
    configuration from users' point of view.
    
    There are lots of reasons to remove verbatim replication.
    Antirez has listed some of the benefits in Issue #5292:
    
    >1. No longer need to explain to users side effects into scripts.
        They can do whatever they want.
    >2. No need for a cache about scripts that we sent or not to the slaves.
    >3. No need to sort the output of certain commands inside scripts
        (SMEMBERS and others): this both simplifies and gains speed.
    >4. No need to store scripts inside the RDB file in order to startup correctly.
    >5. No problems about evicting keys during the script execution.
    
    When looking back at Redis 5.0, antirez and core team decided to set the config
    `lua-replicate-commands yes` by default instead of removing verbatim replication
    directly, in case some bad situations happened. 3 years later now before Redis 7.0,
    it's time to remove it formally.
    
    # Changes
    
    - configuration for lua-replicate-commands removed
      - created config file stub for backward compatibility
    - Replication script cache removed
      - this is useless under script effects replication
      - relevant statistics also removed
    - script persistence in RDB files is also removed
    - Propagation of SCRIPT LOAD and SCRIPT FLUSH to replica / AOF removed
    - Deterministic execution logic in scripts removed (i.e. don't run write commands
      after random ones, and sorting output of commands with random order)
      - the flags indicating which commands have non-deterministic results are kept as hints to clients.
    - `redis.replicate_commands()` & `redis.set_repl()` changed
      - now `redis.replicate_commands()` does nothing and return an 1
      - ...and then `redis.set_repl()` can be issued before `redis.replicate_commands()` now
    - Relevant TCL cases adjusted
    - DEBUG lua-always-replicate-commands removed
    
    # Other changes
    - Fix a recent bug comparing CLIENT_ID_AOF to original_client->flags instead of id. (introduced in #9780)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1140,122 +1140,116 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mh->cluster_links = server.stat_cluster_links_memory;
     mem_total += mh->cluster_links;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
-    mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
-        dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
-    if (listLength(server.repl_scriptcache_fifo) > 0) {
-        mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
-            sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
-    }
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit 792afb443211f190b3f8bea15e945661453fbddf
Date:   Thu Dec 16 21:56:59 2021 -0800

     Introduce memory management on cluster link buffers (#9774)
    
    Introduce memory management on cluster link buffers:
     * Introduce a new `cluster-link-sendbuf-limit` config that caps memory usage of cluster bus link send buffers.
     * Introduce a new `CLUSTER LINKS` command that displays current TCP links to/from peers.
     * Introduce a new `mem_cluster_links` field under `INFO` command output, which displays the overall memory usage by all current cluster links.
     * Introduce a new `total_cluster_links_buffer_limit_exceeded` field under `CLUSTER INFO` command output, which displays the accumulated count of cluster links freed due to `cluster-link-sendbuf-limit`.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1140,119 +1140,122 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
+    mh->cluster_links = server.stat_cluster_links_memory;
+    mem_total += mh->cluster_links;
+
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
     mh->functions_caches = functionsMemoryOverhead();
     mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit cbd463175f8b52d594fd4e6b953fa58a5db053c3
Date:   Thu Oct 7 14:41:26 2021 +0300

    Redis Functions - Added redis function unit and Lua engine
    
    Redis function unit is located inside functions.c
    and contains Redis Function implementation:
    1. FUNCTION commands:
      * FUNCTION CREATE
      * FCALL
      * FCALL_RO
      * FUNCTION DELETE
      * FUNCTION KILL
      * FUNCTION INFO
    2. Register engine
    
    In addition, this commit introduce the first engine
    that uses the Redis Function capabilities, the
    Lua engine.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1139,117 +1140,119 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = evalScriptsMemory();
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
+    mh->functions_caches = functionsMemoryOverhead();
+    mem_total+=mh->functions_caches;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit e0cd580aefe13e49df802fec5135e4f22d46e758
Date:   Tue Oct 5 17:03:12 2021 +0300

    Redis Functions - Move Lua related variable into luaCtx struct
    
    The following variable was renamed:
    1. lua_caller                   -> script_caller
    2. lua_time_limit               -> script_time_limit
    3. lua_timedout                 -> script_timedout
    4. lua_oom                      -> script_oom
    5. lua_disable_deny_script      -> script_disable_deny_script
    6. in_eval                      -> in_script
    
    The following variables was moved to lctx under eval.c
    1.  lua
    2.  lua_client
    3.  lua_cur_script
    4.  lua_scripts
    5.  lua_scripts_mem
    6.  lua_replicate_commands
    7.  lua_write_dirty
    8.  lua_random_dirty
    9.  lua_multi_emitted
    10. lua_repl
    11. lua_kill
    12. lua_time_start
    13. lua_time_snapshot
    
    This commit is in a low risk of introducing any issues and it
    is just moving varibales around and not changing any logic.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1139,119 +1139,117 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     /* Replication backlog and replicas share one global replication buffer,
      * only if replication buffer memory is more than the repl backlog setting,
      * we consider the excess as replicas' memory. Otherwise, replication buffer
      * memory is the consumption of repl backlog. */
     if (listLength(server.slaves) &&
         (long long)server.repl_buffer_mem > server.repl_backlog_size)
     {
         mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
         mh->repl_backlog = server.repl_backlog_size;
     } else {
         mh->clients_slaves = 0;
         mh->repl_backlog = server.repl_buffer_mem;
     }
     if (server.repl_backlog) {
         /* The approximate memory of rax tree for indexed blocks. */
         mh->repl_backlog +=
             server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
             raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
     }
     mem_total += mh->repl_backlog;
     mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_normal;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
-    mem = server.lua_scripts_mem;
-    mem += dictSize(server.lua_scripts) * sizeof(dictEntry) +
-        dictSlots(server.lua_scripts) * sizeof(dictEntry*);
+    mem = evalScriptsMemory();
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[PERF] **new** commit c1718f9d862267bc44b2a326cdc8cb1ca5b81a39
Date:   Mon Oct 25 14:24:31 2021 +0800

    Replication backlog and replicas use one global shared replication buffer (#9166)
    
    ## Background
    For redis master, one replica uses one copy of replication buffer, that is a big waste of memory,
    more replicas more waste, and allocate/free memory for every reply list also cost much.
    If we set client-output-buffer-limit small and write traffic is heavy, master may disconnect with
    replicas and can't finish synchronization with replica. If we set  client-output-buffer-limit big,
    master may be OOM when there are many replicas that separately keep much memory.
    Because replication buffers of different replica client are the same, one simple idea is that
    all replicas only use one replication buffer, that will effectively save memory.
    
    Since replication backlog content is the same as replicas' output buffer, now we
    can discard replication backlog memory and use global shared replication buffer
    to implement replication backlog mechanism.
    
    ## Implementation
    I create one global "replication buffer" which contains content of replication stream.
    The structure of "replication buffer" is similar to the reply list that exists in every client.
    But the node of list is `replBufBlock`, which has `id, repl_offset, refcount` fields.
    ```c
    /* Replication buffer blocks is the list of replBufBlock.
     *
     * +--------------+       +--------------+       +--------------+
     * | refcount = 1 |  ...  | refcount = 0 |  ...  | refcount = 2 |
     * +--------------+       +--------------+       +--------------+
     *      |                                            /       \
     *      |                                           /         \
     *      |                                          /           \
     *  Repl Backlog                               Replia_A      Replia_B
     *
     * Each replica or replication backlog increments only the refcount of the
     * 'ref_repl_buf_node' which it points to. So when replica walks to the next
     * node, it should first increase the next node's refcount, and when we trim
     * the replication buffer nodes, we remove node always from the head node which
     * refcount is 0. If the refcount of the head node is not 0, we must stop
     * trimming and never iterate the next node. */
    
    /* Similar with 'clientReplyBlock', it is used for shared buffers between
     * all replica clients and replication backlog. */
    typedef struct replBufBlock {
        int refcount;           /* Number of replicas or repl backlog using. */
        long long id;           /* The unique incremental number. */
        long long repl_offset;  /* Start replication offset of the block. */
        size_t size, used;
        char buf[];
    } replBufBlock;
    ```
    So now when we feed replication stream into replication backlog and all replicas, we only need
    to feed stream into replication buffer `feedReplicationBuffer`. In this function, we set some fields of
    replication backlog and replicas to references of the global replication buffer blocks. And we also
    need to check replicas' output buffer limit to free if exceeding `client-output-buffer-limit`, and trim
    replication backlog if exceeding `repl-backlog-size`.
    
    When sending reply to replicas, we also need to iterate replication buffer blocks and send its
    content, when totally sending one block for replica, we decrease current node count and
    increase the next current node count, and then free the block which reference is 0 from the
    head of replication buffer blocks.
    
    Since now we use linked list to manage replication backlog, it may cost much time for iterating
    all linked list nodes to find corresponding replication buffer node. So we create a rax tree to
    store some nodes  for index, but to avoid rax tree occupying too much memory, i record
    one per 64 nodes for index.
    
    Currently, to make partial resynchronization as possible as much, we always let replication
    backlog as the last reference of replication buffer blocks, backlog size may exceeds our setting
    if slow replicas that reference vast replication buffer blocks, and this method doesn't increase
    memory usage since they share replication buffer. To avoid freezing server for freeing unreferenced
    replication buffer blocks when we need to trim backlog for exceeding backlog size setting,
    we trim backlog incrementally (free 64 blocks per call now), and make it faster in
    `beforeSleep` (free 640 blocks).
    
    ### Other changes
    - `mem_total_replication_buffers`: we add this field in INFO command, it means the total
      memory of replication buffers used.
    - `mem_clients_slaves`:  now even replica is slow to replicate, and its output buffer memory
      is not 0, but it still may be 0, since replication backlog and replicas share one global replication
      buffer, only if replication buffer memory is more than the repl backlog setting size, we consider
      the excess as replicas' memory. Otherwise, we think replication buffer memory is the consumption
      of repl backlog.
    - Key eviction
      Since all replicas and replication backlog share global replication buffer, we think only the
      part of exceeding backlog size the extra separate consumption of replicas.
      Because we trim backlog incrementally in the background, backlog size may exceeds our
      setting if slow replicas that reference vast replication buffer blocks disconnect.
      To avoid massive eviction loop, we don't count the delayed freed replication backlog into
      used memory even if there are no replicas, i.e. we also regard this memory as replicas's memory.
    - `client-output-buffer-limit` check for replica clients
      It doesn't make sense to set the replica clients output buffer limit lower than the repl-backlog-size
      config (partial sync will succeed and then replica will get disconnected). Such a configuration is
      ignored (the size of repl-backlog-size will be used). This doesn't have memory consumption
      implications since the replica client will share the backlog buffers memory.
    - Drop replication backlog after loading data if needed
      We always create replication backlog if server is a master, we need it because we put DELs in
      it when loading expired keys in RDB, but if RDB doesn't have replication info or there is no rdb,
      it is not possible to support partial resynchronization, to avoid extra memory of replication backlog,
      we drop it.
    - Multi IO threads
     Since all replicas and replication backlog use global replication buffer,  if I/O threads are enabled,
      to guarantee data accessing thread safe, we must let main thread handle sending the output buffer
      to all replicas. But before, other IO threads could handle sending output buffer of all replicas.
    
    ## Other optimizations
    This solution resolve some other problem:
    - When replicas disconnect with master since of out of output buffer limit, releasing the output
      buffer of replicas may freeze server if we set big `client-output-buffer-limit` for replicas, but now,
      it doesn't cause freezing.
    - This implementation may mitigate reply list copy cost time(also freezes server) when one replication
      has huge reply buffer and another replica can copy buffer for full synchronization. now, we just copy
      reference info, it is very light.
    - If we set replication backlog size big, it also may cost much time to copy replication backlog into
      replica's output buffer. But this commit eliminates this problem.
    - Resizing replication backlog size doesn't empty current replication backlog content.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1146,105 +1146,119 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
-    mem = 0;
-    if (server.repl_backlog)
-        mem += zmalloc_size(server.repl_backlog);
-    mh->repl_backlog = mem;
-    mem_total += mem;
+    /* Replication backlog and replicas share one global replication buffer,
+     * only if replication buffer memory is more than the repl backlog setting,
+     * we consider the excess as replicas' memory. Otherwise, replication buffer
+     * memory is the consumption of repl backlog. */
+    if (listLength(server.slaves) &&
+        (long long)server.repl_buffer_mem > server.repl_backlog_size)
+    {
+        mh->clients_slaves = server.repl_buffer_mem - server.repl_backlog_size;
+        mh->repl_backlog = server.repl_backlog_size;
+    } else {
+        mh->clients_slaves = 0;
+        mh->repl_backlog = server.repl_buffer_mem;
+    }
+    if (server.repl_backlog) {
+        /* The approximate memory of rax tree for indexed blocks. */
+        mh->repl_backlog +=
+            server.repl_backlog->blocks_index->numnodes * sizeof(raxNode) +
+            raxSize(server.repl_backlog->blocks_index) * sizeof(void*);
+    }
+    mem_total += mh->repl_backlog;
+    mem_total += mh->clients_slaves;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * updateClientMemUsage(). */
-    mh->clients_slaves = server.stat_clients_type_memory[CLIENT_TYPE_SLAVE];
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
-    mem_total += mh->clients_slaves;
     mem_total += mh->clients_normal;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = server.lua_scripts_mem;
     mem += dictSize(server.lua_scripts) * sizeof(dictEntry) +
         dictSlots(server.lua_scripts) * sizeof(dictEntry*);
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[FUNC] **new** commit 2753429c99425e3d0216cba79e0e61192975f252
Date:   Thu Sep 23 14:02:16 2021 +0300

    Client eviction (#8687)
    
    ### Description
    A mechanism for disconnecting clients when the sum of all connected clients is above a
    configured limit. This prevents eviction or OOM caused by accumulated used memory
    between all clients. It's a complimentary mechanism to the `client-output-buffer-limit`
    mechanism which takes into account not only a single client and not only output buffers
    but rather all memory used by all clients.
    
    #### Design
    The general design is as following:
    * We track memory usage of each client, taking into account all memory used by the
      client (query buffer, output buffer, parsed arguments, etc...). This is kept up to date
      after reading from the socket, after processing commands and after writing to the socket.
    * Based on the used memory we sort all clients into buckets. Each bucket contains all
      clients using up up to x2 memory of the clients in the bucket below it. For example up
      to 1m clients, up to 2m clients, up to 4m clients, ...
    * Before processing a command and before sleep we check if we're over the configured
      limit. If we are we start disconnecting clients from larger buckets downwards until we're
      under the limit.
    
    #### Config
    `maxmemory-clients` max memory all clients are allowed to consume, above this threshold
    we disconnect clients.
    This config can either be set to 0 (meaning no limit), a size in bytes (possibly with MB/GB
    suffix), or as a percentage of `maxmemory` by using the `%` suffix (e.g. setting it to `10%`
    would mean 10% of `maxmemory`).
    
    #### Important code changes
    * During the development I encountered yet more situations where our io-threads access
      global vars. And needed to fix them. I also had to handle keeps the clients sorted into the
      memory buckets (which are global) while their memory usage changes in the io-thread.
      To achieve this I decided to simplify how we check if we're in an io-thread and make it
      much more explicit. I removed the `CLIENT_PENDING_READ` flag used for checking
      if the client is in an io-thread (it wasn't used for anything else) and just used the global
      `io_threads_op` variable the same way to check during writes.
    * I optimized the cleanup of the client from the `clients_pending_read` list on client freeing.
      We now store a pointer in the `client` struct to this list so we don't need to search in it
      (`pending_read_list_node`).
    * Added `evicted_clients` stat to `INFO` command.
    * Added `CLIENT NO-EVICT ON|OFF` sub command to exclude a specific client from the
      client eviction mechanism. Added corrosponding 'e' flag in the client info string.
    * Added `multi-mem` field in the client info string to show how much memory is used up
      by buffered multi commands.
    * Client `tot-mem` now accounts for buffered multi-commands, pubsub patterns and
      channels (partially), tracking prefixes (partially).
    * CLIENT_CLOSE_ASAP flag is now handled in a new `beforeNextClient()` function so
      clients will be disconnected between processing different clients and not only before sleep.
      This new function can be used in the future for work we want to do outside the command
      processing loop but don't want to wait for all clients to be processed before we get to it.
      Specifically I wanted to handle output-buffer-limit related closing before we process client
      eviction in case the two race with each other.
    * Added a `DEBUG CLIENT-EVICTION` command to print out info about the client eviction
      buckets.
    * Each client now holds a pointer to the client eviction memory usage bucket it belongs to
      and listNode to itself in that bucket for quick removal.
    * Global `io_threads_op` variable now can contain a `IO_THREADS_OP_IDLE` value
      indicating no io-threading is currently being executed.
    * In order to track memory used by each clients in real-time we can't rely on updating
      these stats in `clientsCron()` alone anymore. So now I call `updateClientMemUsage()`
      (used to be `clientsCronTrackClientsMemUsage()`) after command processing, after
      writing data to pubsub clients, after writing the output buffer and after reading from the
      socket (and maybe other places too). The function is written to be fast.
    * Clients are evicted if needed (with appropriate log line) in `beforeSleep()` and before
      processing a command (before performing oom-checks and key-eviction).
    * All clients memory usage buckets are grouped as follows:
      * All clients using less than 64k.
      * 64K..128K
      * 128K..256K
      * ...
      * 2G..4G
      * All clients using 4g and up.
    * Added client-eviction.tcl with a bunch of tests for the new mechanism.
    * Extended maxmemory.tcl to test the interaction between maxmemory and
      maxmemory-clients settings.
    * Added an option to flag a numeric configuration variable as a "percent", this means that
      if we encounter a '%' after the number in the config file (or config set command) we
      consider it as valid. Such a number is store internally as a negative value. This way an
      integer value can be interpreted as either a percent (negative) or absolute value (positive).
      This is useful for example if some numeric configuration can optionally be set to a percentage
      of something else.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -1146,105 +1146,105 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     mem = 0;
     if (server.repl_backlog)
         mem += zmalloc_size(server.repl_backlog);
     mh->repl_backlog = mem;
     mem_total += mem;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
-     * clientsCronTrackClientsMemUsage(). */
+     * updateClientMemUsage(). */
     mh->clients_slaves = server.stat_clients_type_memory[CLIENT_TYPE_SLAVE];
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_slaves;
     mem_total += mh->clients_normal;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
         mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = server.lua_scripts_mem;
     mem += dictSize(server.lua_scripts) * sizeof(dictEntry) +
         dictSlots(server.lua_scripts) * sizeof(dictEntry*);
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */

[PERF] **new** commit 58a03eca6705378ae8d29ffcc9d59794132acb14
Date:   Sun May 30 16:57:36 2021 +0800

    Make full use of aofrwblock's buf (#8975)
    
    Make aof rewrite buffer memory size more accurate, before, there may be 20%
    deviation with its real memory usage.
    
    The implication are both lower memory usage, and also a more accurate INFO.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -966,105 +966,105 @@
 struct redisMemOverhead *getMemoryOverheadData(void) {
     int j;
     size_t mem_total = 0;
     size_t mem = 0;
     size_t zmalloc_used = zmalloc_used_memory();
     struct redisMemOverhead *mh = zcalloc(sizeof(*mh));
 
     mh->total_allocated = zmalloc_used;
     mh->startup_allocated = server.initial_memory_usage;
     mh->peak_allocated = server.stat_peak_memory;
     mh->total_frag =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.zmalloc_used;
     mh->total_frag_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.zmalloc_used;
     mh->allocator_frag =
         (float)server.cron_malloc_stats.allocator_active / server.cron_malloc_stats.allocator_allocated;
     mh->allocator_frag_bytes =
         server.cron_malloc_stats.allocator_active - server.cron_malloc_stats.allocator_allocated;
     mh->allocator_rss =
         (float)server.cron_malloc_stats.allocator_resident / server.cron_malloc_stats.allocator_active;
     mh->allocator_rss_bytes =
         server.cron_malloc_stats.allocator_resident - server.cron_malloc_stats.allocator_active;
     mh->rss_extra =
         (float)server.cron_malloc_stats.process_rss / server.cron_malloc_stats.allocator_resident;
     mh->rss_extra_bytes =
         server.cron_malloc_stats.process_rss - server.cron_malloc_stats.allocator_resident;
 
     mem_total += server.initial_memory_usage;
 
     mem = 0;
     if (server.repl_backlog)
         mem += zmalloc_size(server.repl_backlog);
     mh->repl_backlog = mem;
     mem_total += mem;
 
     /* Computing the memory used by the clients would be O(N) if done
      * here online. We use our values computed incrementally by
      * clientsCronTrackClientsMemUsage(). */
     mh->clients_slaves = server.stat_clients_type_memory[CLIENT_TYPE_SLAVE];
     mh->clients_normal = server.stat_clients_type_memory[CLIENT_TYPE_MASTER]+
                          server.stat_clients_type_memory[CLIENT_TYPE_PUBSUB]+
                          server.stat_clients_type_memory[CLIENT_TYPE_NORMAL];
     mem_total += mh->clients_slaves;
     mem_total += mh->clients_normal;
 
     mem = 0;
     if (server.aof_state != AOF_OFF) {
         mem += sdsZmallocSize(server.aof_buf);
-        mem += aofRewriteBufferSize();
+        mem += aofRewriteBufferMemoryUsage();
     }
     mh->aof_buffer = mem;
     mem_total+=mem;
 
     mem = server.lua_scripts_mem;
     mem += dictSize(server.lua_scripts) * sizeof(dictEntry) +
         dictSlots(server.lua_scripts) * sizeof(dictEntry*);
     mem += dictSize(server.repl_scriptcache_dict) * sizeof(dictEntry) +
         dictSlots(server.repl_scriptcache_dict) * sizeof(dictEntry*);
     if (listLength(server.repl_scriptcache_fifo) > 0) {
         mem += listLength(server.repl_scriptcache_fifo) * (sizeof(listNode) +
             sdsZmallocSize(listNodeValue(listFirst(server.repl_scriptcache_fifo))));
     }
     mh->lua_caches = mem;
     mem_total+=mem;
 
     for (j = 0; j < server.dbnum; j++) {
         redisDb *db = server.db+j;
         long long keyscount = dictSize(db->dict);
         if (keyscount==0) continue;
 
         mh->total_keys += keyscount;
         mh->db = zrealloc(mh->db,sizeof(mh->db[0])*(mh->num_dbs+1));
         mh->db[mh->num_dbs].dbid = j;
 
         mem = dictSize(db->dict) * sizeof(dictEntry) +
               dictSlots(db->dict) * sizeof(dictEntry*) +
               dictSize(db->dict) * sizeof(robj);
         mh->db[mh->num_dbs].overhead_ht_main = mem;
         mem_total+=mem;
 
         mem = dictSize(db->expires) * sizeof(dictEntry) +
               dictSlots(db->expires) * sizeof(dictEntry*);
         mh->db[mh->num_dbs].overhead_ht_expires = mem;
         mem_total+=mem;
 
         mh->num_dbs++;
     }
 
     mh->overhead_total = mem_total;
     mh->dataset = zmalloc_used - mem_total;
     mh->peak_perc = (float)zmalloc_used*100/mh->peak_allocated;
 
     /* Metrics computed after subtracting the startup memory from
      * the total memory. */
     size_t net_usage = 1;
     if (zmalloc_used > mh->startup_allocated)
         net_usage = zmalloc_used - mh->startup_allocated;
     mh->dataset_perc = (float)mh->dataset*100/net_usage;
     mh->bytes_per_key = mh->total_keys ? (net_usage / mh->total_keys) : 0;
 
     return mh;
 }
 
 /* Helper for "MEMORY allocator-stats", used as a callback for the jemalloc
  * stats output. */
[NR] **new** commit b2061de2e713d304ab8e845162888cca47ee32d3
Date:   Wed Jun 1 13:04:22 2022 +0300

    Fix broken protocol in MISCONF error, RM_Yield bugs, RM_Call(EVAL) OOM check bug, and new RM_Call checks. (#10786)
    
    * Fix broken protocol when redis can't persist to RDB (general commands, not
      modules), excessive newline. regression of #10372 (7.0 RC3)
    * Fix broken protocol when Redis can't persist to AOF (modules and
      scripts), missing newline.
    * Fix bug in OOM check of EVAL scripts called from RM_Call.
      set the cached OOM state for scripts before executing module commands too,
      so that it can serve scripts that are executed by modules.
      i.e. in the past EVAL executed by RM_Call could have either falsely
      fail or falsely succeeded because of a wrong cached OOM state flag.
    * Fix bugs with RM_Yield:
      1. SHUTDOWN should only accept the NOSAVE mode
      2. Avoid eviction during yield command processing.
      3. Avoid processing master client commands while yielding from another client
    * Add new two more checks to RM_Call script mode.
      1. READONLY You can't write against a read only replica
      2. MASTERDOWN Link with MASTER is down and `replica-serve-stale-data` is set to `no`
    * Add new RM_Call flag to let redis automatically refuse `deny-oom` commands
      while over the memory limit.
    * Add tests to cover various errors from Scripts, Modules, Modules
      calling scripts, and Modules calling commands in script mode.
    
    Add tests:
    * Looks like the MISCONF error was completely uncovered by the tests,
      add tests for it, including from scripts, and modules
    * Add tests for NOREPLICAS from scripts
    * Add tests for the various errors in module RM_Call, including RM_Call that
      calls EVAL, and RM_call in "eval mode". that includes:
      NOREPLICAS, READONLY, MASTERDOWN, MISCONF

diff --git a/src/call_reply.c b/src/call_reply.c
--- a/src/call_reply.c
+++ b/src/call_reply.c
@@ -517,15 +517,18 @@
 CallReply *callReplyCreate(sds reply, list *deferred_error_list, void *private_data) {
     CallReply *res = zmalloc(sizeof(*res));
     res->flags = REPLY_FLAG_ROOT;
     res->original_proto = reply;
     res->proto = reply;
     res->proto_len = sdslen(reply);
     res->private_data = private_data;
     res->attribute = NULL;
     res->deferred_error_list = deferred_error_list;
     return res;
 }
 
 /* Create a new CallReply struct from the reply blob representing an error message.
  * Automatically creating deferred_error_list and set a copy of the reply in it.
- * Refer to callReplyCreate for detailed explanation. */
+ * Refer to callReplyCreate for detailed explanation.
+ * Reply string can come in one of two forms:
+ * 1. A protocol reply starting with "-CODE" and ending with "\r\n"
+ * 2. A plain string, in which case this function adds the protocol header and footer. */

[NR] **new** commit f3855a093049bccf530c93a6c386e826bd58e90e
Date:   Tue Mar 22 14:13:28 2022 +0200

    Add new RM_Call flags for script mode, no writes, and error replies. (#10372)
    
    The PR extends RM_Call with 3 new capabilities using new flags that
    are given to RM_Call as part of the `fmt` argument.
    It aims to assist modules that are getting a list of commands to be
    executed from the user (not hard coded as part of the module logic),
    think of a module that implements a new scripting language...
    
    * `S` - Run the command in a script mode, this means that it will raise an
      error if a command which are not allowed inside a script (flaged with the
      `deny-script` flag) is invoked (like SHUTDOWN). In addition, on script mode,
      write commands are not allowed if there is not enough good replicas (as
      configured with `min-replicas-to-write`) and/or a disk error happened.
    
    * `W` - no writes mode, Redis will reject any command that is marked with `write`
      flag. Again can be useful to modules that implement a new scripting language
      and wants to prevent any write commands.
    
    * `E` - Return errors as RedisModuleCallReply. Today the errors that happened
      before the command was invoked (like unknown commands or acl error) return
      a NULL reply and set errno. This might be missing important information about
      the failure and it is also impossible to just pass the error to the user using
      RM_ReplyWithCallReply. This new flag allows you to get a RedisModuleCallReply
      object with the relevant error message and treat it as if it was an error that was
      raised by the command invocation.
    
    Tests were added to verify the new code paths.
    
    In addition small refactoring was done to share some code between modules,
    scripts, and `processCommand` function:
    1. `getAclErrorMessage` was added to `acl.c` to unified to log message extraction
      from the acl result
    2. `checkGoodReplicasStatus` was added to `replication.c` to check the status of
      good replicas. It is used on `scriptVerifyWriteCommandAllow`, `RM_Call`, and
      `processCommand`.
    3. `writeCommandsGetDiskErrorMessage` was added to `server.c` to get the error
      message on persistence failure. Again it is used on `scriptVerifyWriteCommandAllow`,
      `RM_Call`, and `processCommand`.

diff --git a/src/call_reply.c b/src/call_reply.c
--- a/src/call_reply.c
+++ b/src/call_reply.c
@@ -517,11 +517,15 @@
 CallReply *callReplyCreate(sds reply, list *deferred_error_list, void *private_data) {
     CallReply *res = zmalloc(sizeof(*res));
     res->flags = REPLY_FLAG_ROOT;
     res->original_proto = reply;
     res->proto = reply;
     res->proto_len = sdslen(reply);
     res->private_data = private_data;
     res->attribute = NULL;
     res->deferred_error_list = deferred_error_list;
     return res;
 }
+
+/* Create a new CallReply struct from the reply blob representing an error message.
+ * Automatically creating deferred_error_list and set a copy of the reply in it.
+ * Refer to callReplyCreate for detailed explanation. */

[CORR] **new** commit b099889a3a6dccf5243135f0611b8cdb11cab7b8
Date:   Sun Feb 13 18:37:32 2022 +0200

    Fix and improve module error reply statistics (#10278)
    
    This PR handles several aspects
    1. Calls to RM_ReplyWithError from thread safe contexts don't violate thread safety.
    2. Errors returning from RM_Call to the module aren't counted in the statistics (they
      might be handled silently by the module)
    3. When a module propagates a reply it got from RM_Call to it's client, then the error
      statistics are counted.
    
    This is done by:
    1. When appending an error reply to the output buffer, we avoid updating the global
      error statistics, instead we cache that error in a deferred list in the client struct.
    2. When creating a RedisModuleCallReply object, the deferred error list is moved from
      the client into that object.
    3. when a module calls RM_ReplyWithCallReply we copy the deferred replies to the dest
      client (if that's a real client, then that's when the error statistics are updated to the server)
    
    Note about RM_ReplyWithCallReply: if the original reply had an array with errors, and the module
    replied with just a portion of the original reply, and not the entire reply, the errors are currently not
    propagated and the errors stats will not get propagated.
    
    Fix #10180

diff --git a/src/call_reply.c b/src/call_reply.c
--- a/src/call_reply.c
+++ b/src/call_reply.c
@@ -507,10 +517,11 @@
-CallReply *callReplyCreate(sds reply, void *private_data) {
+CallReply *callReplyCreate(sds reply, list *deferred_error_list, void *private_data) {
     CallReply *res = zmalloc(sizeof(*res));
     res->flags = REPLY_FLAG_ROOT;
     res->original_proto = reply;
     res->proto = reply;
     res->proto_len = sdslen(reply);
     res->private_data = private_data;
     res->attribute = NULL;
+    res->deferred_error_list = deferred_error_list;
     return res;
 }

[FUNC] **new** commit 2237131e15c84689f2cd990455111e222f5164f6
Date:   Wed Aug 4 16:28:07 2021 +0300

    Unified Lua and modules reply parsing and added RESP3 support to RM_Call (#9202)
    
    ## Current state
    1. Lua has its own parser that handles parsing `reds.call` replies and translates them
      to Lua objects that can be used by the user Lua code. The parser partially handles
      resp3 (missing big number, verbatim, attribute, ...)
    2. Modules have their own parser that handles parsing `RM_Call` replies and translates
      them to RedisModuleCallReply objects. The parser does not support resp3.
    
    In addition, in the future, we want to add Redis Function (#8693) that will probably
    support more languages. At some point maintaining so many parsers will stop
    scaling (bug fixes and protocol changes will need to be applied on all of them).
    We will probably end up with different parsers that support different parts of the
    resp protocol (like we already have today with Lua and modules)
    
    ## PR Changes
    This PR attempt to unified the reply parsing of Lua and modules (and in the future
    Redis Function) by introducing a new parser unit (`resp_parser.c`). The new parser
    handles parsing the reply and calls different callbacks to allow the users (another
    unit that uses the parser, i.e, Lua, modules, or Redis Function) to analyze the reply.
    
    ### Lua API Additions
    The code that handles reply parsing on `scripting.c` was removed. Instead, it uses
    the resp_parser to parse and create a Lua object out of the reply. As mentioned
    above the Lua parser did not handle parsing big numbers, verbatim, and attribute.
    The new parser can handle those and so Lua also gets it for free.
    Those are translated to Lua objects in the following way:
    1. Big Number - Lua table `{'big_number':'<str representation for big number>'}`
    2. Verbatim - Lua table `{'verbatim_string':{'format':'<verbatim format>', 'string':'<verbatim string value>'}}`
    3. Attribute - currently ignored and not expose to the Lua parser, another issue will be open to decide how to expose it.
    
    Tests were added to check resp3 reply parsing on Lua
    
    ### Modules API Additions
    The reply parsing code on `module.c` was also removed and the new resp_parser is used instead.
    In addition, the RedisModuleCallReply was also extracted to a separate unit located on `call_reply.c`
    (in the future, this unit will also be used by Redis Function). A nice side effect of unified parsing is
    that modules now also support resp3. Resp3 can be enabled by giving `3` as a parameter to the
    fmt argument of `RM_Call`. It is also possible to give `0`, which will indicate an auto mode. i.e, Redis
    will automatically chose the reply protocol base on the current client set on the RedisModuleCtx
    (this mode will mostly be used when the module want to pass the reply to the client as is).
    In addition, the following RedisModuleAPI were added to allow analyzing resp3 replies:
    
    * New RedisModuleCallReply types:
       * `REDISMODULE_REPLY_MAP`
       * `REDISMODULE_REPLY_SET`
       * `REDISMODULE_REPLY_BOOL`
       * `REDISMODULE_REPLY_DOUBLE`
       * `REDISMODULE_REPLY_BIG_NUMBER`
       * `REDISMODULE_REPLY_VERBATIM_STRING`
       * `REDISMODULE_REPLY_ATTRIBUTE`
    
    * New RedisModuleAPI:
       * `RedisModule_CallReplyDouble` - getting double value from resp3 double reply
       * `RedisModule_CallReplyBool` - getting boolean value from resp3 boolean reply
       * `RedisModule_CallReplyBigNumber` - getting big number value from resp3 big number reply
       * `RedisModule_CallReplyVerbatim` - getting format and value from resp3 verbatim reply
       * `RedisModule_CallReplySetElement` - getting element from resp3 set reply
       * `RedisModule_CallReplyMapElement` - getting key and value from resp3 map reply
       * `RedisModule_CallReplyAttribute` - getting a reply attribute
       * `RedisModule_CallReplyAttributeElement` - getting key and value from resp3 attribute reply
    
    * New context flags:
       * `REDISMODULE_CTX_FLAGS_RESP3` - indicate that the client is using resp3
    
    Tests were added to check the new RedisModuleAPI
    
    ### Modules API Changes
    * RM_ReplyWithCallReply might return REDISMODULE_ERR if the given CallReply is in resp3
      but the client expects resp2. This is not a breaking change because in order to get a resp3
      CallReply one needs to specifically specify `3` as a parameter to the fmt argument of
      `RM_Call` (as mentioned above).
    
    Tests were added to check this change
    
    ### More small Additions
    * Added `debug set-disable-deny-scripts` that allows to turn on and off the commands no-script
    flag protection. This is used by the Lua resp3 tests so it will be possible to run `debug protocol`
    and check the resp3 parsing code.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>
    Co-authored-by: Yossi Gottlieb <yossigo@gmail.com>

diff --git a/src/call_reply.c b/src/call_reply.c
--- /dev/null
+++ b/src/call_reply.c
@@ -0,0 +507,10 @@
+CallReply *callReplyCreate(sds reply, void *private_data) {
+    CallReply *res = zmalloc(sizeof(*res));
+    res->flags = REPLY_FLAG_ROOT;
+    res->original_proto = reply;
+    res->proto = reply;
+    res->proto_len = sdslen(reply);
+    res->private_data = private_data;
+    res->attribute = NULL;
+    return res;
+}
[PERF] **new** commit 47c493e070c8ac59ccc34d694700bca8ec517fbc
Date:   Tue Nov 1 22:26:44 2022 -0400

    Re-design cluster link send buffer to improve memory management (#11343)
    
    Re-design cluster link send queue to improve memory management

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -806,19 +833,23 @@
 clusterLink *createClusterLink(clusterNode *node) {
     clusterLink *link = zmalloc(sizeof(*link));
     link->ctime = mstime();
-    link->sndbuf = sdsempty();
+    link->send_msg_queue = listCreate();
+    listSetFreeMethod(link->send_msg_queue, clusterMsgSendBlockDecrRefCount);
+    link->head_msg_send_offset = 0;
+    link->send_msg_queue_mem = sizeof(list);
     link->rcvbuf = zmalloc(link->rcvbuf_alloc = RCVBUF_INIT_LEN);
     link->rcvbuf_len = 0;
+    server.stat_cluster_links_memory += link->rcvbuf_alloc + link->send_msg_queue_mem;
     link->conn = NULL;
     link->node = node;
     /* Related node can only possibly be known at link creation time if this is an outbound link */
     link->inbound = (node == NULL);
     if (!link->inbound) {
         node->link = link;
     }
     return link;
 }
 
 /* Free a cluster link, but does not free the associated node of course.
  * This function will just make sure that the original node associated
  * with this link will have the 'link' field set to NULL. */

commit 792afb443211f190b3f8bea15e945661453fbddf
Date:   Thu Dec 16 21:56:59 2021 -0800

     Introduce memory management on cluster link buffers (#9774)
    
    Introduce memory management on cluster link buffers:
     * Introduce a new `cluster-link-sendbuf-limit` config that caps memory usage of cluster bus link send buffers.
     * Introduce a new `CLUSTER LINKS` command that displays current TCP links to/from peers.
     * Introduce a new `mem_cluster_links` field under `INFO` command output, which displays the overall memory usage by all current cluster links.
     * Introduce a new `total_cluster_links_buffer_limit_exceeded` field under `CLUSTER INFO` command output, which displays the accumulated count of cluster links freed due to `cluster-link-sendbuf-limit`.

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -708,14 +712,19 @@
 clusterLink *createClusterLink(clusterNode *node) {
     clusterLink *link = zmalloc(sizeof(*link));
     link->ctime = mstime();
     link->sndbuf = sdsempty();
     link->rcvbuf = zmalloc(link->rcvbuf_alloc = RCVBUF_INIT_LEN);
     link->rcvbuf_len = 0;
-    link->node = node;
     link->conn = NULL;
+    link->node = node;
+    /* Related node can only possibly be known at link creation time if this is an outbound link */
+    link->inbound = (node == NULL);
+    if (!link->inbound) {
+        node->link = link;
+    }
     return link;
 }
 
 /* Free a cluster link, but does not free the associated node of course.
  * This function will just make sure that the original node associated
  * with this link will have the 'link' field set to NULL. */
commit b60d33c91eef09aea34cecad789c552405737c55
Date:   Sun Nov 20 23:23:54 2022 +0100

    Remove the bucket-cb from dictScan and move dictEntry defrag to dictScanDefrag
    
    This change deletes the dictGetNext and dictGetNextRef functions, so the
    dict API doesn't expose the next field at all.
    
    The bucket function in dictScan is deleted. A separate dictScanDefrag function
    is added which takes a defrag alloc function to defrag-reallocate the dict entries.
    
    "Dirty" code accessing the dict internals in active defrag is removed.
    
    An 'afterReplaceEntry' is added to dictType, which allows the dict user
    to keep the dictEntry metadata up to date after reallocation/defrag/move.
    
    Additionally, for updating the cluster slot-to-key mapping, after a dictEntry
    has been reallocated, we need to know which db a dict belongs to, so we store
    a pointer to the db in a new metadata section in the dict struct, which is
    a new mechanism similar to dictEntry metadata. This adds some complexity but
    provides better isolation.

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -7348,5 +7350,7 @@
 void slotToKeyInit(redisDb *db) {
     db->slots_to_keys = zcalloc(sizeof(clusterSlotToKeyMapping));
+    clusterDictMetadata *dictmeta = dictMetadata(db->dict);
+    dictmeta->db = db;
 }
 
 /* Empty slots-keys map of given db. */

[FUNC] **new** commit 91d0c758e5453644bb4e784a2af86033ccb971fc
Date:   Thu Nov 4 09:46:50 2021 +0100

    Replica keep serving data during repl-diskless-load=swapdb for better availability (#9323)
    
    For diskless replication in swapdb mode, considering we already spend replica memory
    having a backup of current db to restore in case of failure, we can have the following benefits
    by instead swapping database only in case we succeeded in transferring db from master:
    
    - Avoid `LOADING` response during failed and successful synchronization for cases where the
      replica is already up and running with data.
    - Faster total time of diskless replication, because now we're moving from Transfer + Flush + Load
      time to Transfer + Load only. Flushing the tempDb is done asynchronously after swapping.
    - This could be implemented also for disk replication with similar benefits if consumers are willing
      to spend the extra memory usage.
    
    General notes:
    - The concept of `backupDb` becomes `tempDb` for clarity.
    - Async loading mode will only kick in if the replica is syncing from a master that has the same
      repl-id the one it had before. i.e. the data it's getting belongs to a different time of the same timeline.
    - New property in INFO: `async_loading` to differentiate from the blocking loading
    - Slot to Key mapping is now a field of `redisDb` as it's more natural to access it from both server.db
      and the tempDb that is passed around.
    - Because this is affecting replicas only, we assume that if they are not readonly and write commands
      during replication, they are lost after SYNC same way as before, but we're still denying CONFIG SET
      here anyways to avoid complications.
    
    Considerations for review:
    - We have many cases where server.loading flag is used and even though I tried my best, there may
      be cases where async_loading should be checked as well and cases where it shouldn't (would require
      very good understanding of whole code)
    - Several places that had different behavior depending on the loading flag where actually meant to just
      handle commands coming from the AOF client differently than ones coming from real clients, changed
      to check CLIENT_ID_AOF instead.
    
    **Additional for Release Notes**
    - Bugfix - server.dirty was not incremented for any kind of diskless replication, as effect it wouldn't
      contribute on triggering next database SAVE
    - New flag for RM_GetContextFlags module API: REDISMODULE_CTX_FLAGS_ASYNC_LOADING
    - Deprecated RedisModuleEvent_ReplBackup. Starting from Redis 7.0, we don't fire this event.
      Instead, we have the new RedisModuleEvent_ReplAsyncLoad holding 3 sub-events: STARTED,
      ABORTED and COMPLETED.
    - New module flag REDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD for RedisModule_SetModuleOptions
      to allow modules to declare they support the diskless replication with async loading (when absent, we fall
      back to disk-based loading).
    
    Co-authored-by: Eduardo Semprebon <edus@saxobank.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -6258,10 +6262,5 @@
-/* Copies the slots-keys map to the specified backup structure. */
-void slotToKeyCopyToBackup(clusterSlotsToKeysData *backup) {
-    memcpy(backup, server.cluster->slots_to_keys,
-           sizeof(server.cluster->slots_to_keys));
+void slotToKeyInit(redisDb *db) {
+    db->slots_to_keys = zcalloc(sizeof(clusterSlotToKeyMapping));
 }
 
-/* Overwrites the slots-keys map by copying the provided backup structure. */
-void slotToKeyRestoreBackup(clusterSlotsToKeysData *backup) {
-    memcpy(server.cluster->slots_to_keys, backup,
-           sizeof(server.cluster->slots_to_keys));
+/* Empty slots-keys map of given db. */

commit f24c63a292e045d4b14b82b25981f00a95c1767a
Date:   Tue Aug 31 08:25:36 2021 +0200

    Slot-to-keys using dict entry metadata (#9356)
    
    * Enhance dict to support arbitrary metadata carried in dictEntry
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor.soderqvist@est.tech>
    
    * Rewrite slot-to-keys mapping to linked lists using dict entry metadata
    
    This is a memory enhancement for Redis Cluster.
    
    The radix tree slots_to_keys (which duplicates all key names prefixed with their
    slot number) is replaced with a linked list for each slot. The dict entries of
    the same cluster slot form a linked list and the pointers are stored as metadata
    in each dict entry of the main DB dict.
    
    This commit also moves the slot-to-key API from db.c to cluster.c.
    
    Co-authored-by: Jim Brunner <brunnerj@amazon.com>

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -6102,0 +6164,10 @@
+/* Copies the slots-keys map to the specified backup structure. */
+void slotToKeyCopyToBackup(clusterSlotsToKeysData *backup) {
+    memcpy(backup, server.cluster->slots_to_keys,
+           sizeof(server.cluster->slots_to_keys));
+}
+
+/* Overwrites the slots-keys map by copying the provided backup structure. */
+void slotToKeyRestoreBackup(clusterSlotsToKeysData *backup) {
+    memcpy(server.cluster->slots_to_keys, backup,
+           sizeof(server.cluster->slots_to_keys));
[CORR] **new** commit 79f089bdd92348d5fa3965258f539752f2eb8e78
Date:   Sat Jan 29 21:00:29 2022 +0200

    Fixed Sentinel support for hostnames (#10146)
    
    Sentinel tries to resolve instances hostname to IP only during registration.
    It might be that the instance is unavailable during that time, such as
    leader crashed and failover took place. Yet, promoted replica must support:
    
     - Register leader, even if it fails to resolve its hostname during failover
     - Try later to resolve it, if instance is disconnected. Note that
       this condition also support ip-change of an instance.

diff --git a/src/sentinel.c b/src/sentinel.c
--- a/src/sentinel.c
+++ b/src/sentinel.c
@@ -558,21 +558,27 @@
-sentinelAddr *createSentinelAddr(char *hostname, int port) {
+sentinelAddr *createSentinelAddr(char *hostname, int port, int is_accept_unresolved) {
     char ip[NET_IP_STR_LEN];
     sentinelAddr *sa;
 
     if (port < 0 || port > 65535) {
         errno = EINVAL;
         return NULL;
     }
     if (anetResolve(NULL,hostname,ip,sizeof(ip),
                     sentinel.resolve_hostnames ? ANET_NONE : ANET_IP_ONLY) == ANET_ERR) {
-        errno = ENOENT;
-        return NULL;
+        serverLog(LL_WARNING, "Failed to resolve hostname '%s'", hostname);
+        if (sentinel.resolve_hostnames && is_accept_unresolved) {
+            ip[0] = '\0';
+        }
+        else {
+            errno = ENOENT;
+            return NULL;
+        }
     }
     sa = zmalloc(sizeof(*sa));
     sa->hostname = sdsnew(hostname);
     sa->ip = sdsnew(ip);
     sa->port = port;
     return sa;
 }
 
 /* Return a duplicate of the source address. */
[PERF] **new** commit 7dfd7b9197bbe216912049eebecbda3f1684925e
Date:   Tue Nov 29 12:20:22 2022 +0000

    Reduce eval related overhead introduced in v7.0 by evalCalcFunctionName (#11521)
    
    As being discussed in #10981 we see a degradation in performance
    between v6.2 and v7.0 of Redis on the EVAL command.
    
    After profiling the current unstable branch we can see that we call the
    expensive function evalCalcFunctionName twice.
    
    The current "fix" is to basically avoid calling evalCalcFunctionName and
    even dictFind(lua_scripts) twice for the same command.
    Instead we cache the current script's dictEntry (for both Eval and Functions)
    in the current client so we don't have to repeat these calls.
    The exception would be when doing an EVAL on a new script that's not yet
    in the script cache. in that case we will call evalCalcFunctionName (and even
    evalExtractShebangFlags) twice.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -122,100 +122,101 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = c->realcmd = NULL;
+    c->cur_script = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->slot = -1;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_applied = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listInitNode(&c->clients_pending_write_node, c);
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit d144dc927a6ea10cd5dcbdb2eacd58e929dedcfe
Date:   Thu Sep 15 06:39:47 2022 +0300

    Adds listnode to client struct for clients_pending_write list (#11220)

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,99 +120,100 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = c->realcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->slot = -1;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_applied = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
+    listInitNode(&c->clients_pending_write_node, c);
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit efcd1bf394668e418df1a93cd28cf9e8b0c09ce5
Date:   Tue Apr 26 02:09:21 2022 -0700

    By default prevent cross slot operations in functions and scripts with # (#10615)
    
    Adds the `allow-cross-slot-keys` flag to Eval scripts and Functions to allow
    scripts to access keys from multiple slots.
    The default behavior is now that they are not allowed to do that (unlike before).
    This is a breaking change for 7.0 release candidates (to be part of 7.0.0), but
    not for previous redis releases since EVAL without shebang isn't doing this check.
    
    Note that the check is done on both the keys declared by the EVAL / FCALL command
    arguments, and also the ones used by the script when making a `redis.call`.
    
    A note about the implementation, there seems to have been some confusion
    about allowing access to non local keys. I thought I missed something in our
    wider conversation, but Redis scripts do block access to non-local keys.
    So the issue was just about cross slots being accessed.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,98 +120,99 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = c->realcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
+    c->slot = -1;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_applied = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit 78bef6e1fe4b69e9cca6a922911bd88a92584edb
Date:   Fri Mar 25 10:45:40 2022 +0800

    optimize(remove) usage of client's pending_querybuf (#10413)
    
    To remove `pending_querybuf`, the key point is reusing `querybuf`, it means master client's `querybuf` is not only used to parse command, but also proxy to sub-replicas.
    
    1. add a new variable `repl_applied` for master client to record how many data applied (propagated via `replicationFeedStreamFromMasterStream()`) but not trimmed in `querybuf`.
    
    2. don't sdsrange `querybuf` in `commandProcessed()`, we trim it to `repl_applied` after the whole replication pipeline processed to avoid fragmented `sdsrange`. And here are some scenarios we cannot trim to `qb_pos`:
        * we don't receive complete command from master
        * master client blocked because of client pause
        * IO threads operate read, master client flagged with CLIENT_PENDING_COMMAND
    
        In these scenarios, `qb_pos` points to the part of the current command or the beginning of next command, and the current command is not applied yet, so the `repl_applied` is not equal to `qb_pos`.
    
    Some other notes:
    * Do not do big arg optimization on master client, since we can only sdsrange `querybuf` after data sent to replicas.
    * Set `qb_pos` and `repl_applied` to 0 when `freeClient` in `replicationCacheMaster`.
    * Rewrite `processPendingCommandsAndResetClient` to `processPendingCommandAndInputBuffer`, let `processInputBuffer` to be called successively after `processCommandAndResetClient`.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,98 +120,98 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
-    c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = c->realcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
+    c->repl_applied = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit cf6dcb7bf1f65dd52d97e134223eb6661aa69f64
Date:   Tue Mar 15 14:18:23 2022 +0200

    Optimization: remove `updateClientMemUsage` from i/o threads. (#10401)
    
    In a benchmark we noticed we spend a relatively long time updating the client
    memory usage leading to performance degradation.
    Before #8687 this was performed in the client's cron and didn't affect performance.
    But since introducing client eviction we need to perform this after filling the input
    buffers and after processing commands. This also lead me to write this code to be
    thread safe and perform it in the i/o threads.
    
    It turns out that the main performance issue here is related to atomic operations
    being performed while updating the total clients memory usage stats used for client
    eviction (`server.stat_clients_type_memory[]`). This update needed to be atomic
    because `updateClientMemUsage()` was called from the IO threads.
    
    In this commit I make sure to call `updateClientMemUsage()` only from the main thread.
    In case of threaded IO I call it for each client during the "fan-in" phase of the read/write
    operation. This also means I could chuck the `updateClientMemUsageBucket()` function
    which was called during this phase and embed it into `updateClientMemUsage()`.
    
    Profiling shows this makes `updateClientMemUsage()` (on my x86_64 linux) roughly x4 faster.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,98 +120,98 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = c->realcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
-    c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
+    c->last_memory_usage = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit aa856b39f2ca65dbcc0eaae2d2c52f7a35291bbf
Date:   Sun Feb 27 13:40:57 2022 +0200

    Sort out the mess around Lua error messages and error stats (#10329)
    
    This PR fix 2 issues on Lua scripting:
    * Server error reply statistics (some errors were counted twice).
    * Error code and error strings returning from scripts (error code was missing / misplaced).
    
    ## Statistics
    a Lua script user is considered part of the user application, a sophisticated transaction,
    so we want to count an error even if handled silently by the script, but when it is
    propagated outwards from the script we don't wanna count it twice. on the other hand,
    if the script decides to throw an error on its own (using `redis.error_reply`), we wanna
    count that too.
    Besides, we do count the `calls` in command statistics for the commands the script calls,
    we we should certainly also count `failed_calls`.
    So when a simple `eval "return redis.call('set','x','y')" 0` fails, it should count the failed call
    to both SET and EVAL, but the `errorstats` and `total_error_replies` should be counted only once.
    
    The PR changes the error object that is raised on errors. Instead of raising a simple Lua
    string, Redis will raise a Lua table in the following format:
    
    ```
    {
        err='<error message (including error code)>',
        source='<User source file name>',
        line='<line where the error happned>',
        ignore_error_stats_update=true/false,
    }
    ```
    
    The `luaPushError` function was modified to construct the new error table as describe above.
    The `luaRaiseError` was renamed to `luaError` and is now simply called `lua_error` to raise
    the table on the top of the Lua stack as the error object.
    The reason is that since its functionality is changed, in case some Redis branch / fork uses it,
    it's better to have a compilation error than a bug.
    
    The `source` and `line` fields are enriched by the error handler (if possible) and the
    `ignore_error_stats_update` is optional and if its not present then the default value is `false`.
    If `ignore_error_stats_update` is true, the error will not be counted on the error stats.
    
    When parsing Redis call reply, each error is translated to a Lua table on the format describe
    above and the `ignore_error_stats_update` field is set to `true` so we will not count errors
    twice (we counted this error when we invoke the command).
    
    The changes in this PR might have been considered as a breaking change for users that used
    Lua `pcall` function. Before, the error was a string and now its a table. To keep backward
    comparability the PR override the `pcall` implementation and extract the error message from
    the error table and return it.
    
    Example of the error stats update:
    
    ```
    127.0.0.1:6379> lpush l 1
    (integer) 2
    127.0.0.1:6379> eval "return redis.call('get', 'l')" 0
    (error) WRONGTYPE Operation against a key holding the wrong kind of value. script: e471b73f1ef44774987ab00bdf51f21fd9f7974a, on @user_script:1.
    
    127.0.0.1:6379> info Errorstats
    # Errorstats
    errorstat_WRONGTYPE:count=1
    
    127.0.0.1:6379> info commandstats
    # Commandstats
    cmdstat_eval:calls=1,usec=341,usec_per_call=341.00,rejected_calls=0,failed_calls=1
    cmdstat_info:calls=1,usec=35,usec_per_call=35.00,rejected_calls=0,failed_calls=0
    cmdstat_lpush:calls=1,usec=14,usec_per_call=14.00,rejected_calls=0,failed_calls=0
    cmdstat_get:calls=1,usec=10,usec_per_call=10.00,rejected_calls=0,failed_calls=1
    ```
    
    ## error message
    We can now construct the error message (sent as a reply to the user) from the error table,
    so this solves issues where the error message was malformed and the error code appeared
    in the middle of the error message:
    
    ```diff
    127.0.0.1:6379> eval "return redis.call('set','x','y')" 0
    -(error) ERR Error running script (call to 71e6319f97b0fe8bdfa1c5df3ce4489946dda479): @user_script:1: OOM command not allowed when used memory > 'maxmemory'.
    +(error) OOM command not allowed when used memory > 'maxmemory' @user_script:1. Error running script (call to 71e6319f97b0fe8bdfa1c5df3ce4489946dda479)
    ```
    
    ```diff
    127.0.0.1:6379> eval "redis.call('get', 'l')" 0
    -(error) ERR Error running script (call to f_8a705cfb9fb09515bfe57ca2bd84a5caee2cbbd1): @user_script:1: WRONGTYPE Operation against a key holding the wrong kind of value
    +(error) WRONGTYPE Operation against a key holding the wrong kind of value script: 8a705cfb9fb09515bfe57ca2bd84a5caee2cbbd1, on @user_script:1.
    ```
    
    Notica that `redis.pcall` was not change:
    ```
    127.0.0.1:6379> eval "return redis.pcall('get', 'l')" 0
    (error) WRONGTYPE Operation against a key holding the wrong kind of value
    ```
    
    
    ## other notes
    Notice that Some commands (like GEOADD) changes the cmd variable on the client stats so we
    can not count on it to update the command stats. In order to be able to update those stats correctly
    we needed to promote `realcmd` variable to be located on the client struct.
    
    Tests was added and modified to verify the changes.
    
    Related PR's: #10279, #10218, #10278, #10309
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,98 +120,98 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
     c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c->buf);
     c->buf_peak = c->buf_usable_size;
     c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
-    c->cmd = c->lastcmd = NULL;
+    c->cmd = c->lastcmd = c->realcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[PERF] **new** commit 47c51d0c7858dc8ce7747b78b73cf8cec2e59ff3
Date:   Tue Feb 22 11:19:38 2022 +0200

    introduce dynamic client reply buffer size - save memory on idle clients (#9822)
    
    Current implementation simple idle client which serves no traffic still
    use ~17Kb of memory. this is mainly due to a fixed size reply buffer
    currently set to 16kb.
    
    We have encountered some cases in which the server operates in a low memory environments.
    In such cases a user who wishes to create large connection pools to support potential burst period,
    will exhaust a large amount of memory  to maintain connected Idle clients.
    Some users may choose to "sacrifice" performance in order to save memory.
    
    This commit introduce a dynamic mechanism to shrink and expend the client reply buffer based on
    periodic observed peak.
    the algorithm works as follows:
    1. each time a client reply buffer has been fully written, the last recorded peak is updated:
    new peak = MAX( last peak, current written size)
    2. during clients cron we check for each client if the last observed peak was:
         a. matching the current buffer size - in which case we expend (resize) the buffer size by 100%
         b. less than half the buffer size - in which case we shrink the buffer size by 50%
    3. In any case we will **not** resize the buffer in case:
        a. the current buffer peak is less then the current buffer usable size and higher than 1/2 the
          current buffer usable size
        b. the value of (current buffer usable size/2) is less than 1Kib
        c. the value of  (current buffer usable size*2) is larger than 16Kib
    4. the peak value is reset to the current buffer position once every **5** seconds. we maintain a new
       field in the client structure (buf_peak_last_reset_time) which is used to keep track of how long it
       passed since the last buffer peak reset.
    
    ### **Interface changes:**
    **CIENT LIST** - now contains 2 new extra fields:
    rbs= < the current size in bytes of the client reply buffer >
    rbp=< the current value in bytes of the last observed buffer peak position >
    
    **INFO STATS** - now contains 2 new statistics:
    reply_buffer_shrinks = < total number of buffer shrinks performed >
    reply_buffer_expends = < total number of buffer expends performed >
    
    Co-authored-by: Oran Agra <oran@redislabs.com>
    Co-authored-by: Yoav Steinberg <yoav@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,96 +120,98 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
-
+    c->buf = zmalloc(PROTO_REPLY_CHUNK_BYTES);
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
-    c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
+    c->buf_usable_size = zmalloc_usable_size(c->buf);
+    c->buf_peak = c->buf_usable_size;
+    c->buf_peak_last_reset_time = server.unixtime;
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

commit b099889a3a6dccf5243135f0611b8cdb11cab7b8
Date:   Sun Feb 13 18:37:32 2022 +0200

    Fix and improve module error reply statistics (#10278)
    
    This PR handles several aspects
    1. Calls to RM_ReplyWithError from thread safe contexts don't violate thread safety.
    2. Errors returning from RM_Call to the module aren't counted in the statistics (they
      might be handled silently by the module)
    3. When a module propagates a reply it got from RM_Call to it's client, then the error
      statistics are counted.
    
    This is done by:
    1. When appending an error reply to the output buffer, we avoid updating the global
      error statistics, instead we cache that error in a deferred list in the client struct.
    2. When creating a RedisModuleCallReply object, the deferred error list is moved from
      the client into that object.
    3. when a module calls RM_ReplyWithCallReply we copy the deferred replies to the dest
      client (if that's a real client, then that's when the error statistics are updated to the server)
    
    Note about RM_ReplyWithCallReply: if the original reply had an array with errors, and the module
    replied with just a portion of the original reply, and not the entire reply, the errors are currently not
    propagated and the errors stats will not get propagated.
    
    Fix #10180

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,95 +120,96 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
+    c->deferred_reply_errors = NULL;
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

commit c4b788230ca034761a0e9f6ca35b4aee4b15d340
Date:   Thu Jan 20 09:05:53 2022 +0200

    Adding module api for processing commands during busy jobs and allow flagging the commands that should be handled at this status (#9963)
    
    Some modules might perform a long-running logic in different stages of Redis lifetime, for example:
    * command execution
    * RDB loading
    * thread safe context
    
    During this long-running logic Redis is not responsive.
    
    This PR offers
    1. An API to process events while a busy command is running (`RM_Yield`)
    2. A new flag (`ALLOW_BUSY`) to mark the commands that should be handled during busy
      jobs which can also be used by modules (`allow-busy`)
    3. In slow commands and thread safe contexts, this flag will start rejecting commands with -BUSY only
      after `busy-reply-threshold`
    4. During loading (`rdb_load` callback), it'll process events right away (not wait for `busy-reply-threshold`),
      but either way, the processing is throttled to the server hz rate.
    5. Allow modules to Yield to redis background tasks, but not to client commands
    
    * rename `script-time-limit` to `busy-reply-threshold` (an alias to the pre-7.0 `lua-time-limit`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,95 +120,95 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
-    c->paused_list_node = NULL;
+    c->postponed_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit ae89958972ee720be2bff68231d6353553c2272a
Date:   Mon Jan 17 14:11:11 2022 +0200

    Set repl-diskless-sync to yes by default, add repl-diskless-sync-max-replicas (#10092)
    
    1. enable diskless replication by default
    2. add a new config named repl-diskless-sync-max-replicas that enables
       replication to start before the full repl-diskless-sync-delay was
       reached.
    3. put replica online sooner on the master (see below)
    4. test suite uses repl-diskless-sync-delay of 0 to be faster
    5. a few tests that use multiple replica on a pre-populated master, are
       now using the new repl-diskless-sync-max-replicas
    6. fix possible timing issues in a few cluster tests (see below)
    
    put replica online sooner on the master
    ----------------------------------------------------
    there were two tests that failed because they needed for the master to
    realize that the replica is online, but the test code was actually only
    waiting for the replica to realize it's online, and in diskless it could
    have been before the master realized it.
    
    changes include two things:
    1. the tests wait on the right thing
    2. issues in the master, putting the replica online in two steps.
    
    the master used to put the replica as online in 2 steps. the first
    step was to mark it as online, and the second step was to enable the
    write event (only after getting ACK), but in fact the first step didn't
    contains some of the tasks to put it online (like updating good slave
    count, and sending the module event). this meant that if a test was
    waiting to see that the replica is online form the point of view of the
    master, and then confirm that the module got an event, or that the
    master has enough good replicas, it could fail due to timing issues.
    
    so now the full effect of putting the replica online, happens at once,
    and only the part about enabling the writes is delayed till the ACK.
    
    fix cluster tests
    --------------------
    I added some code to wait for the replica to sync and avoid race
    conditions.
    later realized the sentinel and cluster tests where using the original 5
    seconds delay, so changed it to 0.
    
    this means the other changes are probably not needed, but i suppose
    they're still better (avoid race conditions)

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,95 +120,95 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
-    c->repl_put_online_on_ack = 0;
+    c->repl_start_cmd_stream_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit 9f8885760b53e6d3952b9c9b41f9e6c48dfa6cec
Date:   Mon Jan 3 01:54:47 2022 +0100

    Sharded pubsub implementation (#8621)
    
    This commit implements a sharded pubsub implementation based off of shard channels.
    
    Co-authored-by: Harkrishn Patro <harkrisp@amazon.com>
    Co-authored-by: Madelyn Olson <madelyneolson@gmail.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,94 +120,95 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
+    c->pubsubshard_channels = dictCreate(&objectKeyPointerValueDictType);
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit 1bf6d6f11eb08d98ba3de688d18d805a2d8696d5
Date:   Sun Jan 2 09:39:01 2022 +0200

    Generate RDB with Functions only via redis-cli --functions-rdb (#9968)
    
    This is needed in order to ease the deployment of functions for ephemeral cases, where user
    needs to spin up a server with functions pre-loaded.
    
    #### Details:
    
    * Added `--functions-rdb` option to _redis-cli_.
    * Functions only rdb via `REPLCONF rdb-filter-only functions`. This is a placeholder for a space
      separated inclusion filter for the RDB. In the future can be `REPLCONF rdb-filter-only
      "functions db:3 key-patten:user*"` and a complementing `rdb-filter-exclude` `REPLCONF`
      can also be added.
    * Handle "slave requirements" specification to RDB saving code so we can use the same RDB
      when different slaves express the same requirements (like functions-only) and not share the
      RDB when their requirements differ. This is currently just a flags `int`, but can be extended to
      a more complex structure with various filter fields.
    * make sure to support filters only in diskless replication mode (not to override the persistence file),
      we do that by forcing diskless (even if disabled by config)
    
    other changes:
    * some refactoring in rdb.c (extract portion of a big function to a sub-function)
    * rdb_key_save_delay used in AOFRW too
    * sendChildInfo takes the number of updated keys (incremental, rather than absolute)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -120,93 +120,94 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->ref_repl_buf_node = NULL;
     c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
+    c->slave_req = SLAVE_REQ_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

commit c1718f9d862267bc44b2a326cdc8cb1ca5b81a39
Date:   Mon Oct 25 14:24:31 2021 +0800

    Replication backlog and replicas use one global shared replication buffer (#9166)
    
    ## Background
    For redis master, one replica uses one copy of replication buffer, that is a big waste of memory,
    more replicas more waste, and allocate/free memory for every reply list also cost much.
    If we set client-output-buffer-limit small and write traffic is heavy, master may disconnect with
    replicas and can't finish synchronization with replica. If we set  client-output-buffer-limit big,
    master may be OOM when there are many replicas that separately keep much memory.
    Because replication buffers of different replica client are the same, one simple idea is that
    all replicas only use one replication buffer, that will effectively save memory.
    
    Since replication backlog content is the same as replicas' output buffer, now we
    can discard replication backlog memory and use global shared replication buffer
    to implement replication backlog mechanism.
    
    ## Implementation
    I create one global "replication buffer" which contains content of replication stream.
    The structure of "replication buffer" is similar to the reply list that exists in every client.
    But the node of list is `replBufBlock`, which has `id, repl_offset, refcount` fields.
    ```c
    /* Replication buffer blocks is the list of replBufBlock.
     *
     * +--------------+       +--------------+       +--------------+
     * | refcount = 1 |  ...  | refcount = 0 |  ...  | refcount = 2 |
     * +--------------+       +--------------+       +--------------+
     *      |                                            /       \
     *      |                                           /         \
     *      |                                          /           \
     *  Repl Backlog                               Replia_A      Replia_B
     *
     * Each replica or replication backlog increments only the refcount of the
     * 'ref_repl_buf_node' which it points to. So when replica walks to the next
     * node, it should first increase the next node's refcount, and when we trim
     * the replication buffer nodes, we remove node always from the head node which
     * refcount is 0. If the refcount of the head node is not 0, we must stop
     * trimming and never iterate the next node. */
    
    /* Similar with 'clientReplyBlock', it is used for shared buffers between
     * all replica clients and replication backlog. */
    typedef struct replBufBlock {
        int refcount;           /* Number of replicas or repl backlog using. */
        long long id;           /* The unique incremental number. */
        long long repl_offset;  /* Start replication offset of the block. */
        size_t size, used;
        char buf[];
    } replBufBlock;
    ```
    So now when we feed replication stream into replication backlog and all replicas, we only need
    to feed stream into replication buffer `feedReplicationBuffer`. In this function, we set some fields of
    replication backlog and replicas to references of the global replication buffer blocks. And we also
    need to check replicas' output buffer limit to free if exceeding `client-output-buffer-limit`, and trim
    replication backlog if exceeding `repl-backlog-size`.
    
    When sending reply to replicas, we also need to iterate replication buffer blocks and send its
    content, when totally sending one block for replica, we decrease current node count and
    increase the next current node count, and then free the block which reference is 0 from the
    head of replication buffer blocks.
    
    Since now we use linked list to manage replication backlog, it may cost much time for iterating
    all linked list nodes to find corresponding replication buffer node. So we create a rax tree to
    store some nodes  for index, but to avoid rax tree occupying too much memory, i record
    one per 64 nodes for index.
    
    Currently, to make partial resynchronization as possible as much, we always let replication
    backlog as the last reference of replication buffer blocks, backlog size may exceeds our setting
    if slow replicas that reference vast replication buffer blocks, and this method doesn't increase
    memory usage since they share replication buffer. To avoid freezing server for freeing unreferenced
    replication buffer blocks when we need to trim backlog for exceeding backlog size setting,
    we trim backlog incrementally (free 64 blocks per call now), and make it faster in
    `beforeSleep` (free 640 blocks).
    
    ### Other changes
    - `mem_total_replication_buffers`: we add this field in INFO command, it means the total
      memory of replication buffers used.
    - `mem_clients_slaves`:  now even replica is slow to replicate, and its output buffer memory
      is not 0, but it still may be 0, since replication backlog and replicas share one global replication
      buffer, only if replication buffer memory is more than the repl backlog setting size, we consider
      the excess as replicas' memory. Otherwise, we think replication buffer memory is the consumption
      of repl backlog.
    - Key eviction
      Since all replicas and replication backlog share global replication buffer, we think only the
      part of exceeding backlog size the extra separate consumption of replicas.
      Because we trim backlog incrementally in the background, backlog size may exceeds our
      setting if slow replicas that reference vast replication buffer blocks disconnect.
      To avoid massive eviction loop, we don't count the delayed freed replication backlog into
      used memory even if there are no replicas, i.e. we also regard this memory as replicas's memory.
    - `client-output-buffer-limit` check for replica clients
      It doesn't make sense to set the replica clients output buffer limit lower than the repl-backlog-size
      config (partial sync will succeed and then replica will get disconnected). Such a configuration is
      ignored (the size of repl-backlog-size will be used). This doesn't have memory consumption
      implications since the replica client will share the backlog buffers memory.
    - Drop replication backlog after loading data if needed
      We always create replication backlog if server is a master, we need it because we put DELs in
      it when loading expired keys in RDB, but if RDB doesn't have replication info or there is no rdb,
      it is not possible to support partial resynchronization, to avoid extra memory of replication backlog,
      we drop it.
    - Multi IO threads
     Since all replicas and replication backlog use global replication buffer,  if I/O threads are enabled,
      to guarantee data accessing thread safe, we must let main thread handle sending the output buffer
      to all replicas. But before, other IO threads could handle sending output buffer of all replicas.
    
    ## Other optimizations
    This solution resolve some other problem:
    - When replicas disconnect with master since of out of output buffer limit, releasing the output
      buffer of replicas may freeze server if we set big `client-output-buffer-limit` for replicas, but now,
      it doesn't cause freezing.
    - This implementation may mitigate reply list copy cost time(also freezes server) when one replication
      has huge reply buffer and another replica can copy buffer for full synchronization. now, we just copy
      reference info, it is very light.
    - If we set replication backlog size big, it also may cost much time to copy replication backlog into
      replica's output buffer. But this commit eliminates this problem.
    - Resizing replication backlog size doesn't empty current replication backlog content.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -119,91 +119,93 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
+    c->ref_repl_buf_node = NULL;
+    c->ref_block_pos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit 93e85347136a483047e92a3a7554f428d6260b0c
Date:   Sun Oct 3 09:13:09 2021 +0300

    Remove argument count limit, dynamically grow argv. (#9528)
    
    Remove hard coded multi-bulk limit (was 1,048,576), new limit is INT_MAX.
    When client sends an m-bulk that's higher than 1024, we initially only allocate
    the argv array for 1024 arguments, and gradually grow that allocation as arguments
    are received.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,90 +110,91 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
+    c->argv_len = 0;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
     c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     c->mem_usage_bucket = NULL;
     c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

commit 2753429c99425e3d0216cba79e0e61192975f252
Date:   Thu Sep 23 14:02:16 2021 +0300

    Client eviction (#8687)
    
    ### Description
    A mechanism for disconnecting clients when the sum of all connected clients is above a
    configured limit. This prevents eviction or OOM caused by accumulated used memory
    between all clients. It's a complimentary mechanism to the `client-output-buffer-limit`
    mechanism which takes into account not only a single client and not only output buffers
    but rather all memory used by all clients.
    
    #### Design
    The general design is as following:
    * We track memory usage of each client, taking into account all memory used by the
      client (query buffer, output buffer, parsed arguments, etc...). This is kept up to date
      after reading from the socket, after processing commands and after writing to the socket.
    * Based on the used memory we sort all clients into buckets. Each bucket contains all
      clients using up up to x2 memory of the clients in the bucket below it. For example up
      to 1m clients, up to 2m clients, up to 4m clients, ...
    * Before processing a command and before sleep we check if we're over the configured
      limit. If we are we start disconnecting clients from larger buckets downwards until we're
      under the limit.
    
    #### Config
    `maxmemory-clients` max memory all clients are allowed to consume, above this threshold
    we disconnect clients.
    This config can either be set to 0 (meaning no limit), a size in bytes (possibly with MB/GB
    suffix), or as a percentage of `maxmemory` by using the `%` suffix (e.g. setting it to `10%`
    would mean 10% of `maxmemory`).
    
    #### Important code changes
    * During the development I encountered yet more situations where our io-threads access
      global vars. And needed to fix them. I also had to handle keeps the clients sorted into the
      memory buckets (which are global) while their memory usage changes in the io-thread.
      To achieve this I decided to simplify how we check if we're in an io-thread and make it
      much more explicit. I removed the `CLIENT_PENDING_READ` flag used for checking
      if the client is in an io-thread (it wasn't used for anything else) and just used the global
      `io_threads_op` variable the same way to check during writes.
    * I optimized the cleanup of the client from the `clients_pending_read` list on client freeing.
      We now store a pointer in the `client` struct to this list so we don't need to search in it
      (`pending_read_list_node`).
    * Added `evicted_clients` stat to `INFO` command.
    * Added `CLIENT NO-EVICT ON|OFF` sub command to exclude a specific client from the
      client eviction mechanism. Added corrosponding 'e' flag in the client info string.
    * Added `multi-mem` field in the client info string to show how much memory is used up
      by buffered multi commands.
    * Client `tot-mem` now accounts for buffered multi-commands, pubsub patterns and
      channels (partially), tracking prefixes (partially).
    * CLIENT_CLOSE_ASAP flag is now handled in a new `beforeNextClient()` function so
      clients will be disconnected between processing different clients and not only before sleep.
      This new function can be used in the future for work we want to do outside the command
      processing loop but don't want to wait for all clients to be processed before we get to it.
      Specifically I wanted to handle output-buffer-limit related closing before we process client
      eviction in case the two race with each other.
    * Added a `DEBUG CLIENT-EVICTION` command to print out info about the client eviction
      buckets.
    * Each client now holds a pointer to the client eviction memory usage bucket it belongs to
      and listNode to itself in that bucket for quick removal.
    * Global `io_threads_op` variable now can contain a `IO_THREADS_OP_IDLE` value
      indicating no io-threading is currently being executed.
    * In order to track memory used by each clients in real-time we can't rely on updating
      these stats in `clientsCron()` alone anymore. So now I call `updateClientMemUsage()`
      (used to be `clientsCronTrackClientsMemUsage()`) after command processing, after
      writing data to pubsub clients, after writing the output buffer and after reading from the
      socket (and maybe other places too). The function is written to be fast.
    * Clients are evicted if needed (with appropriate log line) in `beforeSleep()` and before
      processing a command (before performing oom-checks and key-eviction).
    * All clients memory usage buckets are grouped as follows:
      * All clients using less than 64k.
      * 64K..128K
      * 128K..256K
      * ...
      * 2G..4G
      * All clients using 4g and up.
    * Added client-eviction.tcl with a bunch of tests for the new mechanism.
    * Extended maxmemory.tcl to test the interaction between maxmemory and
      maxmemory-clients settings.
    * Added an option to flag a numeric configuration variable as a "percent", this means that
      if we encounter a '%' after the number in the config file (or config set command) we
      consider it as valid. Such a number is store internally as a negative value. This way an
      integer value can be interpreted as either a percent (negative) or absolute value (positive).
      This is useful for example if some numeric configuration can optionally be set to a percentage
      of something else.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,87 +110,90 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
+    c->pending_read_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
-    c->client_cron_last_memory_usage = 0;
-    c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
+    c->last_memory_usage = c->last_memory_usage_on_bucket_update = 0;
+    c->last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
+    c->mem_usage_bucket = NULL;
+    c->mem_usage_bucket_node = NULL;
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,87 +110,87 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
-    c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType,NULL);
+    c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
-    c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType,NULL);
+    c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->client_cron_last_memory_usage = 0;
     c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit 5a3de81925130792f78c35e9e4d0204213a3a41e
Date:   Mon Jul 5 10:34:20 2021 +0300

    Use accept4 on linux instead of fcntl to make a client socket non-blocking (#9177)
    
    This reduces system calls on linux when a new connection is made / accepted.
    
    Changes:
    * Add the SOCK_CLOEXEC option to the accept4() call
      This  ensure that a fork/exec call does not leak a file descriptor.
    * Move anetCloexec and connNonBlock info anetGenericAccept
    * Moving connNonBlock from accept handlers to anetGenericAccept
    
    Moving connNonBlock from createClient, is safe because createClient is
    used in the following ways:
    1. without a connection (fake client)
    2. on an accepted connection (see above)
    3. creating the master client by using connConnect (see below)
    
    The third case, can either use anetTcpNonBlockConnect, or connTLSConnect
    which is by default non-blocking.
    
    Co-authored-by: Rajiv Kurian <geetasen@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>
    Co-authored-by: Yoav Steinberg <yoav@redislabs.com>

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,88 +110,87 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
-        connNonBlock(conn);
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType,NULL);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType,NULL);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->client_cron_last_memory_usage = 0;
     c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[PERF] **new** commit c396fd91a039feb5114e79f6f91459a0b1f74346
Date:   Tue Jun 8 18:40:12 2021 +0800

    Mem efficiency, make full use of client struct memory for reply buffers (#8968)
    
    When we allocate a client struct with 16k reply buffer, the allocator we may give us 20K,
    This commit makes use of that extra space.
    Additionally, it tries to store whatever it can from the reply into the static 'buf' before
    allocating a new node for the reply list.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,87 +110,88 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connNonBlock(conn);
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
+    c->buf_usable_size = zmalloc_usable_size(c)-offsetof(client,buf);
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType,NULL);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType,NULL);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->client_cron_last_memory_usage = 0;
     c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[FUNC] **new** commit d63d02601f5b6ba1b149fdd686c99c20649b9916
Date:   Thu Apr 15 16:18:51 2021 +0200

    Add a timeout mechanism for replicas stuck in fullsync (#8762)
    
    Starting redis 6.0 (part of the TLS feature), diskless master uses pipe from the fork
    child so that the parent is the one sending data to the replicas.
    This mechanism has an issue in which a hung replica will cause the master to wait
    for it to read the data sent to it forever, thus preventing the fork child from terminating
    and preventing the creations of any other forks.
    
    This PR adds a timeout mechanism, much like the ACK-based timeout,
    we disconnect replicas that aren't reading the RDB file fast enough.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,86 +110,87 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connNonBlock(conn);
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
+    c->repl_last_partial_write = 0;
     c->slave_listening_port = 0;
     c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType,NULL);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType,NULL);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->client_cron_last_memory_usage = 0;
     c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 

[CORR] **new** commit d828f90c26bf796cb54d6622389e5c14fcc9cbf0
Date:   Sun Feb 21 11:22:36 2021 +0200

    Fix allowed length for REPLCONF ip-address. (#8517)
    
    Originally this was limited to IPv6 address length, but effectively it
    has been used for host names and now that Sentinel accepts that as well
    we need to be able to store full hostnames.
    
    Fixes #8507

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -110,86 +110,86 @@
 client *createClient(connection *conn) {
     client *c = zmalloc(sizeof(client));
 
     /* passing NULL as conn it is possible to create a non connected client.
      * This is useful since all the commands needs to be executed
      * in the context of a client. When commands are executed in other
      * contexts (for instance a Lua script) we need a non connected client. */
     if (conn) {
         connNonBlock(conn);
         connEnableTcpNoDelay(conn);
         if (server.tcpkeepalive)
             connKeepAlive(conn,server.tcpkeepalive);
         connSetReadHandler(conn, readQueryFromClient);
         connSetPrivateData(conn, c);
     }
 
     selectDb(c,0);
     uint64_t client_id;
     atomicGetIncr(server.next_client_id, client_id, 1);
     c->id = client_id;
     c->resp = 2;
     c->conn = conn;
     c->name = NULL;
     c->bufpos = 0;
     c->qb_pos = 0;
     c->querybuf = sdsempty();
     c->pending_querybuf = sdsempty();
     c->querybuf_peak = 0;
     c->reqtype = 0;
     c->argc = 0;
     c->argv = NULL;
     c->argv_len_sum = 0;
     c->original_argc = 0;
     c->original_argv = NULL;
     c->cmd = c->lastcmd = NULL;
     c->multibulklen = 0;
     c->bulklen = -1;
     c->sentlen = 0;
     c->flags = 0;
     c->ctime = c->lastinteraction = server.unixtime;
     clientSetDefaultAuth(c);
     c->replstate = REPL_STATE_NONE;
     c->repl_put_online_on_ack = 0;
     c->reploff = 0;
     c->read_reploff = 0;
     c->repl_ack_off = 0;
     c->repl_ack_time = 0;
     c->slave_listening_port = 0;
-    c->slave_ip[0] = '\0';
+    c->slave_addr = NULL;
     c->slave_capa = SLAVE_CAPA_NONE;
     c->reply = listCreate();
     c->reply_bytes = 0;
     c->obuf_soft_limit_reached_time = 0;
     listSetFreeMethod(c->reply,freeClientReplyValue);
     listSetDupMethod(c->reply,dupClientReplyValue);
     c->btype = BLOCKED_NONE;
     c->bpop.timeout = 0;
     c->bpop.keys = dictCreate(&objectKeyHeapPointerValueDictType,NULL);
     c->bpop.target = NULL;
     c->bpop.xread_group = NULL;
     c->bpop.xread_consumer = NULL;
     c->bpop.xread_group_noack = 0;
     c->bpop.numreplicas = 0;
     c->bpop.reploffset = 0;
     c->woff = 0;
     c->watched_keys = listCreate();
     c->pubsub_channels = dictCreate(&objectKeyPointerValueDictType,NULL);
     c->pubsub_patterns = listCreate();
     c->peerid = NULL;
     c->sockname = NULL;
     c->client_list_node = NULL;
     c->paused_list_node = NULL;
     c->client_tracking_redirection = 0;
     c->client_tracking_prefixes = NULL;
     c->client_cron_last_memory_usage = 0;
     c->client_cron_last_memory_type = CLIENT_TYPE_NORMAL;
     c->auth_callback = NULL;
     c->auth_callback_privdata = NULL;
     c->auth_module = NULL;
     listSetFreeMethod(c->pubsub_patterns,decrRefCountVoid);
     listSetMatchMethod(c->pubsub_patterns,listMatchObjects);
     if (conn) linkClient(c);
     initClientMultiState(c);
     return c;
 }
 
[FUNC] **new** commit 35e8ae3eb5f80ebb5cad5b509d1fde56176bca0d
Date:   Mon Jul 11 16:23:31 2022 +0800

    Add cluster-port support to redis-cli --cluster (#10344)
    
    In #9389, we add a new `cluster-port` config and make cluster bus port configurable,
    and currently redis-cli --cluster create/add-node doesn't support with a configurable `cluster-port` instance.
    Because redis-cli uses the old way (port + 10000) to send the `CLUSTER MEET` command.
    
    Now we add this support on redis-cli `--cluster`, note we don't need to explicitly pass in the
    `cluster-port` parameter, we can get the real `cluster-port` of the node in `clusterManagerNodeLoadInfo`,
    so the `--cluster create` and `--cluster add-node` interfaces have not changed.
    
    We will use the `cluster-port` when we are doing `CLUSTER MEET`, also note that `CLUSTER MEET` bus-port
    parameter was added in 4.0, so if the bus_port (the one in redis-cli) is 0, or equal (port + 10000),
    we just call `CLUSTER MEET` with 2 arguments, using the old form.
    
    Co-authored-by: Madelyn Olson <34459052+madolson@users.noreply.github.com>

diff --git a/src/redis-cli.c b/src/redis-cli.c
--- a/src/redis-cli.c
+++ b/src/redis-cli.c
@@ -2940,1 +2942,1 @@
-static clusterManagerNode *clusterManagerNewNode(char *ip, int port);
+static clusterManagerNode *clusterManagerNewNode(char *ip, int port, int bus_port);
commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_hash.c b/src/t_hash.c
--- a/src/t_hash.c
+++ b/src/t_hash.c
@@ -321,16 +316,16 @@
 hashTypeIterator *hashTypeInitIterator(robj *subject) {
     hashTypeIterator *hi = zmalloc(sizeof(hashTypeIterator));
     hi->subject = subject;
     hi->encoding = subject->encoding;
 
-    if (hi->encoding == OBJ_ENCODING_ZIPLIST) {
+    if (hi->encoding == OBJ_ENCODING_LISTPACK) {
         hi->fptr = NULL;
         hi->vptr = NULL;
     } else if (hi->encoding == OBJ_ENCODING_HT) {
         hi->di = dictGetIterator(subject->ptr);
     } else {
         serverPanic("Unknown hash encoding");
     }
     return hi;
 }
 
[FUNC] **new** commit c81c7f51c38de6dff5ffc55b5184061b84c7ea5f
Date:   Wed Feb 23 22:34:58 2022 +0200

    Add stream consumer group lag tracking and reporting (#9127)
    
    Adds the ability to track the lag of a consumer group (CG), that is, the number
    of entries yet-to-be-delivered from the stream.
    
    The proposed constant-time solution is in the spirit of "best-effort."
    
    Partially addresses #8737.
    
    ## Description of approach
    
    We add a new "entries_added" property to the stream. This starts at 0 for a new
    stream and is incremented by 1 with every `XADD`.  It is essentially an all-time
    counter of the entries added to the stream.
    
    Given the stream's length and this counter value, we can trivially find the logical
    "entries_added" counter of the first ID if and only if the stream is contiguous.
    A fragmented stream contains one or more tombstones generated by `XDEL`s.
    The new "xdel_max_id" stream property tracks the latest tombstone.
    
    The CG also tracks its last delivered ID's as an "entries_read" counter and
    increments it independently when delivering new messages, unless the this
    read counter is invalid (-1 means invalid offset). When the CG's counter is
    available, the reported lag is the difference between added and read counters.
    
    Lastly, this also adds a "first_id" field to the stream structure in order to make
    looking it up cheaper in most cases.
    
    ## Limitations
    
    There are two cases in which the mechanism isn't able to track the lag.
    In these cases, `XINFO` replies with `null` in the "lag" field.
    
    The first case is when a CG is created with an arbitrary last delivered ID,
    that isn't "0-0", nor the first or the last entries of the stream. In this case,
    it is impossible to obtain a valid read counter (short of an O(N) operation).
    The second case is when there are one or more tombstones fragmenting
    the stream's entries range.
    
    In both cases, given enough time and assuming that the consumers are
    active (reading and lacking) and advancing, the CG should be able to
    catch up with the tip of the stream and report zero lag.
    Once that's achieved, lag tracking would resume as normal (until the
    next tombstone is set).
    
    ## API changes
    
    * `XGROUP CREATE` added with the optional named argument `[ENTRIESREAD entries-read]`
      for explicitly specifying the new CG's counter.
    * `XGROUP SETID` added with an optional positional argument `[ENTRIESREAD entries-read]`
      for specifying the CG's counter.
    * `XINFO` reports the maximal tombstone ID, the recorded first entry ID, and total
      number of entries added to the stream.
    * `XINFO` reports the current lag and logical read counter of CGs.
    * `XSETID` is an internal command that's used in replication/aof. It has been added with
      the optional positional arguments `[ENTRIESADDED entries-added] [MAXDELETEDID max-deleted-entry-id]`
      for propagating the CG's offset and maximal tombstone ID of the stream.
    
    ## The generic unsolved problem
    
    The current stream implementation doesn't provide an efficient way to obtain the
    approximate/exact size of a range of entries. While it could've been nice to have
    that ability (#5813) in general, let alone specifically in the context of CGs, the risk
    and complexities involved in such implementation are in all likelihood prohibitive.
    
    ## A refactoring note
    
    The `streamGetEdgeID` has been refactored to accommodate both the existing seek
    of any entry as well as seeking non-deleted entries (the addition of the `skip_tombstones`
    argument). Furthermore, this refactoring also migrated the seek logic to use the
    `streamIterator` (rather than `raxIterator`) that was, in turn, extended with the
    `skip_tombstones` Boolean struct field to control the emission of these.
    
    Co-authored-by: Guy Benoish <guy.benoish@redislabs.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -67,11 +67,16 @@
 stream *streamNew(void) {
     stream *s = zmalloc(sizeof(*s));
     s->rax = raxNew();
     s->length = 0;
+    s->first_id.ms = 0;
+    s->first_id.seq = 0;
     s->last_id.ms = 0;
     s->last_id.seq = 0;
+    s->max_deleted_entry_id.seq = 0;
+    s->max_deleted_entry_id.ms = 0;
+    s->entries_added = 0;
     s->cgroups = NULL; /* Created on demand to save memory when not used. */
     return s;
 }
 
 /* Free a stream, including the listpacks stored inside the radix tree. */
[PERF] **new** commit a642947e04168b40aea6cec666927a9e653035e6
Date:   Wed Apr 13 10:29:24 2022 +0100

    Optimize stream id sds creation on XADD key * (~20% saved cpu cycles) (#10574)
    
    we can observe that when adding to a stream without ID there is a duplicate work
    on sds creation/freeing/sdslen that costs ~11% of the CPU cycles.
    
    This PR avoids it by not freeing the sds after the first reply.
    The expected reduction in CPU cycles is around 9-10%
    
    Additionally, we now pre-allocate the sds to the right size, to avoid realloc.
    this brought another ~10% improvement
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -1388,6 +1400,5 @@
 robj *createObjectFromStreamID(streamID *id) {
-    return createObject(OBJ_STRING, sdscatfmt(sdsempty(),"%U-%U",
-                        id->ms,id->seq));
+    return createObject(OBJ_STRING, createStreamIDString(id));
 }
 
 /* Returns non-zero if the ID is 0-0. */

commit c81c7f51c38de6dff5ffc55b5184061b84c7ea5f
Date:   Wed Feb 23 22:34:58 2022 +0200

    Add stream consumer group lag tracking and reporting (#9127)
    
    Adds the ability to track the lag of a consumer group (CG), that is, the number
    of entries yet-to-be-delivered from the stream.
    
    The proposed constant-time solution is in the spirit of "best-effort."
    
    Partially addresses #8737.
    
    ## Description of approach
    
    We add a new "entries_added" property to the stream. This starts at 0 for a new
    stream and is incremented by 1 with every `XADD`.  It is essentially an all-time
    counter of the entries added to the stream.
    
    Given the stream's length and this counter value, we can trivially find the logical
    "entries_added" counter of the first ID if and only if the stream is contiguous.
    A fragmented stream contains one or more tombstones generated by `XDEL`s.
    The new "xdel_max_id" stream property tracks the latest tombstone.
    
    The CG also tracks its last delivered ID's as an "entries_read" counter and
    increments it independently when delivering new messages, unless the this
    read counter is invalid (-1 means invalid offset). When the CG's counter is
    available, the reported lag is the difference between added and read counters.
    
    Lastly, this also adds a "first_id" field to the stream structure in order to make
    looking it up cheaper in most cases.
    
    ## Limitations
    
    There are two cases in which the mechanism isn't able to track the lag.
    In these cases, `XINFO` replies with `null` in the "lag" field.
    
    The first case is when a CG is created with an arbitrary last delivered ID,
    that isn't "0-0", nor the first or the last entries of the stream. In this case,
    it is impossible to obtain a valid read counter (short of an O(N) operation).
    The second case is when there are one or more tombstones fragmenting
    the stream's entries range.
    
    In both cases, given enough time and assuming that the consumers are
    active (reading and lacking) and advancing, the CG should be able to
    catch up with the tip of the stream and report zero lag.
    Once that's achieved, lag tracking would resume as normal (until the
    next tombstone is set).
    
    ## API changes
    
    * `XGROUP CREATE` added with the optional named argument `[ENTRIESREAD entries-read]`
      for explicitly specifying the new CG's counter.
    * `XGROUP SETID` added with an optional positional argument `[ENTRIESREAD entries-read]`
      for specifying the CG's counter.
    * `XINFO` reports the maximal tombstone ID, the recorded first entry ID, and total
      number of entries added to the stream.
    * `XINFO` reports the current lag and logical read counter of CGs.
    * `XSETID` is an internal command that's used in replication/aof. It has been added with
      the optional positional arguments `[ENTRIESADDED entries-added] [MAXDELETEDID max-deleted-entry-id]`
      for propagating the CG's offset and maximal tombstone ID of the stream.
    
    ## The generic unsolved problem
    
    The current stream implementation doesn't provide an efficient way to obtain the
    approximate/exact size of a range of entries. While it could've been nice to have
    that ability (#5813) in general, let alone specifically in the context of CGs, the risk
    and complexities involved in such implementation are in all likelihood prohibitive.
    
    ## A refactoring note
    
    The `streamGetEdgeID` has been refactored to accommodate both the existing seek
    of any entry as well as seeking non-deleted entries (the addition of the `skip_tombstones`
    argument). Furthermore, this refactoring also migrated the seek logic to use the
    `streamIterator` (rather than `raxIterator`) that was, in turn, extended with the
    `skip_tombstones` Boolean struct field to control the emission of these.
    
    Co-authored-by: Guy Benoish <guy.benoish@redislabs.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -1384,5 +1388,6 @@
 robj *createObjectFromStreamID(streamID *id) {
     return createObject(OBJ_STRING, sdscatfmt(sdsempty(),"%U-%U",
                         id->ms,id->seq));
 }
 
+/* Returns non-zero if the ID is 0-0. */
[FUNC] **new** commit 35b3fbd90c2ad2c503c9e3d28bfbffff13099925
Date:   Sun Oct 9 13:18:34 2022 +0800

    Freeze time sampling during command execution, and scripts (#10300)
    
    Freeze time during execution of scripts and all other commands.
    This means that a key is either expired or not, and doesn't change
    state during a script execution. resolves #10182
    
    This PR try to add a new `commandTimeSnapshot` function.
    The function logic is extracted from `keyIsExpired`, but the related
    calls to `fixed_time_expire` and `mstime()` are removed, see below.
    
    In commands, we will avoid calling `mstime()` multiple times
    and just use the one that sampled in call. The background is,
    e.g. using `PEXPIRE 1` with valgrind sometimes result in the key
    being deleted rather than expired. The reason is that both `PEXPIRE`
    command and `checkAlreadyExpired` call `mstime()` separately.
    
    There are other more important changes in this PR:
    1. Eliminate `fixed_time_expire`, it is no longer needed.
       When we want to sample time we should always use a time snapshot.
       We will use `in_nested_call` instead to update the cached time in `call`.
    2. Move the call for `updateCachedTime` from `serverCron` to `afterSleep`.
        Now `commandTimeSnapshot` will always return the sample time, the
        `lookupKeyReadWithFlags` call in `getNodeByQuery` will get a outdated
        cached time (because `processCommand` is out of the `call` context).
        We put the call to `updateCachedTime` in `aftersleep`.
    3. Cache the time each time the module lock Redis.
        Call `updateCachedTime` in `moduleGILAfterLock`, affecting `RM_ThreadSafeContextLock`
        and `RM_ThreadSafeContextTryLock`
    
    Currently the commandTimeSnapshot change affects the following TTL commands:
    - SET EX / SET PX
    - EXPIRE / PEXPIRE
    - SETEX / PSETEX
    - GETEX EX / GETEX PX
    - TTL / PTTL
    - EXPIRETIME / PEXPIRETIME
    - RESTORE key TTL
    
    And other commands just use the cached mstime (including TIME).
    
    This is considered to be a breaking change since it can break a script
    that uses a loop to wait for a key to expire.

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2451,9 +2451,9 @@
 streamNACK *streamCreateNACK(streamConsumer *consumer) {
     streamNACK *nack = zmalloc(sizeof(*nack));
-    nack->delivery_time = mstime();
+    nack->delivery_time = commandTimeSnapshot();
     nack->delivery_count = 1;
     nack->consumer = consumer;
     return nack;
 }
 
 /* Free a NACK entry. */
commit c81c7f51c38de6dff5ffc55b5184061b84c7ea5f
Date:   Wed Feb 23 22:34:58 2022 +0200

    Add stream consumer group lag tracking and reporting (#9127)
    
    Adds the ability to track the lag of a consumer group (CG), that is, the number
    of entries yet-to-be-delivered from the stream.
    
    The proposed constant-time solution is in the spirit of "best-effort."
    
    Partially addresses #8737.
    
    ## Description of approach
    
    We add a new "entries_added" property to the stream. This starts at 0 for a new
    stream and is incremented by 1 with every `XADD`.  It is essentially an all-time
    counter of the entries added to the stream.
    
    Given the stream's length and this counter value, we can trivially find the logical
    "entries_added" counter of the first ID if and only if the stream is contiguous.
    A fragmented stream contains one or more tombstones generated by `XDEL`s.
    The new "xdel_max_id" stream property tracks the latest tombstone.
    
    The CG also tracks its last delivered ID's as an "entries_read" counter and
    increments it independently when delivering new messages, unless the this
    read counter is invalid (-1 means invalid offset). When the CG's counter is
    available, the reported lag is the difference between added and read counters.
    
    Lastly, this also adds a "first_id" field to the stream structure in order to make
    looking it up cheaper in most cases.
    
    ## Limitations
    
    There are two cases in which the mechanism isn't able to track the lag.
    In these cases, `XINFO` replies with `null` in the "lag" field.
    
    The first case is when a CG is created with an arbitrary last delivered ID,
    that isn't "0-0", nor the first or the last entries of the stream. In this case,
    it is impossible to obtain a valid read counter (short of an O(N) operation).
    The second case is when there are one or more tombstones fragmenting
    the stream's entries range.
    
    In both cases, given enough time and assuming that the consumers are
    active (reading and lacking) and advancing, the CG should be able to
    catch up with the tip of the stream and report zero lag.
    Once that's achieved, lag tracking would resume as normal (until the
    next tombstone is set).
    
    ## API changes
    
    * `XGROUP CREATE` added with the optional named argument `[ENTRIESREAD entries-read]`
      for explicitly specifying the new CG's counter.
    * `XGROUP SETID` added with an optional positional argument `[ENTRIESREAD entries-read]`
      for specifying the CG's counter.
    * `XINFO` reports the maximal tombstone ID, the recorded first entry ID, and total
      number of entries added to the stream.
    * `XINFO` reports the current lag and logical read counter of CGs.
    * `XSETID` is an internal command that's used in replication/aof. It has been added with
      the optional positional arguments `[ENTRIESADDED entries-added] [MAXDELETEDID max-deleted-entry-id]`
      for propagating the CG's offset and maximal tombstone ID of the stream.
    
    ## The generic unsolved problem
    
    The current stream implementation doesn't provide an efficient way to obtain the
    approximate/exact size of a range of entries. While it could've been nice to have
    that ability (#5813) in general, let alone specifically in the context of CGs, the risk
    and complexities involved in such implementation are in all likelihood prohibitive.
    
    ## A refactoring note
    
    The `streamGetEdgeID` has been refactored to accommodate both the existing seek
    of any entry as well as seeking non-deleted entries (the addition of the `skip_tombstones`
    argument). Furthermore, this refactoring also migrated the seek logic to use the
    `streamIterator` (rather than `raxIterator`) that was, in turn, extended with the
    `skip_tombstones` Boolean struct field to control the emission of these.
    
    Co-authored-by: Guy Benoish <guy.benoish@redislabs.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2301,17 +2466,15 @@
- * specified name and last server ID. If a consumer group with the same name
- * already existed NULL is returned, otherwise the pointer to the consumer
- * group is returned. */
-streamCG *streamCreateCG(stream *s, char *name, size_t namelen, streamID *id) {
+streamCG *streamCreateCG(stream *s, char *name, size_t namelen, streamID *id, long long entries_read) {
     if (s->cgroups == NULL) s->cgroups = raxNew();
     if (raxFind(s->cgroups,(unsigned char*)name,namelen) != raxNotFound)
         return NULL;
 
     streamCG *cg = zmalloc(sizeof(*cg));
     cg->pel = raxNew();
     cg->consumers = raxNew();
     cg->last_id = *id;
+    cg->entries_read = entries_read;
     raxInsert(s->cgroups,(unsigned char*)name,namelen,cg,NULL);
     return cg;
 }
 
 /* Free a consumer group and all its associated data. */
[FUNC] **new** commit 72e90695ec8091e483c50a5f0003372f9bebc06d
Date:   Wed Nov 30 17:51:31 2022 +0530

    Stream consumers: Re-purpose seen-time, add active-time (#11099)
    
    1. "Fixed" the current code so that seen-time/idle actually refers to interaction
      attempts (as documented; breaking change)
    2. Added active-time/inactive to refer to successful interaction (what
      seen-time/idle used to be)
    
    At first, I tried to avoid changing the behavior of seen-time/idle but then realized
    that, in this case, the odds are the people read the docs and implemented their
    code based on the docs (which didn't match the behavior).
    For the most part, that would work fine, except that issue #9996 was found.
    
    I was working under the assumption that people relied on the docs, and for
    the most part, it could have worked well enough. so instead of fixing the docs,
    as I would usually do, I fixed the code to match the docs in this particular case.
    
    Note that, in case the consumer has never read any entries, the values
    for both "active-time" (XINFO FULL) and "inactive" (XINFO CONSUMERS) will
    be -1, meaning here that the consumer was never active.
    
    Note that seen/active time is only affected by XREADGROUP / X[AUTO]CLAIM, not
    by XPENDING, XINFO, and other "read-only" stream CG commands (always has been,
    even before this PR)
    
    Other changes:
    * Another behavioral change (arguably a bugfix) is that XREADGROUP and X[AUTO]CLAIM
      create the consumer regardless of whether it was able to perform some reading/claiming
    * RDB format change to save the `active_time`, and set it to the same value of `seen_time` in old rdb files.

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2517,22 +2520,21 @@
 streamConsumer *streamCreateConsumer(streamCG *cg, sds name, robj *key, int dbid, int flags) {
     if (cg == NULL) return NULL;
     int notify = !(flags & SCC_NO_NOTIFY);
     int dirty = !(flags & SCC_NO_DIRTIFY);
     streamConsumer *consumer = zmalloc(sizeof(*consumer));
     int success = raxTryInsert(cg->consumers,(unsigned char*)name,
                                sdslen(name),consumer,NULL);
     if (!success) {
         zfree(consumer);
         return NULL;
     }
     consumer->name = sdsdup(name);
     consumer->pel = raxNew();
+    consumer->active_time = -1;
     consumer->seen_time = commandTimeSnapshot();
     if (dirty) server.dirty++;
     if (notify) notifyKeyspaceEvent(NOTIFY_STREAM,"xgroup-createconsumer",key,dbid);
     return consumer;
 }
 
-/* Lookup the consumer with the specified name in the group 'cg'. Its last 
- * seen time is updated unless the SLC_NO_REFRESH flag is specified. */
-streamConsumer *streamLookupConsumer(streamCG *cg, sds name, int flags) {
+/* Lookup the consumer with the specified name in the group 'cg'. */

commit 35b3fbd90c2ad2c503c9e3d28bfbffff13099925
Date:   Sun Oct 9 13:18:34 2022 +0800

    Freeze time sampling during command execution, and scripts (#10300)
    
    Freeze time during execution of scripts and all other commands.
    This means that a key is either expired or not, and doesn't change
    state during a script execution. resolves #10182
    
    This PR try to add a new `commandTimeSnapshot` function.
    The function logic is extracted from `keyIsExpired`, but the related
    calls to `fixed_time_expire` and `mstime()` are removed, see below.
    
    In commands, we will avoid calling `mstime()` multiple times
    and just use the one that sampled in call. The background is,
    e.g. using `PEXPIRE 1` with valgrind sometimes result in the key
    being deleted rather than expired. The reason is that both `PEXPIRE`
    command and `checkAlreadyExpired` call `mstime()` separately.
    
    There are other more important changes in this PR:
    1. Eliminate `fixed_time_expire`, it is no longer needed.
       When we want to sample time we should always use a time snapshot.
       We will use `in_nested_call` instead to update the cached time in `call`.
    2. Move the call for `updateCachedTime` from `serverCron` to `afterSleep`.
        Now `commandTimeSnapshot` will always return the sample time, the
        `lookupKeyReadWithFlags` call in `getNodeByQuery` will get a outdated
        cached time (because `processCommand` is out of the `call` context).
        We put the call to `updateCachedTime` in `aftersleep`.
    3. Cache the time each time the module lock Redis.
        Call `updateCachedTime` in `moduleGILAfterLock`, affecting `RM_ThreadSafeContextLock`
        and `RM_ThreadSafeContextTryLock`
    
    Currently the commandTimeSnapshot change affects the following TTL commands:
    - SET EX / SET PX
    - EXPIRE / PEXPIRE
    - SETEX / PSETEX
    - GETEX EX / GETEX PX
    - TTL / PTTL
    - EXPIRETIME / PEXPIRETIME
    - RESTORE key TTL
    
    And other commands just use the cached mstime (including TIME).
    
    This is considered to be a breaking change since it can break a script
    that uses a loop to wait for a key to expire.

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2514,22 +2514,22 @@
 streamConsumer *streamCreateConsumer(streamCG *cg, sds name, robj *key, int dbid, int flags) {
     if (cg == NULL) return NULL;
     int notify = !(flags & SCC_NO_NOTIFY);
     int dirty = !(flags & SCC_NO_DIRTIFY);
     streamConsumer *consumer = zmalloc(sizeof(*consumer));
     int success = raxTryInsert(cg->consumers,(unsigned char*)name,
                                sdslen(name),consumer,NULL);
     if (!success) {
         zfree(consumer);
         return NULL;
     }
     consumer->name = sdsdup(name);
     consumer->pel = raxNew();
-    consumer->seen_time = mstime();
+    consumer->seen_time = commandTimeSnapshot();
     if (dirty) server.dirty++;
     if (notify) notifyKeyspaceEvent(NOTIFY_STREAM,"xgroup-createconsumer",key,dbid);
     return consumer;
 }
 
 /* Lookup the consumer with the specified name in the group 'cg'. Its last 
  * seen time is updated unless the SLC_NO_REFRESH flag is specified. */
 streamConsumer *streamLookupConsumer(streamCG *cg, sds name, int flags) {

[CORR] **new** commit 82c3158ad5fe5aab002a6d0565832d5bd15082f5
Date:   Mon Aug 2 13:31:33 2021 +0800

    Fix if consumer is created as a side effect without notify and dirty++ (#9263)
    
    Fixes:
    - When a consumer is created as a side effect, redis didn't issue a keyspace notification,
      nor incremented the server.dirty (affects periodic snapshots).
      this was a bug in XREADGROUP, XCLAIM, and XAUTOCLAIM.
    - When attempting to delete a non-existent consumer, don't issue a keyspace notification
      and don't increment server.dirty
      this was a bug in XGROUP DELCONSUMER
    
    Other changes:
    - Changed streamLookupConsumer() to always only do lookup consumer (never do implicit creation),
      Its last seen time is updated unless the SLC_NO_REFRESH flag is specified.
    - Added streamCreateConsumer() to create a new consumer. When the creation is successful,
      it will notify and dirty++ unless the SCC_NO_NOTIFY or SCC_NO_DIRTIFY flags is specified.
    - Changed streamDelConsumer() to always only do delete consumer.
    - Added keyspace notifications tests about stream events.

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2272,32 +2279,22 @@
-/* Lookup the consumer with the specified name in the group 'cg': if the
- * consumer does not exist it is created unless SLC_NOCREAT flag was specified.
- * Its last seen time is updated unless SLC_NOREFRESH flag was specified. */
-streamConsumer *streamLookupConsumer(streamCG *cg, sds name, int flags, int *created) {
-    if (created) *created = 0;
-    int create = !(flags & SLC_NOCREAT);
-    int refresh = !(flags & SLC_NOREFRESH);
-    streamConsumer *consumer = raxFind(cg->consumers,(unsigned char*)name,
-                               sdslen(name));
-    if (consumer == raxNotFound) {
-        if (!create) return NULL;
-        consumer = zmalloc(sizeof(*consumer));
-        consumer->name = sdsdup(name);
-        consumer->pel = raxNew();
-        raxInsert(cg->consumers,(unsigned char*)name,sdslen(name),
-                  consumer,NULL);
-        consumer->seen_time = mstime();
-        if (created) *created = 1;
-    } else if (refresh)
-        consumer->seen_time = mstime();
+streamConsumer *streamCreateConsumer(streamCG *cg, sds name, robj *key, int dbid, int flags) {
+    if (cg == NULL) return NULL;
+    int notify = !(flags & SCC_NO_NOTIFY);
+    int dirty = !(flags & SCC_NO_DIRTIFY);
+    streamConsumer *consumer = zmalloc(sizeof(*consumer));
+    int success = raxTryInsert(cg->consumers,(unsigned char*)name,
+                               sdslen(name),consumer,NULL);
+    if (!success) {
+        zfree(consumer);
+        return NULL;
+    }
+    consumer->name = sdsdup(name);
+    consumer->pel = raxNew();
+    consumer->seen_time = mstime();
+    if (dirty) server.dirty++;
+    if (notify) notifyKeyspaceEvent(NOTIFY_STREAM,"xgroup-createconsumer",key,dbid);
     return consumer;
 }
 
-/* Delete the consumer specified in the consumer group 'cg'. The consumer
- * may have pending messages: they are removed from the PEL, and the number
- * of pending messages "lost" is returned. */
-uint64_t streamDelConsumer(streamCG *cg, sds name) {
-    streamConsumer *consumer =
-        streamLookupConsumer(cg,name,SLC_NOCREAT|SLC_NOREFRESH,NULL);
-    if (consumer == NULL) return 0;
-
-    uint64_t retval = raxSize(consumer->pel);
+/* Lookup the consumer with the specified name in the group 'cg'. Its last 
+ * seen time is updated unless the SLC_NO_REFRESH flag is specified. */
+streamConsumer *streamLookupConsumer(streamCG *cg, sds name, int flags) {
commit 5e908a290ccbe9c4a7bea9356faf3b837df62793
Date:   Thu Aug 5 08:25:58 2021 +0300

    dict struct memory optimizations (#9228)
    
    Reduce dict struct memory overhead
    on 64bit dict size goes down from jemalloc's 96 byte bin to its 56 byte bin.
    
    summary of changes:
    - Remove `privdata` from callbacks and dict creation. (this affects many files, see "Interface change" below).
    - Meld `dictht` struct into the `dict` struct to eliminate struct padding. (this affects just dict.c and defrag.c)
    - Eliminate the `sizemask` field, can be calculated from size when needed.
    - Convert the `size` field into `size_exp` (exponent), utilizes one byte instead of 8.
    
    Interface change: pass dict pointer to dict type call back functions.
    This is instead of passing the removed privdata field. In the future if
    we'd like to have private data in the callbacks we can extract it from
    the dict type. We can extend dictType to include a custom dict struct
    allocator and use it to allocate more data at the end of the dict
    struct. This data can then be used to store private data later acccessed
    by the callbacks.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -1048,7 +1051,7 @@
-void dictEmpty(dict *d, void(callback)(void*)) {
-    _dictClear(d,&d->ht[0],callback);
-    _dictClear(d,&d->ht[1],callback);
+void dictEmpty(dict *d, void(callback)(dict*)) {
+    _dictClear(d,0,callback);
+    _dictClear(d,1,callback);
     d->rehashidx = -1;
     d->pauserehash = 0;
 }
 

[CORR] **new** commit 06966d2a0e6a2087e4f70265e0f03fa8e1d1b94b
Date:   Sat Feb 20 02:56:30 2021 -0800

    dict: pause rehash, minor readability refactor (#8515)
    
    The `dict` field `iterators` is misleading and incorrect.
    This variable is used for 1 purpose - to pause rehashing.
    
    The current `iterators` field doesn't actually count "iterators".
    It counts "safe iterators".  But - it doesn't actually count safe iterators
    either.  For one, it's only incremented once the safe iterator begins to
    iterate, not when it's created.  It's also incremented in `dictScan` to
    prevent rehashing (and commented to make it clear why `iterators` is
    being incremented during a scan).
    
    This update renames the field as `pauserehash` and creates 2 helper
    macros `dictPauseRehashing(d)` and `dictResumeRehashing(d)`

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -1055,7 +1053,7 @@
 void dictEmpty(dict *d, void(callback)(void*)) {
     _dictClear(d,&d->ht[0],callback);
     _dictClear(d,&d->ht[1],callback);
     d->rehashidx = -1;
-    d->iterators = 0;
+    d->pauserehash = 0;
 }
 
commit fb1d56bc2ae6466f4f6eac5a966936b904b5dbdc
Date:   Thu Sep 8 04:57:43 2022 +0300

    Added API to initialize dictionary iterators without memory allocation (#11245)
    
    * Added api to use dictionary iterators without calling malloc.

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -628,13 +648,8 @@
 void dictReleaseIterator(dictIterator *iter)
 {
-    if (!(iter->index == -1 && iter->table == 0)) {
-        if (iter->safe)
-            dictResumeRehashing(iter->d);
-        else
-            assert(iter->fingerprint == dictFingerprint(iter->d));
-    }
+    dictResetIterator(iter);
     zfree(iter);
 }
 
 /* Return a random entry from the hash table. Useful to
  * implement randomized algorithms */

commit 06966d2a0e6a2087e4f70265e0f03fa8e1d1b94b
Date:   Sat Feb 20 02:56:30 2021 -0800

    dict: pause rehash, minor readability refactor (#8515)
    
    The `dict` field `iterators` is misleading and incorrect.
    This variable is used for 1 purpose - to pause rehashing.
    
    The current `iterators` field doesn't actually count "iterators".
    It counts "safe iterators".  But - it doesn't actually count safe iterators
    either.  For one, it's only incremented once the safe iterator begins to
    iterate, not when it's created.  It's also incremented in `dictScan` to
    prevent rehashing (and commented to make it clear why `iterators` is
    being incremented during a scan).
    
    This update renames the field as `pauserehash` and creates 2 helper
    macros `dictPauseRehashing(d)` and `dictResumeRehashing(d)`

diff --git a/src/dict.c b/src/dict.c
--- a/src/dict.c
+++ b/src/dict.c
@@ -624,13 +624,13 @@
 void dictReleaseIterator(dictIterator *iter)
 {
     if (!(iter->index == -1 && iter->table == 0)) {
         if (iter->safe)
-            iter->d->iterators--;
+            dictResumeRehashing(iter->d);
         else
             assert(iter->fingerprint == dictFingerprint(iter->d));
     }
     zfree(iter);
 }
 
 /* Return a random entry from the hash table. Useful to
  * implement randomized algorithms */
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -650,13 +648,15 @@
 static void moduleFreeKeyIterator(RedisModuleKey *key) {
     serverAssert(key->iter != NULL);
     switch (key->value->type) {
     case OBJ_LIST: listTypeReleaseIterator(key->iter); break;
     case OBJ_STREAM:
         streamIteratorStop(key->iter);
         zfree(key->iter);
         break;
     default: serverAssert(0); /* No key->iter for other types. */
     }
     key->iter = NULL;
 }
 
+/* Callback for listTypeTryConversion().
+ * Frees list iterator and sets it to NULL. */

[SEC] **new** commit dff153ff247478015d0cf93f0f46a222169ac09c
Date:   Mon Feb 28 23:06:39 2022 +0800

    Fix memory leak in RM_StreamIteratorStop and moduleFreeKeyIterator (#10353)
    
    * Fix memory leak in RM_StreamIteratorStop
    * Fix memory leak in moduleFreeKeyIterator

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -595,10 +595,13 @@
 static void moduleFreeKeyIterator(RedisModuleKey *key) {
     serverAssert(key->iter != NULL);
     switch (key->value->type) {
     case OBJ_LIST: listTypeReleaseIterator(key->iter); break;
-    case OBJ_STREAM: zfree(key->iter); break;
+    case OBJ_STREAM:
+        streamIteratorStop(key->iter);
+        zfree(key->iter);
+        break;
     default: serverAssert(0); /* No key->iter for other types. */
     }
     key->iter = NULL;
 }
 

commit ea36d4de17101f05b03d267a4afbae0f7b33a27c
Date:   Tue Sep 14 16:48:06 2021 +0200

    Modules: Add remaining list API functions (#8439)
    
    List functions operating on elements by index:
    
    * RM_ListGet
    * RM_ListSet
    * RM_ListInsert
    * RM_ListDelete
    
    Iteration is done using a simple for loop over indices.
    The index based functions use an internal iterator as an optimization.
    This is explained in the docs:
    
    ```
     * Many of the list functions access elements by index. Since a list is in
     * essence a doubly-linked list, accessing elements by index is generally an
     * O(N) operation. However, if elements are accessed sequentially or with
     * indices close together, the functions are optimized to seek the index from
     * the previous index, rather than seeking from the ends of the list.
     *
     * This enables iteration to be done efficiently using a simple for loop:
     *
     *     long n = RM_ValueLength(key);
     *     for (long i = 0; i < n; i++) {
     *         RedisModuleString *elem = RedisModule_ListGet(key, i);
     *         // Do stuff...
     *     }
    ```

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -541,0 +547,10 @@
+static void moduleFreeKeyIterator(RedisModuleKey *key) {
+    serverAssert(key->iter != NULL);
+    switch (key->value->type) {
+    case OBJ_LIST: listTypeReleaseIterator(key->iter); break;
+    case OBJ_STREAM: zfree(key->iter); break;
+    default: serverAssert(0); /* No key->iter for other types. */
+    }
+    key->iter = NULL;
+}
+
[FUNC] **new** commit bebc7f8470a5c6093514abf02f2514268c78b28f
Date:   Thu Sep 23 15:00:37 2021 +0300

    Add RM_TrimStringAllocation(). (#9540)
    
    This commit makes it possible to explicitly trim the allocation of a
    RedisModuleString.
    
    Currently, Redis automatically trims strings that have been retained by
    a module command when it returns. However, this is not thread safe and
    may result with corruption in threaded modules.
    
    Supporting explicit trimming offers a backwards compatible workaround to
    this problem.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -1506,29 +1506,37 @@
 void RM_FreeString(RedisModuleCtx *ctx, RedisModuleString *str) {
     decrRefCount(str);
     if (ctx != NULL) autoMemoryFreed(ctx,REDISMODULE_AM_STRING,str);
 }
 
 /* Every call to this function, will make the string 'str' requiring
  * an additional call to RedisModule_FreeString() in order to really
  * free the string. Note that the automatic freeing of the string obtained
  * enabling modules automatic memory management counts for one
  * RedisModule_FreeString() call (it is just executed automatically).
  *
  * Normally you want to call this function when, at the same time
  * the following conditions are true:
  *
  * 1. You have automatic memory management enabled.
  * 2. You want to create string objects.
  * 3. Those string objects you create need to live *after* the callback
  *    function(for example a command implementation) creating them returns.
  *
  * Usually you want this in order to store the created string object
  * into your own data structure, for example when implementing a new data
  * type.
  *
  * Note that when memory management is turned off, you don't need
  * any call to RetainString() since creating a string will always result
  * into a string that lives after the callback function returns, if
  * no FreeString() call is performed.
  *
- * It is possible to call this function with a NULL context. */
+ * It is possible to call this function with a NULL context.
+ *
+ * When strings are going to be retained for an extended duration, it is good
+ * practice to also call RedisModule_TrimStringAllocation() in order to
+ * optimize memory usage.
+ *
+ * Threaded modules that reference retained strings from other threads *must*
+ * explicitly trim the allocation as soon as the string is retained. Not doing
+ * so may result with automatic trimming which is not thread safe. */
[NA] **new** commit 66be30f7fc2f7f6378eedc8d7b219db18addbc06
Date:   Tue Feb 8 10:01:35 2022 +0200

    Handle key-spec flags with modules (#10237)
    
    - add COMMAND GETKEYSANDFLAGS sub-command
    - add RM_KeyAtPosWithFlags and GetCommandKeysWithFlags
    - RM_KeyAtPos and RM_CreateCommand set flags requiring full access for keys
    - RM_CreateCommand set VARIABLE_FLAGS
    - expose `variable_flags` flag in COMMAND INFO key-specs
    - getKeysFromCommandWithSpecs prefers key-specs over getkeys-api
    - add tests for all of these

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -405,2 +406,3 @@
 void RM_FreeServerInfo(RedisModuleCtx *ctx, RedisModuleServerInfoData *data);
 
+/* Helpers for RM_SetCommandInfo. */
commit a56d4533b72db8aa147be090c4c1d2bc548b9408
Date:   Thu Sep 23 08:52:56 2021 +0300

    Adding ACL support for modules (#9309)
    
    This commit introduced a new flag to the RM_Call:
    'C' - Check if the command can be executed according to the ACLs associated with it.
    
    Also, three new API's added to check if a command, key, or channel can be executed or accessed
    by a user, according to the ACLs associated with it.
    - RM_ACLCheckCommandPerm
    - RM_ACLCheckKeyPerm
    - RM_ACLCheckChannelPerm
    
    The user for these API's is a RedisModuleUser object, that for a Module user returned by the RM_CreateModuleUser API, or for a general ACL user can be retrieved by these two new API's:
    - RM_GetCurrentUserName - Retrieve the user name of the client connection behind the current context.
    - RM_GetModuleUserFromUserName - Get a RedisModuleUser from a user name
    
    As a result of getting a RedisModuleUser from name, it can now also access the general ACL users (not just ones created by the module).
    This mean the already existing API RM_SetModuleUserACL(), can be used to change the ACL rules for such users.

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -7209,13 +7238,14 @@
 int RM_FreeModuleUser(RedisModuleUser *user) {
-    ACLFreeUserAndKillClients(user->user);
+    if (user->free_user)
+        ACLFreeUserAndKillClients(user->user);
     zfree(user);
     return REDISMODULE_OK;
 }
 
 /* Sets the permissions of a user created through the redis module
  * interface. The syntax is the same as ACL SETUSER, so refer to the
  * documentation in acl.c for more information. See RM_CreateModuleUser
  * for detailed usage.
  *
  * Returns REDISMODULE_OK on success and REDISMODULE_ERR on failure
  * and will set an errno describing why the operation failed. */

commit 0bfccc55e2df349104b34608365dc17db8e0a749
Date:   Thu Jun 10 20:39:33 2021 +0800

    Fixed some typos, add a spell check ci and others minor fix (#8890)
    
    This PR adds a spell checker CI action that will fail future PRs if they introduce typos and spelling mistakes.
    This spell checker is based on blacklist of common spelling mistakes, so it will not catch everything,
    but at least it is also unlikely to cause false positives.
    
    Besides that, the PR also fixes many spelling mistakes and types, not all are a result of the spell checker we use.
    
    Here's a summary of other changes:
    1. Scanned the entire source code and fixes all sorts of typos and spelling mistakes (including missing or extra spaces).
    2. Outdated function / variable / argument names in comments
    3. Fix outdated keyspace masks error log when we check `config.notify-keyspace-events` in loadServerConfigFromString.
    4. Trim the white space at the end of line in `module.c`. Check: https://github.com/redis/redis/pull/7751
    5. Some outdated https link URLs.
    6. Fix some outdated comment. Such as:
        - In README: about the rdb, we used to said create a `thread`, change to `process`
        - dbRandomKey function coment (about the dictGetRandomKey, change to dictGetFairRandomKey)
        - notifyKeyspaceEvent fucntion comment (add type arg)
        - Some others minor fix in comment (Most of them are incorrectly quoted by variable names)
    7. Modified the error log so that users can easily distinguish between TCP and TLS in `changeBindAddr`

diff --git a/src/module.c b/src/module.c
--- a/src/module.c
+++ b/src/module.c
@@ -6480,13 +6480,13 @@
 int RM_FreeModuleUser(RedisModuleUser *user) {
     ACLFreeUserAndKillClients(user->user);
     zfree(user);
     return REDISMODULE_OK;
 }
 
-/* Sets the permissions of a user created through the redis module 
- * interface. The syntax is the same as ACL SETUSER, so refer to the 
+/* Sets the permissions of a user created through the redis module
+ * interface. The syntax is the same as ACL SETUSER, so refer to the
  * documentation in acl.c for more information. See RM_CreateModuleUser
  * for detailed usage.
- * 
+ *
  * Returns REDISMODULE_OK on success and REDISMODULE_ERR on failure
  * and will set an errno describing why the operation failed. */
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -114,8 +275,9 @@
 void listTypeReleaseIterator(listTypeIterator *li) {
-    quicklistReleaseIterator(li->iter);
+    if (li->encoding == OBJ_ENCODING_QUICKLIST)
+        quicklistReleaseIterator(li->iter);
     zfree(li);
 }
 
 /* Stores pointer to current the entry in the provided entry structure
  * and advances the position of the iterator. Returns 1 when the current
  * entry is in fact an entry, 0 otherwise. */

commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/t_list.c b/src/t_list.c
--- a/src/t_list.c
+++ b/src/t_list.c
@@ -114,8 +114,8 @@
 void listTypeReleaseIterator(listTypeIterator *li) {
-    zfree(li->iter);
+    quicklistReleaseIterator(li->iter);
     zfree(li);
 }
 
 /* Stores pointer to current the entry in the provided entry structure
  * and advances the position of the iterator. Returns 1 when the current
  * entry is in fact an entry, 0 otherwise. */
commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -173,24 +179,24 @@
 void quicklistRelease(quicklist *quicklist) {
     unsigned long len;
     quicklistNode *current, *next;
 
     current = quicklist->head;
     len = quicklist->len;
     while (len--) {
         next = current->next;
 
         zfree(current->entry);
         quicklist->count -= current->count;
 
         zfree(current);
 
         quicklist->len--;
         current = next;
     }
     quicklistBookmarksClear(quicklist);
     zfree(quicklist);
 }
 
-/* Compress the ziplist in 'node' and update encoding details.
- * Returns 1 if ziplist compressed successfully.
- * Returns 0 if compression failed or if ziplist too small to compress. */
+/* Compress the listpack in 'node' and update encoding details.
+ * Returns 1 if listpack compressed successfully.
+ * Returns 0 if compression failed or if listpack too small to compress. */

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -161,24 +173,24 @@
 void quicklistRelease(quicklist *quicklist) {
     unsigned long len;
     quicklistNode *current, *next;
 
     current = quicklist->head;
     len = quicklist->len;
     while (len--) {
         next = current->next;
 
-        zfree(current->zl);
+        zfree(current->entry);
         quicklist->count -= current->count;
 
         zfree(current);
 
         quicklist->len--;
         current = next;
     }
     quicklistBookmarksClear(quicklist);
     zfree(quicklist);
 }
 
 /* Compress the ziplist in 'node' and update encoding details.
  * Returns 1 if ziplist compressed successfully.
  * Returns 0 if compression failed or if ziplist too small to compress. */
commit 4512905961b3a2f4c00e5fe7ffff8d96db82861e
Date:   Wed Nov 24 19:34:13 2021 +0800

    Replace ziplist with listpack in quicklist (#9740)
    
    Part three of implementing #8702, following #8887 and #9366 .
    
    ## Description of the feature
    1. Replace the ziplist container of quicklist with listpack.
    2. Convert existing quicklist ziplists on RDB loading time. an O(n) operation.
    
    ## Interface changes
    1. New `list-max-listpack-size` config is an alias for `list-max-ziplist-size`.
    2. Replace `debug ziplist` command with `debug listpack`.
    
    ## Internal changes
    1. Add `lpMerge` to merge two listpacks . (same as `ziplistMerge`)
    2. Add `lpRepr` to print info of listpack which is used in debugCommand and `quicklistRepr`. (same as `ziplistRepr`)
    3. Replace `QUICKLIST_NODE_CONTAINER_ZIPLIST` with `QUICKLIST_NODE_CONTAINER_PACKED`(following #9357 ).
        It represent that a quicklistNode is a packed node, as opposed to a plain node.
    4. Remove `createZiplistObject` method, which is never used.
    5. Calculate listpack entry size using overhead overestimation in `quicklistAllowInsert`.
        We prefer an overestimation, which would at worse lead to a few bytes below the lowest limit of 4k.
    
    ## Improvements
    1. Calling `lpShrinkToFit` after converting Ziplist to listpack, which was missed at #9366.
    2. Optimize `quicklistAppendPlainNode` to avoid memcpy data.
    
    ## Bugfix
    1. Fix crash in `quicklistRepr` when ziplist is compressed, introduced from #9366.
    
    ## Test
    1. Add unittest for `lpMerge`.
    2. Modify the old quicklist ziplist corrupt dump test.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -684,44 +620,44 @@
 REDIS_STATIC void __quicklistDelNode(quicklist *quicklist,
                                      quicklistNode *node) {
     /* Update the bookmark if any */
     quicklistBookmark *bm = _quicklistBookmarkFindByNode(quicklist, node);
     if (bm) {
         bm->node = node->next;
         /* if the bookmark was to the last node, delete it. */
         if (!bm->node)
             _quicklistBookmarkDelete(quicklist, bm);
     }
 
     if (node->next)
         node->next->prev = node->prev;
     if (node->prev)
         node->prev->next = node->next;
 
     if (node == quicklist->tail) {
         quicklist->tail = node->prev;
     }
 
     if (node == quicklist->head) {
         quicklist->head = node->next;
     }
 
     /* Update len first, so in __quicklistCompress we know exactly len */
     quicklist->len--;
     quicklist->count -= node->count;
 
     /* If we deleted a node within our compress depth, we
      * now have compressed nodes needing to be decompressed. */
     __quicklistCompress(quicklist, NULL);
 
     zfree(node->entry);
     zfree(node);
 }
 
 /* Delete one entry from list given the node for the entry and a pointer
  * to the entry in the node.
  *
  * Note: quicklistDelIndex() *requires* uncompressed nodes because you
  *       already had to get *p from an uncompressed node somewhere.
  *
  * Returns 1 if the entire node was deleted, 0 if node still exists.
- * Also updates in/out param 'p' with the next offset in the ziplist. */
+ * Also updates in/out param 'p' with the next offset in the listpack. */

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -593,44 +674,44 @@
 REDIS_STATIC void __quicklistDelNode(quicklist *quicklist,
                                      quicklistNode *node) {
     /* Update the bookmark if any */
     quicklistBookmark *bm = _quicklistBookmarkFindByNode(quicklist, node);
     if (bm) {
         bm->node = node->next;
         /* if the bookmark was to the last node, delete it. */
         if (!bm->node)
             _quicklistBookmarkDelete(quicklist, bm);
     }
 
     if (node->next)
         node->next->prev = node->prev;
     if (node->prev)
         node->prev->next = node->next;
 
     if (node == quicklist->tail) {
         quicklist->tail = node->prev;
     }
 
     if (node == quicklist->head) {
         quicklist->head = node->next;
     }
 
     /* Update len first, so in __quicklistCompress we know exactly len */
     quicklist->len--;
     quicklist->count -= node->count;
 
     /* If we deleted a node within our compress depth, we
      * now have compressed nodes needing to be decompressed. */
     __quicklistCompress(quicklist, NULL);
 
-    zfree(node->zl);
+    zfree(node->entry);
     zfree(node);
 }
 
 /* Delete one entry from list given the node for the entry and a pointer
  * to the entry in the node.
  *
  * Note: quicklistDelIndex() *requires* uncompressed nodes because you
  *       already had to get *p from an uncompressed node somewhere.
  *
  * Returns 1 if the entire node was deleted, 0 if node still exists.
  * Also updates in/out param 'p' with the next offset in the ziplist. */

[CORR] **new** commit 9b4edfdf08a99adda0b6da5b1434d14884d6419b
Date:   Tue Mar 9 03:43:09 2021 +0800

    __quicklistCompress may compress more node than required (#8311)
    
    When a quicklist has quicklist->compress * 2 nodes, then call
    __quicklistCompress, all nodes will be decompressed and the middle
    two nodes will be recompressed again. This violates the fact that
    quicklist->compress * 2 nodes are uncompressed. It's harmless
    because when visit a node, we always try to uncompress node first.
    This only happened when a quicklist has quicklist->compress * 2 + 1
    nodes, then delete a node. For other scenarios like insert node and
    iterate this will not happen.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -581,43 +582,44 @@
 REDIS_STATIC void __quicklistDelNode(quicklist *quicklist,
                                      quicklistNode *node) {
     /* Update the bookmark if any */
     quicklistBookmark *bm = _quicklistBookmarkFindByNode(quicklist, node);
     if (bm) {
         bm->node = node->next;
         /* if the bookmark was to the last node, delete it. */
         if (!bm->node)
             _quicklistBookmarkDelete(quicklist, bm);
     }
 
     if (node->next)
         node->next->prev = node->prev;
     if (node->prev)
         node->prev->next = node->next;
 
     if (node == quicklist->tail) {
         quicklist->tail = node->prev;
     }
 
     if (node == quicklist->head) {
         quicklist->head = node->next;
     }
 
+    /* Update len first, so in __quicklistCompress we know exactly len */
+    quicklist->len--;
+    quicklist->count -= node->count;
+
     /* If we deleted a node within our compress depth, we
      * now have compressed nodes needing to be decompressed. */
     __quicklistCompress(quicklist, NULL);
 
-    quicklist->count -= node->count;
-
     zfree(node->zl);
     zfree(node);
-    quicklist->len--;
 }
 
 /* Delete one entry from list given the node for the entry and a pointer
  * to the entry in the node.
  *
  * Note: quicklistDelIndex() *requires* uncompressed nodes because you
  *       already had to get *p from an uncompressed node somewhere.
  *
  * Returns 1 if the entire node was deleted, 0 if node still exists.
  * Also updates in/out param 'p' with the next offset in the ziplist. */
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1189,28 +1258,29 @@
 void quicklistReleaseIterator(quicklistIter *iter) {
+    if (!iter) return;
     if (iter->current)
         quicklistCompress(iter->quicklist, iter->current);
 
     zfree(iter);
 }
 
 /* Get next element in iterator.
  *
  * Note: You must NOT insert into the list while iterating over it.
  * You *may* delete from the list while iterating using the
  * quicklistDelEntry() function.
  * If you insert into the quicklist while iterating, you should
  * re-create the iterator after your addition.
  *
  * iter = quicklistGetIterator(quicklist,<direction>);
  * quicklistEntry entry;
  * while (quicklistNext(iter, &entry)) {
  *     if (entry.value)
  *          [[ use entry.value with entry.sz ]]
  *     else
  *          [[ use entry.longval ]]
  * }
  *
  * Populates 'entry' with values for this iteration.
  * Returns 0 when iteration is complete or if iteration not possible.
  * If return value is 0, the contents of 'entry' are not valid.
  */
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -102,15 +102,23 @@
 void _quicklistBookmarkDelete(quicklist *ql, quicklistBookmark *bm);
 
 /* Simple way to give quicklistEntry structs default values with one call. */
 #define initEntry(e)                                                           \
     do {                                                                       \
         (e)->zi = (e)->value = NULL;                                           \
         (e)->longval = -123456789;                                             \
         (e)->quicklist = NULL;                                                 \
         (e)->node = NULL;                                                      \
         (e)->offset = 123456789;                                               \
         (e)->sz = 0;                                                           \
     } while (0)
 
+/* Reset the quicklistIter to prevent it from being used again after
+ * insert, replace, or other against quicklist operation. */
+#define resetIterator(iter)                                                    \
+    do {                                                                       \
+        (iter)->current = NULL;                                                \
+        (iter)->zi = NULL;                                                     \
+    } while (0)
+
 /* Create a new quicklist.
  * Free with quicklistRelease(). */
commit 494ee2f1fc5cf1687b302a95e49003573dc375d5
Date:   Mon Nov 29 13:57:01 2021 +0800

    Fix abnormal compression due to out-of-control recompress (#9849)
    
    This pr is following #9779 .
    
    ## Describe of feature
    Now when we turn on the `list-compress-depth` configuration, the list will compress
    the ziplist between `[list-compress-depth, -list-compress-depth]`.
    When we need to use the compressed data, we will first decompress it, then use it,
    and finally compress it again.
    It's controlled by `quicklistNode->recompress`, which is designed to avoid the need to
    re-traverse the entire quicklist for compression after each decompression, we only need
    to recompress the quicklsitNode being used.
    In order to ensure the correctness of recompressing, we should normally let
    quicklistDecompressNodeForUse and quicklistCompress appear in pairs, otherwise,
    it may lead to the head and tail being compressed or the middle ziplist not being
    compressed correctly, which is exactly the problem this pr needs to solve.
    
    ## Solution
    1. Reset `quicklistIter` after insert and replace.
        The quicklist node will be compressed in `quicklistInsertAfter`, `quicklistInsertBefore`,
       `quicklistReplaceAtIndex`, so we can safely reset the quicklistIter to avoid it being used again
    2. `quicklistIndex` will return an iterator that can be used to recompress the current node after use.
    
    ## Test
    1. In the `Stress Tester for #3343-Similar Errors` test, when the server crashes or when
       `valgrind` or `asan` error is detected, print violating commands.
    2. Add a crash test due to wrongly recompressing after `lrem`.
    3. Remove `insert before with 0 elements` and `insert after with 0 elements`,
       Now we forbid any operation on an NULL quicklistIter.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -102,15 +102,23 @@
 void _quicklistBookmarkDelete(quicklist *ql, quicklistBookmark *bm);
 
 /* Simple way to give quicklistEntry structs default values with one call. */
 #define initEntry(e)                                                           \
     do {                                                                       \
         (e)->zi = (e)->value = NULL;                                           \
         (e)->longval = -123456789;                                             \
         (e)->quicklist = NULL;                                                 \
         (e)->node = NULL;                                                      \
         (e)->offset = 123456789;                                               \
         (e)->sz = 0;                                                           \
     } while (0)
 
+/* Reset the quicklistIter to prevent it from being used again after
+ * insert, replace, or other against quicklist operation. */
+#define resetIterator(iter)                                                    \
+    do {                                                                       \
+        (iter)->current = NULL;                                                \
+        (iter)->zi = NULL;                                                     \
+    } while (0)
+
 /* Create a new quicklist.
  * Free with quicklistRelease(). */
[FUNC] **new** commit 985430b4fca5ac55b121a98ac0407909c6767530
Date:   Tue Nov 16 19:12:25 2021 +0800

    Change lzf to handle values larger than UINT32_MAX (#9776)
    
    Redis supports inserting data over 4GB into string (and recently for lists too, see #9357),
    But LZF compression used in RDB files (see `rdbcompression` config), and in quicklist
    (see `list-compress-depth` config) does not support compress/decompress data over
    UINT32_MAX, which will result in corrupting the rdb after compression.
    
    Internal changes:
    1. Modify the `unsigned int` parameter of `lzf_compress/lzf_decompress` to `size_t`.
    2. Modify the variable types in `lzf_compress` involving offsets and lengths to `size_t`.
    3. Set LZF_USE_OFFSETS to 0.
        When LZF_USE_OFFSETS is 1, lzf store offset into `LZF_HSLOT`(32bit).
        Even in 64-bit, `LZF_USE_OFFSETS` defaults to 1, because lzf assumes that it only
        compresses and decompresses data smaller than UINT32_MAX.
        But now we need to make lzf support 64-bit, turning on `LZF_USE_OFFSETS` will make
        it impossible to store 64-bit offsets or pointers.
        BTW, disable LZF_USE_OFFSETS also brings a few performance improvements.
    
    Tests:
    1. Add test for compress/decompress string large than UINT32_MAX.
    2. Add unittest for compress/decompress quicklistNode.

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1712,34 +1712,35 @@
 void quicklistBookmarksClear(quicklist *ql) {
     while (ql->bookmark_count)
         zfree(ql->bookmarks[--ql->bookmark_count].name);
     /* NOTE: We do not shrink (realloc) the quick list. main use case for this
      * function is just before releasing the allocation. */
 }
 
 /* The rest of this file is test cases and test helpers. */
 #ifdef REDIS_TEST
 #include <stdint.h>
 #include <sys/time.h>
 #include "testhelp.h"
+#include <stdlib.h>
 
 #define yell(str, ...) printf("ERROR! " str "\n\n", __VA_ARGS__)
 
 #define ERROR                                                                  \
     do {                                                                       \
         printf("\tERROR!\n");                                                  \
         err++;                                                                 \
     } while (0)
 
 #define ERR(x, ...)                                                            \
     do {                                                                       \
         printf("%s:%s:%d:\t", __FILE__, __func__, __LINE__);                   \
         printf("ERROR! " x "\n", __VA_ARGS__);                                 \
         err++;                                                                 \
     } while (0)
 
 #define TEST(name) printf("test â %s\n", name);
 #define TEST_DESC(name, ...) printf("test â " name "\n", __VA_ARGS__);
 
 #define QL_TEST_VERBOSE 0
 
 #define UNUSED(x) (void)(x)

[NA] **new** commit e725d737fb2ee492fbcd04bb7deb1696d7e182d1
Date:   Tue Nov 16 14:55:10 2021 +0800

    Add --large-memory flag for REDIS_TEST to enable tests that consume more than 100mb (#9784)
    
    This is a preparation step in order to add a new test in quicklist.c see #9776

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1712,33 +1712,34 @@
 void quicklistBookmarksClear(quicklist *ql) {
     while (ql->bookmark_count)
         zfree(ql->bookmarks[--ql->bookmark_count].name);
     /* NOTE: We do not shrink (realloc) the quick list. main use case for this
      * function is just before releasing the allocation. */
 }
 
 /* The rest of this file is test cases and test helpers. */
 #ifdef REDIS_TEST
 #include <stdint.h>
 #include <sys/time.h>
+#include "testhelp.h"
 
 #define yell(str, ...) printf("ERROR! " str "\n\n", __VA_ARGS__)
 
 #define ERROR                                                                  \
     do {                                                                       \
         printf("\tERROR!\n");                                                  \
         err++;                                                                 \
     } while (0)
 
 #define ERR(x, ...)                                                            \
     do {                                                                       \
         printf("%s:%s:%d:\t", __FILE__, __func__, __LINE__);                   \
         printf("ERROR! " x "\n", __VA_ARGS__);                                 \
         err++;                                                                 \
     } while (0)
 
 #define TEST(name) printf("test â %s\n", name);
 #define TEST_DESC(name, ...) printf("test â " name "\n", __VA_ARGS__);
 
 #define QL_TEST_VERBOSE 0
 
 #define UNUSED(x) (void)(x)

[NA] **new** commit 95d6297db868fc5400fb833c6753c8d25da486c7
Date:   Wed Mar 10 15:13:11 2021 +0800

    Add run all test support with define REDIS_TEST (#8570)
    
    1. Add `redis-server test all` support to run all tests.
    2. Add redis test to daily ci.
    3. Add `--accurate` option to run slow tests for more iterations (so that
       by default we run less cycles (shorter time, and less prints).
    4. Move dict benchmark to REDIS_TEST.
    5. fix some leaks in tests
    6. make quicklist tests run on a specific fill set of options rather than huge ranges
    7. move some prints in quicklist test outside their loops to reduce prints
    8. removing sds.h from dict.c since it is now used in both redis-server and
       redis-cli (uses hiredis sds)

diff --git a/src/quicklist.c b/src/quicklist.c
--- a/src/quicklist.c
+++ b/src/quicklist.c
@@ -1509,35 +1509,33 @@
 void quicklistBookmarksClear(quicklist *ql) {
     while (ql->bookmark_count)
         zfree(ql->bookmarks[--ql->bookmark_count].name);
     /* NOTE: We do not shrink (realloc) the quick list. main use case for this
      * function is just before releasing the allocation. */
 }
 
 /* The rest of this file is test cases and test helpers. */
 #ifdef REDIS_TEST
 #include <stdint.h>
 #include <sys/time.h>
 
 #define yell(str, ...) printf("ERROR! " str "\n\n", __VA_ARGS__)
 
-#define OK printf("\tOK\n")
-
 #define ERROR                                                                  \
     do {                                                                       \
         printf("\tERROR!\n");                                                  \
         err++;                                                                 \
     } while (0)
 
 #define ERR(x, ...)                                                            \
     do {                                                                       \
         printf("%s:%s:%d:\t", __FILE__, __func__, __LINE__);                   \
         printf("ERROR! " x "\n", __VA_ARGS__);                                 \
         err++;                                                                 \
     } while (0)
 
 #define TEST(name) printf("test â %s\n", name);
 #define TEST_DESC(name, ...) printf("test â " name "\n", __VA_ARGS__);
 
 #define QL_TEST_VERBOSE 0
 
 #define UNUSED(x) (void)(x)
commit aab479f8cfaa4493f5618ba05cfec0e2b406e77c
Date:   Tue Feb 16 22:17:38 2021 +0800

    Optimize listpack for stream usage to avoid repeated reallocs (#6281)
    
    Avoid repeated reallocs growing the listpack while entries are being added.
    This is done by pre-allocating the listpack to near maximum size, and using
    malloc_size to check if it needs realloc or not.
    When the listpack reaches the maximum number of entries, we shrink it to fit it's used size.
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor@zuiderkwast.se>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/listpack.c b/src/listpack.c
--- a/src/listpack.c
+++ b/src/listpack.c
@@ -233,4 +236,5 @@
 void lpFree(unsigned char *lp) {
     lp_free(lp);
 }
 
+/* Shrink the memory to fit. */
[INCR] **new** commit e5d50b236cd2ae81cbe901fe1f44e8c285f8f2dc
Date:   Thu Apr 1 13:50:23 2021 +0800

    reuse existing range comparators in the zset (#8714)
    
    There are 2 common range comparators for skiplist: zslValueGteMin and
    zslValueLteMax, but they're not being reused in zslDeleteRangeByScore
    
    This is a small change to make code cleaner.

diff --git a/src/t_zset.c b/src/t_zset.c
--- a/src/t_zset.c
+++ b/src/t_zset.c
@@ -384,31 +384,28 @@
 unsigned long zslDeleteRangeByScore(zskiplist *zsl, zrangespec *range, dict *dict) {
     zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;
     unsigned long removed = 0;
     int i;
 
     x = zsl->header;
     for (i = zsl->level-1; i >= 0; i--) {
-        while (x->level[i].forward && (range->minex ?
-            x->level[i].forward->score <= range->min :
-            x->level[i].forward->score < range->min))
+        while (x->level[i].forward &&
+            !zslValueGteMin(x->level[i].forward->score, range))
                 x = x->level[i].forward;
         update[i] = x;
     }
 
     /* Current node is the last with score < or <= min. */
     x = x->level[0].forward;
 
     /* Delete nodes while in range. */
-    while (x &&
-           (range->maxex ? x->score < range->max : x->score <= range->max))
-    {
+    while (x && zslValueLteMax(x->score, range)) {
         zskiplistNode *next = x->level[0].forward;
         zslDeleteNode(zsl,x,update);
         dictDelete(dict,x->ele);
         zslFreeNode(x); /* Here is where x->ele is actually released. */
         removed++;
         x = next;
     }
     return removed;
 }
 
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -302,8 +309,10 @@
 void freeListObject(robj *o) {
     if (o->encoding == OBJ_ENCODING_QUICKLIST) {
         quicklistRelease(o->ptr);
+    } else if (o->encoding == OBJ_ENCODING_LISTPACK) {
+        lpFree(o->ptr);
     } else {
         serverPanic("Unknown list encoding type");
     }
 }
 
[FUNC] **new** commit 4e472a1a7fc0dc2c7da2b48ac7342e9385b4f92a
Date:   Wed Nov 9 18:50:07 2022 +0100

    Listpack encoding for sets (#11290)
    
    Small sets with not only integer elements are listpack encoded, by default
    up to 128 elements, max 64 bytes per element, new config `set-max-listpack-entries`
    and `set-max-listpack-value`. This saves memory for small sets compared to using a hashtable.
    
    Sets with only integers, even very small sets, are still intset encoded (up to 1G
    limit, etc.). Larger sets are hashtable encoded.
    
    This PR increments the RDB version, and has an effect on OBJECT ENCODING
    
    Possible conversions when elements are added:
    
        intset -> listpack
        listpack -> hashtable
        intset -> hashtable
    
    Note: No conversion happens when elements are deleted. If all elements are
    deleted and then added again, the set is deleted and recreated, thus implicitly
    converted to a smaller encoding.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -303,13 +310,14 @@
 void freeSetObject(robj *o) {
     switch (o->encoding) {
     case OBJ_ENCODING_HT:
         dictRelease((dict*) o->ptr);
         break;
     case OBJ_ENCODING_INTSET:
+    case OBJ_ENCODING_LISTPACK:
         zfree(o->ptr);
         break;
     default:
         serverPanic("Unknown set encoding type");
     }
 }
 
commit 3ca6972ecd3e9963f65b9cb1ff050ad60f03563e
Date:   Thu Sep 9 23:18:53 2021 +0800

    Replace all usage of ziplist with listpack for t_zset (#9366)
    
    Part two of implementing #8702 (zset), after #8887.
    
    ## Description of the feature
    Replaced all uses of ziplist with listpack in t_zset, and optimized some of the code to optimize performance.
    
    ## Rdb format changes
    New `RDB_TYPE_ZSET_LISTPACK` rdb type.
    
    ## Rdb loading improvements:
    1) Pre-expansion of dict for validation of duplicate data for listpack and ziplist.
    2) Simplifying the release of empty key objects when RDB loading.
    3) Unify ziplist and listpack data verify methods for zset and hash, and move code to rdb.c.
    
    ## Interface changes
    1) New `zset-max-listpack-entries` config is an alias for `zset-max-ziplist-entries` (same with `zset-max-listpack-value`).
    2) OBJECT ENCODING will return listpack instead of ziplist.
    
    ## Listpack improvements:
    1) Add `lpDeleteRange` and `lpDeleteRangeWithEntry` functions to delete a range of entries from listpack.
    2) Improve the performance of `lpCompare`, converting from string to integer is faster than converting from integer to string.
    3) Replace `snprintf` with `ll2string` to improve performance in converting numbers to strings in `lpGet()`.
    
    ## Zset improvements:
    1) Improve the performance of `zzlFind` method, use `lpFind` instead of `lpCompare` in a loop.
    2) Use `lpDeleteRangeWithEntry` instead of `lpDelete` twice to delete a element of zset.
    
    ## Tests
    1) Add some unittests for `lpDeleteRange` and `lpDeleteRangeWithEntry` function.
    2) Add zset RDB loading test.
    3) Add benchmark test for `lpCompare` and `ziplsitCompare`.
    4) Add empty listpack zset corrupt dump test.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -323,17 +323,17 @@
 void freeZsetObject(robj *o) {
     zset *zs;
     switch (o->encoding) {
     case OBJ_ENCODING_SKIPLIST:
         zs = o->ptr;
         dictRelease(zs->dict);
         zslFree(zs->zsl);
         zfree(zs);
         break;
-    case OBJ_ENCODING_ZIPLIST:
+    case OBJ_ENCODING_LISTPACK:
         zfree(o->ptr);
         break;
     default:
         serverPanic("Unknown sorted set encoding");
     }
 }
 
commit 02fd76b97cbc5b8ad6f4c81c8538f02c76cbed46
Date:   Tue Aug 10 14:18:49 2021 +0800

    Replace all usage of ziplist with listpack for t_hash (#8887)
    
    Part one of implementing #8702 (taking hashes first before other types)
    
    ## Description of the feature
    1. Change ziplist encoded hash objects to listpack encoding.
    2. Convert existing ziplists on RDB loading time. an O(n) operation.
    
    ## Rdb format changes
    1. Add RDB_TYPE_HASH_LISTPACK rdb type.
    2. Bump RDB_VERSION to 10
    
    ## Interface changes
    1. New `hash-max-listpack-entries` config is an alias for `hash-max-ziplist-entries` (same with `hash-max-listpack-value`)
    2. OBJECT ENCODING will return `listpack` instead of `ziplist`
    
    ## Listpack improvements:
    1. Support direct insert, replace integer element (rather than convert back and forth from string)
    3. Add more listpack capabilities to match the ziplist ones (like `lpFind`, `lpRandomPairs` and such)
    4. Optimize element length fetching, avoid multiple calculations
    5. Use inline to avoid function call overhead.
    
    ## Tests
    1. Add a new test to the RDB load time conversion
    2. Adding the listpack unit tests. (based on the one in ziplist.c)
    3. Add a few "corrupt payload: fuzzer findings" tests, and slightly modify existing ones.
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -340,14 +340,14 @@
 void freeHashObject(robj *o) {
     switch (o->encoding) {
     case OBJ_ENCODING_HT:
         dictRelease((dict*) o->ptr);
         break;
-    case OBJ_ENCODING_ZIPLIST:
-        zfree(o->ptr);
+    case OBJ_ENCODING_LISTPACK:
+        lpFree(o->ptr);
         break;
     default:
         serverPanic("Unknown hash encoding type");
         break;
     }
 }
 
[PERF] **new** commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -361,19 +361,20 @@
 void decrRefCount(robj *o) {
     if (o->refcount == 1) {
         switch(o->type) {
         case OBJ_STRING: freeStringObject(o); break;
         case OBJ_LIST: freeListObject(o); break;
         case OBJ_SET: freeSetObject(o); break;
         case OBJ_ZSET: freeZsetObject(o); break;
         case OBJ_HASH: freeHashObject(o); break;
         case OBJ_MODULE: freeModuleObject(o); break;
         case OBJ_STREAM: freeStreamObject(o); break;
         default: serverPanic("Unknown object type"); break;
         }
         zfree(o);
     } else {
         if (o->refcount <= 0) serverPanic("decrRefCount against refcount <= 0");
         if (o->refcount != OBJ_SHARED_REFCOUNT) o->refcount--;
     }
 }
 
+/* See dismissObject() */
commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +381,5 @@
+void dismissSds(sds s) {
+    dismissMemory(sdsAllocPtr(s), sdsAllocSize(s));
+}
+
+/* See dismissObject() */
commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +386,7 @@
+void dismissStringObject(robj *o) {
+    if (o->encoding == OBJ_ENCODING_RAW) {
+        dismissSds(o->ptr);
+    }
+}
+
+/* See dismissObject() */
commit 2168ccc661791ced6271c5e4ab0f5eb60b1559e2
Date:   Thu Nov 17 02:29:46 2022 +0800

    Add listpack encoding for list (#11303)
    
    Improve memory efficiency of list keys
    
    ## Description of the feature
    The new listpack encoding uses the old `list-max-listpack-size` config
    to perform the conversion, which we can think it of as a node inside a
    quicklist, but without 80 bytes overhead (internal fragmentation included)
    of quicklist and quicklistNode structs.
    For example, a list key with 5 items of 10 chars each, now takes 128 bytes
    instead of 208 it used to take.
    
    ## Conversion rules
    * Convert listpack to quicklist
      When the listpack length or size reaches the `list-max-listpack-size` limit,
      it will be converted to a quicklist.
    * Convert quicklist to listpack
      When a quicklist has only one node, and its length or size is reduced to half
      of the `list-max-listpack-size` limit, it will be converted to a listpack.
      This is done to avoid frequent conversions when we add or remove at the bounding size or length.
    
    ## Interface changes
    1. add list entry param to listTypeSetIteratorDirection
        When list encoding is listpack, `listTypeIterator->lpi` points to the next entry of current entry,
        so when changing the direction, we need to use the current node (listTypeEntry->p) to
        update `listTypeIterator->lpi` to the next node in the reverse direction.
    
    ## Benchmark
    ### Listpack VS Quicklist with one node
    * LPUSH - roughly 0.3% improvement
    * LRANGE - roughly 13% improvement
    
    ### Both are quicklist
    * LRANGE - roughly 3% improvement
    * LRANGE without pipeline - roughly 3% improvement
    
    From the benchmark, as we can see from the results
    1. When list is quicklist encoding, LRANGE improves performance by <5%.
    2. When list is listpack encoding, LRANGE improves performance by ~13%,
       the main enhancement is brought by `addListListpackRangeReply()`.
    
    ## Memory usage
    1M lists(key:0~key:1000000) with 5 items of 10 chars ("hellohello") each.
    shows memory usage down by 35.49%, from 214MB to 138MB.
    
    ## Note
    1. Add conversion callback to support doing some work before conversion
        Since the quicklist iterator decompresses the current node when it is released, we can
        no longer decompress the quicklist after we convert the list.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -409,23 +418,25 @@
 void dismissListObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_QUICKLIST) {
         quicklist *ql = o->ptr;
         serverAssert(ql->len != 0);
         /* We iterate all nodes only when average node size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / ql->len >= server.page_size) {
             quicklistNode *node = ql->head;
             while (node) {
                 if (quicklistNodeIsCompressed(node)) {
                     dismissMemory(node->entry, ((quicklistLZF*)node->entry)->sz);
                 } else {
                     dismissMemory(node->entry, node->sz);
                 }
                 node = node->next;
             }
         }
+    } else if (o->encoding == OBJ_ENCODING_LISTPACK) {
+        dismissMemory(o->ptr, lpBytes((unsigned char*)o->ptr));
     } else {
         serverPanic("Unknown list encoding type");
     }
 }
 
 /* See dismissObject() */

commit f27083a4a8a6682e391a533724c904c69852c0a0
Date:   Wed Nov 3 20:47:18 2021 +0200

    Add support for list type to store elements larger than 4GB (#9357)
    
    Redis lists are stored in quicklist, which is currently a linked list of ziplists.
    Ziplists are limited to storing elements no larger than 4GB, so when bigger
    items are added they're getting truncated.
    This PR changes quicklists so that they're capable of storing large items
    in quicklist nodes that are plain string buffers rather than ziplist.
    
    As part of the PR there were few other changes in redis:
    1. new DEBUG sub-commands:
       - QUICKLIST-PACKED-THRESHOLD - set the threshold of for the node type to
         be plan or ziplist. default (1GB)
       - QUICKLIST <key> - Shows low level info about the quicklist encoding of <key>
    2. rdb format change:
       - A new type was added - RDB_TYPE_LIST_QUICKLIST_2 .
       - container type (packed / plain) was added to the beginning of the rdb object
         (before the actual node list).
    3. testing:
       - Tests that requires over 100MB will be by default skipped. a new flag was
         added to 'runtest' to run the large memory tests (not used by default)
    
    Co-authored-by: sundb <sundbcn@gmail.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -408,23 +408,23 @@
 void dismissListObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_QUICKLIST) {
         quicklist *ql = o->ptr;
         serverAssert(ql->len != 0);
         /* We iterate all nodes only when average node size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / ql->len >= server.page_size) {
             quicklistNode *node = ql->head;
             while (node) {
                 if (quicklistNodeIsCompressed(node)) {
-                    dismissMemory(node->zl, ((quicklistLZF*)node->zl)->sz);
+                    dismissMemory(node->entry, ((quicklistLZF*)node->entry)->sz);
                 } else {
-                    dismissMemory(node->zl, node->sz);
+                    dismissMemory(node->entry, node->sz);
                 }
                 node = node->next;
             }
         }
     } else {
         serverPanic("Unknown list encoding type");
     }
 }
 
 /* See dismissObject() */

[CORR] **new** commit 5705cec68e2b93ace879cc1c8d05aca19bcfd188
Date:   Tue Aug 10 21:54:19 2021 +0800

    Fix missing dismiss hash listpack memory due to ziplist->listpack migration (#9353)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -408,21 +408,23 @@
 void dismissListObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_QUICKLIST) {
         quicklist *ql = o->ptr;
         serverAssert(ql->len != 0);
         /* We iterate all nodes only when average node size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / ql->len >= server.page_size) {
             quicklistNode *node = ql->head;
             while (node) {
                 if (quicklistNodeIsCompressed(node)) {
                     dismissMemory(node->zl, ((quicklistLZF*)node->zl)->sz);
                 } else {
                     dismissMemory(node->zl, node->sz);
                 }
                 node = node->next;
             }
         }
+    } else {
+        serverPanic("Unknown list encoding type");
     }
 }
 
 /* See dismissObject() */

commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +393,21 @@
+void dismissListObject(robj *o, size_t size_hint) {
+    if (o->encoding == OBJ_ENCODING_QUICKLIST) {
+        quicklist *ql = o->ptr;
+        serverAssert(ql->len != 0);
+        /* We iterate all nodes only when average node size is bigger than a
+         * page size, and there's a high chance we'll actually dismiss something. */
+        if (size_hint / ql->len >= server.page_size) {
+            quicklistNode *node = ql->head;
+            while (node) {
+                if (quicklistNodeIsCompressed(node)) {
+                    dismissMemory(node->zl, ((quicklistLZF*)node->zl)->sz);
+                } else {
+                    dismissMemory(node->zl, node->sz);
+                }
+                node = node->next;
+            }
+        }
+    }
+}
+
+/* See dismissObject() */
commit 4e472a1a7fc0dc2c7da2b48ac7342e9385b4f92a
Date:   Wed Nov 9 18:50:07 2022 +0100

    Listpack encoding for sets (#11290)
    
    Small sets with not only integer elements are listpack encoded, by default
    up to 128 elements, max 64 bytes per element, new config `set-max-listpack-entries`
    and `set-max-listpack-value`. This saves memory for small sets compared to using a hashtable.
    
    Sets with only integers, even very small sets, are still intset encoded (up to 1G
    limit, etc.). Larger sets are hashtable encoded.
    
    This PR increments the RDB version, and has an effect on OBJECT ENCODING
    
    Possible conversions when elements are added:
    
        intset -> listpack
        listpack -> hashtable
        intset -> hashtable
    
    Note: No conversion happens when elements are deleted. If all elements are
    deleted and then added again, the set is deleted and recreated, thus implicitly
    converted to a smaller encoding.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -424,26 +432,28 @@
 void dismissSetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_HT) {
         dict *set = o->ptr;
         serverAssert(dictSize(set) != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / dictSize(set) >= server.page_size) {
             dictEntry *de;
             dictIterator *di = dictGetIterator(set);
             while ((de = dictNext(di)) != NULL) {
                 dismissSds(dictGetKey(de));
             }
             dictReleaseIterator(di);
         }
 
         /* Dismiss hash table memory. */
         dismissMemory(set->ht_table[0], DICTHT_SIZE(set->ht_size_exp[0])*sizeof(dictEntry*));
         dismissMemory(set->ht_table[1], DICTHT_SIZE(set->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_INTSET) {
         dismissMemory(o->ptr, intsetBlobLen((intset*)o->ptr));
+    } else if (o->encoding == OBJ_ENCODING_LISTPACK) {
+        dismissMemory(o->ptr, lpBytes((unsigned char *)o->ptr));
     } else {
         serverPanic("Unknown set encoding type");
     }
 }
 
 /* See dismissObject() */

commit 5705cec68e2b93ace879cc1c8d05aca19bcfd188
Date:   Tue Aug 10 21:54:19 2021 +0800

    Fix missing dismiss hash listpack memory due to ziplist->listpack migration (#9353)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -429,24 +431,26 @@
 void dismissSetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_HT) {
         dict *set = o->ptr;
         serverAssert(dictSize(set) != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / dictSize(set) >= server.page_size) {
             dictEntry *de;
             dictIterator *di = dictGetIterator(set);
             while ((de = dictNext(di)) != NULL) {
                 dismissSds(dictGetKey(de));
             }
             dictReleaseIterator(di);
         }
 
         /* Dismiss hash table memory. */
         dismissMemory(set->ht_table[0], DICTHT_SIZE(set->ht_size_exp[0])*sizeof(dictEntry*));
         dismissMemory(set->ht_table[1], DICTHT_SIZE(set->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_INTSET) {
         dismissMemory(o->ptr, intsetBlobLen((intset*)o->ptr));
+    } else {
+        serverPanic("Unknown set encoding type");
     }
 }
 
 /* See dismissObject() */

[CORR] **new** commit d32f8641ed5cda76234f7405d2b65e167223a9f1
Date:   Thu Aug 5 09:02:30 2021 +0300

    fix dict access broken by #9228  (#9319)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -414,24 +414,24 @@
 void dismissSetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_HT) {
         dict *set = o->ptr;
         serverAssert(dictSize(set) != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / dictSize(set) >= server.page_size) {
             dictEntry *de;
             dictIterator *di = dictGetIterator(set);
             while ((de = dictNext(di)) != NULL) {
                 dismissSds(dictGetKey(de));
             }
             dictReleaseIterator(di);
         }
 
         /* Dismiss hash table memory. */
-        dismissMemory(set->ht[0].table, set->ht[0].size*sizeof(dictEntry*));
-        dismissMemory(set->ht[1].table, set->ht[1].size*sizeof(dictEntry*));
+        dismissMemory(set->ht_table[0], DICTHT_SIZE(set->ht_size_exp[0])*sizeof(dictEntry*));
+        dismissMemory(set->ht_table[1], DICTHT_SIZE(set->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_INTSET) {
         dismissMemory(o->ptr, intsetBlobLen((intset*)o->ptr));
     }
 }
 
 /* See dismissObject() */

commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +414,24 @@
+void dismissSetObject(robj *o, size_t size_hint) {
+    if (o->encoding == OBJ_ENCODING_HT) {
+        dict *set = o->ptr;
+        serverAssert(dictSize(set) != 0);
+        /* We iterate all nodes only when average member size is bigger than a
+         * page size, and there's a high chance we'll actually dismiss something. */
+        if (size_hint / dictSize(set) >= server.page_size) {
+            dictEntry *de;
+            dictIterator *di = dictGetIterator(set);
+            while ((de = dictNext(di)) != NULL) {
+                dismissSds(dictGetKey(de));
+            }
+            dictReleaseIterator(di);
+        }
+
+        /* Dismiss hash table memory. */
+        dismissMemory(set->ht[0].table, set->ht[0].size*sizeof(dictEntry*));
+        dismissMemory(set->ht[1].table, set->ht[1].size*sizeof(dictEntry*));
+    } else if (o->encoding == OBJ_ENCODING_INTSET) {
+        dismissMemory(o->ptr, intsetBlobLen((intset*)o->ptr));
+    }
+}
+
+/* See dismissObject() */
commit 3ca6972ecd3e9963f65b9cb1ff050ad60f03563e
Date:   Thu Sep 9 23:18:53 2021 +0800

    Replace all usage of ziplist with listpack for t_zset (#9366)
    
    Part two of implementing #8702 (zset), after #8887.
    
    ## Description of the feature
    Replaced all uses of ziplist with listpack in t_zset, and optimized some of the code to optimize performance.
    
    ## Rdb format changes
    New `RDB_TYPE_ZSET_LISTPACK` rdb type.
    
    ## Rdb loading improvements:
    1) Pre-expansion of dict for validation of duplicate data for listpack and ziplist.
    2) Simplifying the release of empty key objects when RDB loading.
    3) Unify ziplist and listpack data verify methods for zset and hash, and move code to rdb.c.
    
    ## Interface changes
    1) New `zset-max-listpack-entries` config is an alias for `zset-max-ziplist-entries` (same with `zset-max-listpack-value`).
    2) OBJECT ENCODING will return listpack instead of ziplist.
    
    ## Listpack improvements:
    1) Add `lpDeleteRange` and `lpDeleteRangeWithEntry` functions to delete a range of entries from listpack.
    2) Improve the performance of `lpCompare`, converting from string to integer is faster than converting from integer to string.
    3) Replace `snprintf` with `ll2string` to improve performance in converting numbers to strings in `lpGet()`.
    
    ## Zset improvements:
    1) Improve the performance of `zzlFind` method, use `lpFind` instead of `lpCompare` in a loop.
    2) Use `lpDeleteRangeWithEntry` instead of `lpDelete` twice to delete a element of zset.
    
    ## Tests
    1) Add some unittests for `lpDeleteRange` and `lpDeleteRangeWithEntry` function.
    2) Add zset RDB loading test.
    3) Add benchmark test for `lpCompare` and `ziplsitCompare`.
    4) Add empty listpack zset corrupt dump test.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -457,27 +457,27 @@
 void dismissZsetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_SKIPLIST) {
         zset *zs = o->ptr;
         zskiplist *zsl = zs->zsl;
         serverAssert(zsl->length != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / zsl->length >= server.page_size) {
             zskiplistNode *zn = zsl->tail;
             while (zn != NULL) {
                 dismissSds(zn->ele);
                 zn = zn->backward;
             }
         }
 
         /* Dismiss hash table memory. */
         dict *d = zs->dict;
         dismissMemory(d->ht_table[0], DICTHT_SIZE(d->ht_size_exp[0])*sizeof(dictEntry*));
         dismissMemory(d->ht_table[1], DICTHT_SIZE(d->ht_size_exp[1])*sizeof(dictEntry*));
-    } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
-        dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
+    } else if (o->encoding == OBJ_ENCODING_LISTPACK) {
+        dismissMemory(o->ptr, lpBytes((unsigned char*)o->ptr));
     } else {
         serverPanic("Unknown zset encoding type");
     }
 }
 
 /* See dismissObject() */

commit 5705cec68e2b93ace879cc1c8d05aca19bcfd188
Date:   Tue Aug 10 21:54:19 2021 +0800

    Fix missing dismiss hash listpack memory due to ziplist->listpack migration (#9353)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -453,25 +457,27 @@
 void dismissZsetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_SKIPLIST) {
         zset *zs = o->ptr;
         zskiplist *zsl = zs->zsl;
         serverAssert(zsl->length != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / zsl->length >= server.page_size) {
             zskiplistNode *zn = zsl->tail;
             while (zn != NULL) {
                 dismissSds(zn->ele);
                 zn = zn->backward;
             }
         }
 
         /* Dismiss hash table memory. */
         dict *d = zs->dict;
         dismissMemory(d->ht_table[0], DICTHT_SIZE(d->ht_size_exp[0])*sizeof(dictEntry*));
         dismissMemory(d->ht_table[1], DICTHT_SIZE(d->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
         dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
+    } else {
+        serverPanic("Unknown zset encoding type");
     }
 }
 
 /* See dismissObject() */

commit d32f8641ed5cda76234f7405d2b65e167223a9f1
Date:   Thu Aug 5 09:02:30 2021 +0300

    fix dict access broken by #9228  (#9319)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -438,25 +438,25 @@
 void dismissZsetObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_SKIPLIST) {
         zset *zs = o->ptr;
         zskiplist *zsl = zs->zsl;
         serverAssert(zsl->length != 0);
         /* We iterate all nodes only when average member size is bigger than a
          * page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / zsl->length >= server.page_size) {
             zskiplistNode *zn = zsl->tail;
             while (zn != NULL) {
                 dismissSds(zn->ele);
                 zn = zn->backward;
             }
         }
 
         /* Dismiss hash table memory. */
         dict *d = zs->dict;
-        dismissMemory(d->ht[0].table, d->ht[0].size*sizeof(dictEntry*));
-        dismissMemory(d->ht[1].table, d->ht[1].size*sizeof(dictEntry*));
+        dismissMemory(d->ht_table[0], DICTHT_SIZE(d->ht_size_exp[0])*sizeof(dictEntry*));
+        dismissMemory(d->ht_table[1], DICTHT_SIZE(d->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
         dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
     }
 }
 
 /* See dismissObject() */

commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +438,25 @@
+void dismissZsetObject(robj *o, size_t size_hint) {
+    if (o->encoding == OBJ_ENCODING_SKIPLIST) {
+        zset *zs = o->ptr;
+        zskiplist *zsl = zs->zsl;
+        serverAssert(zsl->length != 0);
+        /* We iterate all nodes only when average member size is bigger than a
+         * page size, and there's a high chance we'll actually dismiss something. */
+        if (size_hint / zsl->length >= server.page_size) {
+            zskiplistNode *zn = zsl->tail;
+            while (zn != NULL) {
+                dismissSds(zn->ele);
+                zn = zn->backward;
+            }
+        }
+
+        /* Dismiss hash table memory. */
+        dict *d = zs->dict;
+        dismissMemory(d->ht[0].table, d->ht[0].size*sizeof(dictEntry*));
+        dismissMemory(d->ht[1].table, d->ht[1].size*sizeof(dictEntry*));
+    } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
+        dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
+    }
+}
+
+/* See dismissObject() */
commit 5705cec68e2b93ace879cc1c8d05aca19bcfd188
Date:   Tue Aug 10 21:54:19 2021 +0800

    Fix missing dismiss hash listpack memory due to ziplist->listpack migration (#9353)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -478,26 +484,28 @@
 void dismissHashObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_HT) {
         dict *d = o->ptr;
         serverAssert(dictSize(d) != 0);
         /* We iterate all fields only when average field/value size is bigger than
          * a page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / dictSize(d) >= server.page_size) {
             dictEntry *de;
             dictIterator *di = dictGetIterator(d);
             while ((de = dictNext(di)) != NULL) {
                 /* Only dismiss values memory since the field size
                  * usually is small. */
                 dismissSds(dictGetVal(de));
             }
             dictReleaseIterator(di);
         }
 
         /* Dismiss hash table memory. */
         dismissMemory(d->ht_table[0], DICTHT_SIZE(d->ht_size_exp[0])*sizeof(dictEntry*));
         dismissMemory(d->ht_table[1], DICTHT_SIZE(d->ht_size_exp[1])*sizeof(dictEntry*));
-    } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
-        dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
+    } else if (o->encoding == OBJ_ENCODING_LISTPACK) {
+        dismissMemory(o->ptr, lpBytes((unsigned char*)o->ptr));
+    } else {
+        serverPanic("Unknown hash encoding type");
     }
 }
 
 /* See dismissObject() */

commit d32f8641ed5cda76234f7405d2b65e167223a9f1
Date:   Thu Aug 5 09:02:30 2021 +0300

    fix dict access broken by #9228  (#9319)

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -463,26 +463,26 @@
 void dismissHashObject(robj *o, size_t size_hint) {
     if (o->encoding == OBJ_ENCODING_HT) {
         dict *d = o->ptr;
         serverAssert(dictSize(d) != 0);
         /* We iterate all fields only when average field/value size is bigger than
          * a page size, and there's a high chance we'll actually dismiss something. */
         if (size_hint / dictSize(d) >= server.page_size) {
             dictEntry *de;
             dictIterator *di = dictGetIterator(d);
             while ((de = dictNext(di)) != NULL) {
                 /* Only dismiss values memory since the field size
                  * usually is small. */
                 dismissSds(dictGetVal(de));
             }
             dictReleaseIterator(di);
         }
 
         /* Dismiss hash table memory. */
-        dismissMemory(d->ht[0].table, d->ht[0].size*sizeof(dictEntry*));
-        dismissMemory(d->ht[1].table, d->ht[1].size*sizeof(dictEntry*));
+        dismissMemory(d->ht_table[0], DICTHT_SIZE(d->ht_size_exp[0])*sizeof(dictEntry*));
+        dismissMemory(d->ht_table[1], DICTHT_SIZE(d->ht_size_exp[1])*sizeof(dictEntry*));
     } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
         dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
     }
 }
 
 /* See dismissObject() */

commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +463,26 @@
+void dismissHashObject(robj *o, size_t size_hint) {
+    if (o->encoding == OBJ_ENCODING_HT) {
+        dict *d = o->ptr;
+        serverAssert(dictSize(d) != 0);
+        /* We iterate all fields only when average field/value size is bigger than
+         * a page size, and there's a high chance we'll actually dismiss something. */
+        if (size_hint / dictSize(d) >= server.page_size) {
+            dictEntry *de;
+            dictIterator *di = dictGetIterator(d);
+            while ((de = dictNext(di)) != NULL) {
+                /* Only dismiss values memory since the field size
+                 * usually is small. */
+                dismissSds(dictGetVal(de));
+            }
+            dictReleaseIterator(di);
+        }
+
+        /* Dismiss hash table memory. */
+        dismissMemory(d->ht[0].table, d->ht[0].size*sizeof(dictEntry*));
+        dismissMemory(d->ht[1].table, d->ht[1].size*sizeof(dictEntry*));
+    } else if (o->encoding == OBJ_ENCODING_ZIPLIST) {
+        dismissMemory(o->ptr, ziplistBlobLen((unsigned char*)o->ptr));
+    }
+}
+
+/* See dismissObject() */
commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,0 +489,32 @@
+void dismissStreamObject(robj *o, size_t size_hint) {
+    stream *s = o->ptr;
+    rax *rax = s->rax;
+    if (raxSize(rax) == 0) return;
+
+    /* Iterate only on stream entries, although size_hint may include serialized
+     * consumer groups info, but usually, stream entries take up most of
+     * the space. */
+    if (size_hint / raxSize(rax) >= server.page_size) {
+        raxIterator ri;
+        raxStart(&ri,rax);
+        raxSeek(&ri,"^",NULL,0);
+        while (raxNext(&ri)) {
+            dismissMemory(ri.data, lpBytes(ri.data));
+        }
+        raxStop(&ri);
+    }
+}
+
+/* When creating a snapshot in a fork child process, the main process and child
+ * process share the same physical memory pages, and if / when the parent
+ * modifies any keys due to write traffic, it'll cause CoW which consume
+ * physical memory. In the child process, after serializing the key and value,
+ * the data is definitely not accessed again, so to avoid unnecessary CoW, we
+ * try to release their memory back to OS. see dismissMemory().
+ *
+ * Because of the cost of iterating all node/field/member/entry of complex data
+ * types, we iterate and dismiss them only when approximate average we estimate
+ * the size of an individual allocation is more than a page size of OS.
+ * 'size_hint' is the size of serialized value. This method is not accurate, but
+ * it can reduce unnecessary iteration for complex data types that are probably
+ * not going to release any memory. */
[CORR] **new** commit 8ab33c18e4c34dbf2e894adca5b9e74fd4348587
Date:   Tue Aug 10 16:32:27 2021 +0800

    fix a compilation error around madvise when make with jemalloc on MacOS (#9350)
    
    We only use MADV_DONTNEED on Linux, that's were it was tested.

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -536,25 +536,25 @@
 void dismissObject(robj *o, size_t size_hint) {
     /* madvise(MADV_DONTNEED) may not work if Transparent Huge Pages is enabled. */
     if (server.thp_enabled) return;
 
-    /* Currently we use zmadvise_dontneed only when we use jemalloc.
+    /* Currently we use zmadvise_dontneed only when we use jemalloc with Linux.
      * so we avoid these pointless loops when they're not going to do anything. */
-#if defined(USE_JEMALLOC)
+#if defined(USE_JEMALLOC) && defined(__linux__)
     if (o->refcount != 1) return;
     switch(o->type) {
         case OBJ_STRING: dismissStringObject(o); break;
         case OBJ_LIST: dismissListObject(o, size_hint); break;
         case OBJ_SET: dismissSetObject(o, size_hint); break;
         case OBJ_ZSET: dismissZsetObject(o, size_hint); break;
         case OBJ_HASH: dismissHashObject(o, size_hint); break;
         case OBJ_STREAM: dismissStreamObject(o, size_hint); break;
         default: break;
     }
 #else
     UNUSED(o); UNUSED(size_hint);
 #endif
 }
 
 /* This variant of decrRefCount() gets its argument as void, and is useful
  * as free method in data structures that expect a 'void free_object(void*)'
  * prototype for the free method. */

commit d4bca53cd9879e0296bfa0a7c17df79dd52496ae
Date:   Thu Aug 5 04:01:46 2021 +0800

    Use madvise(MADV_DONTNEED) to release memory to reduce COW (#8974)
    
    ## Backgroud
    As we know, after `fork`, one process will copy pages when writing data to these
    pages(CoW), and another process still keep old pages, they totally cost more memory.
    For redis, we suffered that redis consumed much memory when the fork child is serializing
    key/values, even that maybe cause OOM.
    
    But actually we find, in redis fork child process, the child process don't need to keep some
    memory and parent process may write or update that, for example, child process will never
    access the key-value that is serialized but users may update it in parent process.
    So we think it may reduce COW if the child process release memory that it is not needed.
    
    ## Implementation
    For releasing key value in child process, we may think we call `decrRefCount` to free memory,
    but i find the fork child process still use much memory when we don't write any data to redis,
    and it costs much more time that slows down bgsave. Maybe because memory allocator doesn't
    really release memory to OS, and it may modify some inner data for this free operation, especially
    when we free small objects.
    
    Moreover, CoW is based on  pages, so it is a easy way that we only free the memory bulk that is
    not less than kernel page size. madvise(MADV_DONTNEED) can quickly release specified region
    pages to OS bypassing memory allocator, and allocator still consider that this memory still is used
    and don't change its inner data.
    
    There are some buffers we can release in the fork child process:
    - **Serialized key-values**
      the fork child process never access serialized key-values, so we try to free them.
      Because we only can release big bulk memory, and it is time consumed to iterate all
      items/members/fields/entries of complex data type. So we decide to iterate them and
      try to release them only when their average size of item/member/field/entry is more
      than page size of OS.
    - **Replication backlog**
      Because replication backlog is a cycle buffer, it will be changed quickly if redis has heavy
      write traffic, but in fork child process, we don't need to access that.
    - **Client buffers**
      If clients have requests during having the fork child process, clients' buffer also be changed
      frequently. The memory includes client query buffer, output buffer, and client struct used memory.
    
    To get child process peak private dirty memory, we need to count peak memory instead
    of last used memory, because the child process may continue to release memory (since
    COW used to only grow till now, the last was equivalent to the peak).
    Also we're adding a new `current_cow_peak` info variable (to complement the existing
    `current_cow_size`)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/object.c b/src/object.c
--- a/src/object.c
+++ b/src/object.c
@@ -380,3 +521,25 @@
+void dismissObject(robj *o, size_t size_hint) {
+    /* madvise(MADV_DONTNEED) may not work if Transparent Huge Pages is enabled. */
+    if (server.thp_enabled) return;
+
+    /* Currently we use zmadvise_dontneed only when we use jemalloc.
+     * so we avoid these pointless loops when they're not going to do anything. */
+#if defined(USE_JEMALLOC)
+    if (o->refcount != 1) return;
+    switch(o->type) {
+        case OBJ_STRING: dismissStringObject(o); break;
+        case OBJ_LIST: dismissListObject(o, size_hint); break;
+        case OBJ_SET: dismissSetObject(o, size_hint); break;
+        case OBJ_ZSET: dismissZsetObject(o, size_hint); break;
+        case OBJ_HASH: dismissHashObject(o, size_hint); break;
+        case OBJ_STREAM: dismissStreamObject(o, size_hint); break;
+        default: break;
+    }
+#else
+    UNUSED(o); UNUSED(size_hint);
+#endif
+}
+
 /* This variant of decrRefCount() gets its argument as void, and is useful
  * as free method in data structures that expect a 'void free_object(void*)'
  * prototype for the free method. */
commit 91d0c758e5453644bb4e784a2af86033ccb971fc
Date:   Thu Nov 4 09:46:50 2021 +0100

    Replica keep serving data during repl-diskless-load=swapdb for better availability (#9323)
    
    For diskless replication in swapdb mode, considering we already spend replica memory
    having a backup of current db to restore in case of failure, we can have the following benefits
    by instead swapping database only in case we succeeded in transferring db from master:
    
    - Avoid `LOADING` response during failed and successful synchronization for cases where the
      replica is already up and running with data.
    - Faster total time of diskless replication, because now we're moving from Transfer + Flush + Load
      time to Transfer + Load only. Flushing the tempDb is done asynchronously after swapping.
    - This could be implemented also for disk replication with similar benefits if consumers are willing
      to spend the extra memory usage.
    
    General notes:
    - The concept of `backupDb` becomes `tempDb` for clarity.
    - Async loading mode will only kick in if the replica is syncing from a master that has the same
      repl-id the one it had before. i.e. the data it's getting belongs to a different time of the same timeline.
    - New property in INFO: `async_loading` to differentiate from the blocking loading
    - Slot to Key mapping is now a field of `redisDb` as it's more natural to access it from both server.db
      and the tempDb that is passed around.
    - Because this is affecting replicas only, we assume that if they are not readonly and write commands
      during replication, they are lost after SYNC same way as before, but we're still denying CONFIG SET
      here anyways to avoid complications.
    
    Considerations for review:
    - We have many cases where server.loading flag is used and even though I tried my best, there may
      be cases where async_loading should be checked as well and cases where it shouldn't (would require
      very good understanding of whole code)
    - Several places that had different behavior depending on the loading flag where actually meant to just
      handle commands coming from the AOF client differently than ones coming from real clients, changed
      to check CLIENT_ID_AOF instead.
    
    **Additional for Release Notes**
    - Bugfix - server.dirty was not incremented for any kind of diskless replication, as effect it wouldn't
      contribute on triggering next database SAVE
    - New flag for RM_GetContextFlags module API: REDISMODULE_CTX_FLAGS_ASYNC_LOADING
    - Deprecated RedisModuleEvent_ReplBackup. Starting from Redis 7.0, we don't fire this event.
      Instead, we have the new RedisModuleEvent_ReplAsyncLoad holding 3 sub-events: STARTED,
      ABORTED and COMPLETED.
    - New module flag REDISMODULE_OPTIONS_HANDLE_REPL_ASYNC_LOAD for RedisModule_SetModuleOptions
      to allow modules to declare they support the diskless replication with async loading (when absent, we fall
      back to disk-based loading).
    
    Co-authored-by: Eduardo Semprebon <edus@saxobank.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -6270,8 +6273,7 @@
-/* Empty the slots-keys map of Redis Cluster. */
-void slotToKeyFlush(void) {
-    memset(&server.cluster->slots_to_keys, 0,
-           sizeof(server.cluster->slots_to_keys));
+void slotToKeyDestroy(redisDb *db) {
+    zfree(db->slots_to_keys);
+    db->slots_to_keys = NULL;
 }
 
 /* Remove all the keys in the specified hash slot.
  * The number of removed items is returned. */

commit f24c63a292e045d4b14b82b25981f00a95c1767a
Date:   Tue Aug 31 08:25:36 2021 +0200

    Slot-to-keys using dict entry metadata (#9356)
    
    * Enhance dict to support arbitrary metadata carried in dictEntry
    
    Co-authored-by: Viktor SÃ¶derqvist <viktor.soderqvist@est.tech>
    
    * Rewrite slot-to-keys mapping to linked lists using dict entry metadata
    
    This is a memory enhancement for Redis Cluster.
    
    The radix tree slots_to_keys (which duplicates all key names prefixed with their
    slot number) is replaced with a linked list for each slot. The dict entries of
    the same cluster slot form a linked list and the pointers are stored as metadata
    in each dict entry of the main DB dict.
    
    This commit also moves the slot-to-key API from db.c to cluster.c.
    
    Co-authored-by: Jim Brunner <brunnerj@amazon.com>

diff --git a/src/cluster.c b/src/cluster.c
--- a/src/cluster.c
+++ b/src/cluster.c
@@ -6102,0 +6176,8 @@
+/* Empty the slots-keys map of Redis Cluster. */
+void slotToKeyFlush(void) {
+    memset(&server.cluster->slots_to_keys, 0,
+           sizeof(server.cluster->slots_to_keys));
+}
+
+/* Remove all the keys in the specified hash slot.
+ * The number of removed items is returned. */
[FUNC] **new** commit 4a27aa4875250c075ad2860e9ecc88d77ef6091b
Date:   Thu Dec 8 19:14:21 2022 +0200

    Fix sentinel issue if replica changes IP (#11590)
    
    As Sentinel supports dynamic IP only when using hostnames, there
    are few leftover addess comparison logic that doesn't take into
    account that the IP might get change.
    
    Co-authored-by: moticless <moticless@github.com>

diff --git a/src/sentinel.c b/src/sentinel.c
--- a/src/sentinel.c
+++ b/src/sentinel.c
@@ -595,14 +595,9 @@
 void releaseSentinelAddr(sentinelAddr *sa) {
     sdsfree(sa->hostname);
     sdsfree(sa->ip);
     zfree(sa);
 }
 
-/* Return non-zero if two addresses are equal. */
-int sentinelAddrIsEqual(sentinelAddr *a, sentinelAddr *b) {
-    return a->port == b->port && !strcasecmp(a->ip,b->ip);
-}
-
 /* Return non-zero if the two addresses are equal, either by address
  * or by hostname if they could not have been resolved.
  */

commit 79f089bdd92348d5fa3965258f539752f2eb8e78
Date:   Sat Jan 29 21:00:29 2022 +0200

    Fixed Sentinel support for hostnames (#10146)
    
    Sentinel tries to resolve instances hostname to IP only during registration.
    It might be that the instance is unavailable during that time, such as
    leader crashed and failover took place. Yet, promoted replica must support:
    
     - Register leader, even if it fails to resolve its hostname during failover
     - Try later to resolve it, if instance is disconnected. Note that
       this condition also support ip-change of an instance.

diff --git a/src/sentinel.c b/src/sentinel.c
--- a/src/sentinel.c
+++ b/src/sentinel.c
@@ -590,11 +596,14 @@
 void releaseSentinelAddr(sentinelAddr *sa) {
     sdsfree(sa->hostname);
     sdsfree(sa->ip);
     zfree(sa);
 }
 
 /* Return non-zero if two addresses are equal. */
 int sentinelAddrIsEqual(sentinelAddr *a, sentinelAddr *b) {
     return a->port == b->port && !strcasecmp(a->ip,b->ip);
 }
 
+/* Return non-zero if the two addresses are equal, either by address
+ * or by hostname if they could not have been resolved.
+ */
[NA] **new** commit d08f0552ee13fc9feaa7afbb2c493d1bf92ee6ac
Date:   Tue Nov 2 16:53:52 2021 +0800

    rebuild replication backlog index when master restart (#9720)
    
    After PR #9166 , replication backlog is not a real block of memory, just contains a
    reference points to replication buffer's block and the blocks index (to accelerate
    search offset when partial sync), so we need update both replication buffer's block's
    offset and replication backlog blocks index's offset when master restart from RDB,
    since the `server.master_repl_offset` is changed.
    The implications of this bug was just a slow search, but not a replication failure.

diff --git a/src/replication.c b/src/replication.c
--- a/src/replication.c
+++ b/src/replication.c
@@ -140,22 +140,25 @@
 void freeReplicationBacklog(void) {
     serverAssert(listLength(server.slaves) == 0);
     if (server.repl_backlog == NULL) return;
 
     /* Decrease the start buffer node reference count. */
     if (server.repl_backlog->ref_repl_buf_node) {
         replBufBlock *o = listNodeValue(
             server.repl_backlog->ref_repl_buf_node);
         serverAssert(o->refcount == 1); /* Last reference. */
         o->refcount--;
     }
 
     /* Replication buffer blocks are completely released when we free the
      * backlog, since the backlog is released only when there are no replicas
      * and the backlog keeps the last reference of all blocks. */
     freeReplicationBacklogRefMemAsync(server.repl_buffer_blocks,
                             server.repl_backlog->blocks_index);
     resetReplicationBuffer();
     zfree(server.repl_backlog);
     server.repl_backlog = NULL;
 }
 
+/* To make search offset from replication buffer blocks quickly
+ * when replicas ask partial resynchronization, we create one index
+ * block every REPL_BACKLOG_INDEX_PER_BLOCKS blocks. */

commit c1718f9d862267bc44b2a326cdc8cb1ca5b81a39
Date:   Mon Oct 25 14:24:31 2021 +0800

    Replication backlog and replicas use one global shared replication buffer (#9166)
    
    ## Background
    For redis master, one replica uses one copy of replication buffer, that is a big waste of memory,
    more replicas more waste, and allocate/free memory for every reply list also cost much.
    If we set client-output-buffer-limit small and write traffic is heavy, master may disconnect with
    replicas and can't finish synchronization with replica. If we set  client-output-buffer-limit big,
    master may be OOM when there are many replicas that separately keep much memory.
    Because replication buffers of different replica client are the same, one simple idea is that
    all replicas only use one replication buffer, that will effectively save memory.
    
    Since replication backlog content is the same as replicas' output buffer, now we
    can discard replication backlog memory and use global shared replication buffer
    to implement replication backlog mechanism.
    
    ## Implementation
    I create one global "replication buffer" which contains content of replication stream.
    The structure of "replication buffer" is similar to the reply list that exists in every client.
    But the node of list is `replBufBlock`, which has `id, repl_offset, refcount` fields.
    ```c
    /* Replication buffer blocks is the list of replBufBlock.
     *
     * +--------------+       +--------------+       +--------------+
     * | refcount = 1 |  ...  | refcount = 0 |  ...  | refcount = 2 |
     * +--------------+       +--------------+       +--------------+
     *      |                                            /       \
     *      |                                           /         \
     *      |                                          /           \
     *  Repl Backlog                               Replia_A      Replia_B
     *
     * Each replica or replication backlog increments only the refcount of the
     * 'ref_repl_buf_node' which it points to. So when replica walks to the next
     * node, it should first increase the next node's refcount, and when we trim
     * the replication buffer nodes, we remove node always from the head node which
     * refcount is 0. If the refcount of the head node is not 0, we must stop
     * trimming and never iterate the next node. */
    
    /* Similar with 'clientReplyBlock', it is used for shared buffers between
     * all replica clients and replication backlog. */
    typedef struct replBufBlock {
        int refcount;           /* Number of replicas or repl backlog using. */
        long long id;           /* The unique incremental number. */
        long long repl_offset;  /* Start replication offset of the block. */
        size_t size, used;
        char buf[];
    } replBufBlock;
    ```
    So now when we feed replication stream into replication backlog and all replicas, we only need
    to feed stream into replication buffer `feedReplicationBuffer`. In this function, we set some fields of
    replication backlog and replicas to references of the global replication buffer blocks. And we also
    need to check replicas' output buffer limit to free if exceeding `client-output-buffer-limit`, and trim
    replication backlog if exceeding `repl-backlog-size`.
    
    When sending reply to replicas, we also need to iterate replication buffer blocks and send its
    content, when totally sending one block for replica, we decrease current node count and
    increase the next current node count, and then free the block which reference is 0 from the
    head of replication buffer blocks.
    
    Since now we use linked list to manage replication backlog, it may cost much time for iterating
    all linked list nodes to find corresponding replication buffer node. So we create a rax tree to
    store some nodes  for index, but to avoid rax tree occupying too much memory, i record
    one per 64 nodes for index.
    
    Currently, to make partial resynchronization as possible as much, we always let replication
    backlog as the last reference of replication buffer blocks, backlog size may exceeds our setting
    if slow replicas that reference vast replication buffer blocks, and this method doesn't increase
    memory usage since they share replication buffer. To avoid freezing server for freeing unreferenced
    replication buffer blocks when we need to trim backlog for exceeding backlog size setting,
    we trim backlog incrementally (free 64 blocks per call now), and make it faster in
    `beforeSleep` (free 640 blocks).
    
    ### Other changes
    - `mem_total_replication_buffers`: we add this field in INFO command, it means the total
      memory of replication buffers used.
    - `mem_clients_slaves`:  now even replica is slow to replicate, and its output buffer memory
      is not 0, but it still may be 0, since replication backlog and replicas share one global replication
      buffer, only if replication buffer memory is more than the repl backlog setting size, we consider
      the excess as replicas' memory. Otherwise, we think replication buffer memory is the consumption
      of repl backlog.
    - Key eviction
      Since all replicas and replication backlog share global replication buffer, we think only the
      part of exceeding backlog size the extra separate consumption of replicas.
      Because we trim backlog incrementally in the background, backlog size may exceeds our
      setting if slow replicas that reference vast replication buffer blocks disconnect.
      To avoid massive eviction loop, we don't count the delayed freed replication backlog into
      used memory even if there are no replicas, i.e. we also regard this memory as replicas's memory.
    - `client-output-buffer-limit` check for replica clients
      It doesn't make sense to set the replica clients output buffer limit lower than the repl-backlog-size
      config (partial sync will succeed and then replica will get disconnected). Such a configuration is
      ignored (the size of repl-backlog-size will be used). This doesn't have memory consumption
      implications since the replica client will share the backlog buffers memory.
    - Drop replication backlog after loading data if needed
      We always create replication backlog if server is a master, we need it because we put DELs in
      it when loading expired keys in RDB, but if RDB doesn't have replication info or there is no rdb,
      it is not possible to support partial resynchronization, to avoid extra memory of replication backlog,
      we drop it.
    - Multi IO threads
     Since all replicas and replication backlog use global replication buffer,  if I/O threads are enabled,
      to guarantee data accessing thread safe, we must let main thread handle sending the output buffer
      to all replicas. But before, other IO threads could handle sending output buffer of all replicas.
    
    ## Other optimizations
    This solution resolve some other problem:
    - When replicas disconnect with master since of out of output buffer limit, releasing the output
      buffer of replicas may freeze server if we set big `client-output-buffer-limit` for replicas, but now,
      it doesn't cause freezing.
    - This implementation may mitigate reply list copy cost time(also freezes server) when one replication
      has huge reply buffer and another replica can copy buffer for full synchronization. now, we just copy
      reference info, it is very light.
    - If we set replication backlog size big, it also may cost much time to copy replication backlog into
      replica's output buffer. But this commit eliminates this problem.
    - Resizing replication backlog size doesn't empty current replication backlog content.

diff --git a/src/replication.c b/src/replication.c
--- a/src/replication.c
+++ b/src/replication.c
@@ -151,6 +140,22 @@
 void freeReplicationBacklog(void) {
     serverAssert(listLength(server.slaves) == 0);
+    if (server.repl_backlog == NULL) return;
+
+    /* Decrease the start buffer node reference count. */
+    if (server.repl_backlog->ref_repl_buf_node) {
+        replBufBlock *o = listNodeValue(
+            server.repl_backlog->ref_repl_buf_node);
+        serverAssert(o->refcount == 1); /* Last reference. */
+        o->refcount--;
+    }
+
+    /* Replication buffer blocks are completely released when we free the
+     * backlog, since the backlog is released only when there are no replicas
+     * and the backlog keeps the last reference of all blocks. */
+    freeReplicationBacklogRefMemAsync(server.repl_buffer_blocks,
+                            server.repl_backlog->blocks_index);
+    resetReplicationBuffer();
     zfree(server.repl_backlog);
     server.repl_backlog = NULL;
 }
 
[NA] **new** commit 72aa37623762a66f7b67251baa56bb7fe6156bc5
Date:   Sun Apr 25 20:50:15 2021 +0800

    Fix comments and typos in sentinel.c. (#8801)

diff --git a/src/replication.c b/src/replication.c
--- a/src/replication.c
+++ b/src/replication.c
@@ -2660,62 +2660,58 @@
 void replicationUnsetMaster(void) {
     if (server.masterhost == NULL) return; /* Nothing to do. */
 
     /* Fire the master link modules event. */
     if (server.repl_state == REPL_STATE_CONNECTED)
         moduleFireServerEvent(REDISMODULE_EVENT_MASTER_LINK_CHANGE,
                               REDISMODULE_SUBEVENT_MASTER_LINK_DOWN,
                               NULL);
 
     /* Clear masterhost first, since the freeClient calls
      * replicationHandleMasterDisconnection which can attempt to re-connect. */
     sdsfree(server.masterhost);
     server.masterhost = NULL;
     if (server.master) freeClient(server.master);
     replicationDiscardCachedMaster();
     cancelReplicationHandshake(0);
     /* When a slave is turned into a master, the current replication ID
      * (that was inherited from the master at synchronization time) is
      * used as secondary ID up to the current offset, and a new replication
-     * ID is created to continue with a new replication history.
-     *
-     * NOTE: this function MUST be called after we call
-     * freeClient(server.master), since there we adjust the replication
-     * offset trimming the final PINGs. See Github issue #7320. */
+     * ID is created to continue with a new replication history. */
     shiftReplicationId();
     /* Disconnecting all the slaves is required: we need to inform slaves
      * of the replication ID change (see shiftReplicationId() call). However
      * the slaves will be able to partially resync with us, so it will be
      * a very fast reconnection. */
     disconnectSlaves();
     server.repl_state = REPL_STATE_NONE;
 
     /* We need to make sure the new master will start the replication stream
      * with a SELECT statement. This is forced after a full resync, but
      * with PSYNC version 2, there is no need for full resync after a
      * master switch. */
     server.slaveseldb = -1;
 
     /* Update oom_score_adj */
     setOOMScoreAdj(-1);
 
     /* Once we turn from slave to master, we consider the starting time without
      * slaves (that is used to count the replication backlog time to live) as
      * starting from now. Otherwise the backlog will be freed after a
      * failover if slaves do not connect immediately. */
     server.repl_no_slaves_since = server.unixtime;
     
     /* Reset down time so it'll be ready for when we turn into replica again. */
     server.repl_down_since = 0;
 
     /* Fire the role change modules event. */
     moduleFireServerEvent(REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED,
                           REDISMODULE_EVENT_REPLROLECHANGED_NOW_MASTER,
                           NULL);
 
     /* Restart the AOF subsystem in case we shut it down during a sync when
      * we were still a slave. */
     if (server.aof_enabled && server.aof_state == AOF_OFF) restartAOFAfterSYNC();
 }
 
 /* This function is called when the slave lose the connection with the
  * master into an unexpected way. */

[CORR] **new** commit 0413fbc7d015d2ad9a4f57cc50a68e581f0e7744
Date:   Mon Apr 19 02:34:21 2021 -0400

    fix invalid master_link_down_since_seconds in info repication (#8785)
    
    When replica never successfully connect to master, server.repl_down_since
    will be initialized to 0, therefore, the info master_link_down_since_seconds
    was showing the current unix timestamp, which does not make much sense.
    
    This commit fixes the issue by showing master_link_down_since_seconds to -1.
    means the replica never connect to master before.
    
    This commit also resets this variable back to 0 when a replica is turned into
    a master, so that it'll behave the same if the master is later turned into a
    replica again.
    
    The implication of this change is that if some app is checking if the value is > 60
    do something, like conclude the replica is stale, this could case harm (changing
    a big positive number with a small one).

diff --git a/src/replication.c b/src/replication.c
--- a/src/replication.c
+++ b/src/replication.c
@@ -2660,59 +2660,62 @@
 void replicationUnsetMaster(void) {
     if (server.masterhost == NULL) return; /* Nothing to do. */
 
     /* Fire the master link modules event. */
     if (server.repl_state == REPL_STATE_CONNECTED)
         moduleFireServerEvent(REDISMODULE_EVENT_MASTER_LINK_CHANGE,
                               REDISMODULE_SUBEVENT_MASTER_LINK_DOWN,
                               NULL);
 
     /* Clear masterhost first, since the freeClient calls
      * replicationHandleMasterDisconnection which can attempt to re-connect. */
     sdsfree(server.masterhost);
     server.masterhost = NULL;
     if (server.master) freeClient(server.master);
     replicationDiscardCachedMaster();
     cancelReplicationHandshake(0);
     /* When a slave is turned into a master, the current replication ID
      * (that was inherited from the master at synchronization time) is
      * used as secondary ID up to the current offset, and a new replication
      * ID is created to continue with a new replication history.
      *
      * NOTE: this function MUST be called after we call
      * freeClient(server.master), since there we adjust the replication
      * offset trimming the final PINGs. See Github issue #7320. */
     shiftReplicationId();
     /* Disconnecting all the slaves is required: we need to inform slaves
      * of the replication ID change (see shiftReplicationId() call). However
      * the slaves will be able to partially resync with us, so it will be
      * a very fast reconnection. */
     disconnectSlaves();
     server.repl_state = REPL_STATE_NONE;
 
     /* We need to make sure the new master will start the replication stream
      * with a SELECT statement. This is forced after a full resync, but
      * with PSYNC version 2, there is no need for full resync after a
      * master switch. */
     server.slaveseldb = -1;
 
     /* Update oom_score_adj */
     setOOMScoreAdj(-1);
 
     /* Once we turn from slave to master, we consider the starting time without
      * slaves (that is used to count the replication backlog time to live) as
      * starting from now. Otherwise the backlog will be freed after a
      * failover if slaves do not connect immediately. */
     server.repl_no_slaves_since = server.unixtime;
+    
+    /* Reset down time so it'll be ready for when we turn into replica again. */
+    server.repl_down_since = 0;
 
     /* Fire the role change modules event. */
     moduleFireServerEvent(REDISMODULE_EVENT_REPLICATION_ROLE_CHANGED,
                           REDISMODULE_EVENT_REPLROLECHANGED_NOW_MASTER,
                           NULL);
 
     /* Restart the AOF subsystem in case we shut it down during a sync when
      * we were still a slave. */
     if (server.aof_enabled && server.aof_state == AOF_OFF) restartAOFAfterSYNC();
 }
 
 /* This function is called when the slave lose the connection with the
  * master into an unexpected way. */
commit 93e85347136a483047e92a3a7554f428d6260b0c
Date:   Sun Oct 3 09:13:09 2021 +0300

    Remove argument count limit, dynamically grow argv. (#9528)
    
    Remove hard coded multi-bulk limit (was 1,048,576), new limit is INT_MAX.
    When client sends an m-bulk that's higher than 1024, we initially only allocate
    the argv array for 1024 arguments, and gradually grow that allocation as arguments
    are received.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -1205,12 +1206,15 @@
 void freeClientArgv(client *c) {
     int j;
     for (j = 0; j < c->argc; j++)
         decrRefCount(c->argv[j]);
     c->argc = 0;
     c->cmd = NULL;
     c->argv_len_sum = 0;
+    c->argv_len = 0;
+    zfree(c->argv);
+    c->argv = NULL;
 }
 
 /* Close all the slaves connections. This is useful in chained replication
  * when we resync with our own master and want to force all our slaves to
  * resync with us as well. */

[CORR] **new** commit 0b643e930d978862b3284ba742fba1a659832b8c
Date:   Mon Aug 9 01:03:59 2021 -0700

     Cleanup: createAOFClient uses createClient to avoid overlooked mismatches (#9338)
    
    AOF fake client creation (createAOFClient) was doing similar work as createClient,
    with some minor differences, most of which unintended, this was dangerous and
    meant that many changes to createClient should have always been reflected to aof.c
    
    This cleanup changes createAOFClient to call createClient with NULL, like we
    do in module.c and elsewhere.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -1187,12 +1187,12 @@
-static void freeClientArgv(client *c) {
+void freeClientArgv(client *c) {
     int j;
     for (j = 0; j < c->argc; j++)
         decrRefCount(c->argv[j]);
     c->argc = 0;
     c->cmd = NULL;
     c->argv_len_sum = 0;
 }
 
 /* Close all the slaves connections. This is useful in chained replication
  * when we resync with our own master and want to force all our slaves to
  * resync with us as well. */
[NA] **new** commit a1ae260e8addad04e1a73348c8f7bfeab398c2a9
Date:   Mon Jan 10 14:21:16 2022 +0800

    Make sure replicas don't write their own replies to the replication link (#10081)
    
    The following steps will crash redis-server:
    ```
    [root]# cat crash
    PSYNC replicationid -1
    SLOWLOG GET
    GET key
    [root]# nc 127.0.0.1 6379 < crash
    ```
    
    This one following #10020 and the crash was reported in #10076.
    
    Other changes about the output info:
    1. Cmd with a full name by using `getFullCommandName`, now it will print the right
       subcommand name like `slowlog|get`.
    2. Print the full client info by using `catClientInfoString`, the info is also valuable.:

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -1512,19 +1526,21 @@
 void freeClientAsync(client *c) {
     /* We need to handle concurrent access to the server.clients_to_close list
      * only in the freeClientAsync() function, since it's the only function that
      * may access the list while Redis uses I/O threads. All the other accesses
      * are in the context of the main thread while the other threads are
      * idle. */
     if (c->flags & CLIENT_CLOSE_ASAP || c->flags & CLIENT_SCRIPT) return;
     c->flags |= CLIENT_CLOSE_ASAP;
     if (server.io_threads_num == 1) {
         /* no need to bother with locking if there's just one thread (the main thread) */
         listAddNodeTail(server.clients_to_close,c);
         return;
     }
     static pthread_mutex_t async_free_queue_mutex = PTHREAD_MUTEX_INITIALIZER;
     pthread_mutex_lock(&async_free_queue_mutex);
     listAddNodeTail(server.clients_to_close,c);
     pthread_mutex_unlock(&async_free_queue_mutex);
 }
 
+/* Log errors for invalid use and free the client in async way.
+ * We will add additional information about the client to the message. */

[FUNC] **new** commit fc731bc67f8ecd07e83aa138b03a073028f9f3f2
Date:   Tue Oct 5 19:37:03 2021 +0300

    Redis Functions - Introduce script unit.
    
    Script unit is a new unit located on script.c.
    Its purpose is to provides an API for functions (and eval)
    to interact with Redis. Interaction includes mostly
    executing commands, but also functionalities like calling
    Redis back on long scripts or check if the script was killed.
    
    The interaction is done using a scriptRunCtx object that
    need to be created by the user and initialized using scriptPrepareForRun.
    
    Detailed list of functionalities expose by the unit:
    1. Calling commands (including all the validation checks such as
       acl, cluster, read only run, ...)
    2. Set Resp
    3. Set Replication method (AOF/REPLICATION/NONE)
    4. Call Redis back to on long running scripts to allow Redis reply
       to clients and perform script kill
    
    The commit introduce the new unit and uses it on eval commands to
    interact with Redis.

diff --git a/src/networking.c b/src/networking.c
--- a/src/networking.c
+++ b/src/networking.c
@@ -1488,19 +1489,19 @@
 void freeClientAsync(client *c) {
     /* We need to handle concurrent access to the server.clients_to_close list
      * only in the freeClientAsync() function, since it's the only function that
      * may access the list while Redis uses I/O threads. All the other accesses
      * are in the context of the main thread while the other threads are
      * idle. */
-    if (c->flags & CLIENT_CLOSE_ASAP || c->flags & CLIENT_LUA) return;
+    if (c->flags & CLIENT_CLOSE_ASAP || c->flags & CLIENT_SCRIPT) return;
     c->flags |= CLIENT_CLOSE_ASAP;
     if (server.io_threads_num == 1) {
         /* no need to bother with locking if there's just one thread (the main thread) */
         listAddNodeTail(server.clients_to_close,c);
         return;
     }
     static pthread_mutex_t async_free_queue_mutex = PTHREAD_MUTEX_INITIALIZER;
     pthread_mutex_lock(&async_free_queue_mutex);
     listAddNodeTail(server.clients_to_close,c);
     pthread_mutex_unlock(&async_free_queue_mutex);
 }
 
[FUNC] **new** commit 4aa927d16d4458124157bcc1d6a31b54df4f3a3f
Date:   Tue Aug 3 10:21:29 2021 +0100

    Enabled -x option (Read last argument from STDIN) on redis-benchmark  (#9130)
    
    Add the -x option (Read last argument from STDIN) on redis-benchmark.
    
    Other changes:
    To be able to use the code from redis-cli some helper methods were moved to cli_common.(h|c)
    
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/redis-cli.c b/src/redis-cli.c
--- a/src/redis-cli.c
+++ b/src/redis-cli.c
@@ -770,26 +770,9 @@
 static void freeHintsCallback(void *ptr) {
     sdsfree(ptr);
 }
 
 /*------------------------------------------------------------------------------
  * Networking / parsing
  *--------------------------------------------------------------------------- */
 
-/* Unquote a null-terminated string and return it as a binary-safe sds. */
-static sds unquoteCString(char *str) {
-    int count;
-    sds *unquoted = sdssplitargs(str, &count);
-    sds res = NULL;
-
-    if (unquoted && count == 1) {
-        res = unquoted[0];
-        unquoted[0] = NULL;
-    }
-
-    if (unquoted)
-        sdsfreesplitres(unquoted, count);
-
-    return res;
-}
-
 /* Send AUTH command to the server */

[FUNC] **new** commit 3c7d6a185329f2dc20c82a29bdbe125d5ad4140b
Date:   Thu Mar 4 15:03:49 2021 +0200

    Improve redis-cli non-binary safe string handling. (#8566)
    
    * The `redis-cli --scan` output should honor output mode (set explicitly or implicitly), and quote key names when not in raw mode.
      * Technically this is a breaking change, but it should be very minor since raw mode is by default on for non-tty output.
      * It should only affect  TTY output (human users) or non-tty output if `--no-raw` is specified.
    
    * Added `--quoted-input` option to treat all arguments as potentially quoted strings.
    * Added `--quoted-pattern` option to accept a potentially quoted pattern.
    
    Unquoting is applied to potentially quoted input only if single or double quotes are used.
    
    Fixes #8561, #8563

diff --git a/src/redis-cli.c b/src/redis-cli.c
--- a/src/redis-cli.c
+++ b/src/redis-cli.c
@@ -758,9 +759,26 @@
 static void freeHintsCallback(void *ptr) {
     sdsfree(ptr);
 }
 
 /*------------------------------------------------------------------------------
  * Networking / parsing
  *--------------------------------------------------------------------------- */
 
+/* Unquote a null-terminated string and return it as a binary-safe sds. */
+static sds unquoteCString(char *str) {
+    int count;
+    sds *unquoted = sdssplitargs(str, &count);
+    sds res = NULL;
+
+    if (unquoted && count == 1) {
+        res = unquoted[0];
+        unquoted[0] = NULL;
+    }
+
+    if (unquoted)
+        sdsfreesplitres(unquoted, count);
+
+    return res;
+}
+
 /* Send AUTH command to the server */
commit c81c7f51c38de6dff5ffc55b5184061b84c7ea5f
Date:   Wed Feb 23 22:34:58 2022 +0200

    Add stream consumer group lag tracking and reporting (#9127)
    
    Adds the ability to track the lag of a consumer group (CG), that is, the number
    of entries yet-to-be-delivered from the stream.
    
    The proposed constant-time solution is in the spirit of "best-effort."
    
    Partially addresses #8737.
    
    ## Description of approach
    
    We add a new "entries_added" property to the stream. This starts at 0 for a new
    stream and is incremented by 1 with every `XADD`.  It is essentially an all-time
    counter of the entries added to the stream.
    
    Given the stream's length and this counter value, we can trivially find the logical
    "entries_added" counter of the first ID if and only if the stream is contiguous.
    A fragmented stream contains one or more tombstones generated by `XDEL`s.
    The new "xdel_max_id" stream property tracks the latest tombstone.
    
    The CG also tracks its last delivered ID's as an "entries_read" counter and
    increments it independently when delivering new messages, unless the this
    read counter is invalid (-1 means invalid offset). When the CG's counter is
    available, the reported lag is the difference between added and read counters.
    
    Lastly, this also adds a "first_id" field to the stream structure in order to make
    looking it up cheaper in most cases.
    
    ## Limitations
    
    There are two cases in which the mechanism isn't able to track the lag.
    In these cases, `XINFO` replies with `null` in the "lag" field.
    
    The first case is when a CG is created with an arbitrary last delivered ID,
    that isn't "0-0", nor the first or the last entries of the stream. In this case,
    it is impossible to obtain a valid read counter (short of an O(N) operation).
    The second case is when there are one or more tombstones fragmenting
    the stream's entries range.
    
    In both cases, given enough time and assuming that the consumers are
    active (reading and lacking) and advancing, the CG should be able to
    catch up with the tip of the stream and report zero lag.
    Once that's achieved, lag tracking would resume as normal (until the
    next tombstone is set).
    
    ## API changes
    
    * `XGROUP CREATE` added with the optional named argument `[ENTRIESREAD entries-read]`
      for explicitly specifying the new CG's counter.
    * `XGROUP SETID` added with an optional positional argument `[ENTRIESREAD entries-read]`
      for specifying the CG's counter.
    * `XINFO` reports the maximal tombstone ID, the recorded first entry ID, and total
      number of entries added to the stream.
    * `XINFO` reports the current lag and logical read counter of CGs.
    * `XSETID` is an internal command that's used in replication/aof. It has been added with
      the optional positional arguments `[ENTRIESADDED entries-added] [MAXDELETEDID max-deleted-entry-id]`
      for propagating the CG's offset and maximal tombstone ID of the stream.
    
    ## The generic unsolved problem
    
    The current stream implementation doesn't provide an efficient way to obtain the
    approximate/exact size of a range of entries. While it could've been nice to have
    that ability (#5813) in general, let alone specifically in the context of CGs, the risk
    and complexities involved in such implementation are in all likelihood prohibitive.
    
    ## A refactoring note
    
    The `streamGetEdgeID` has been refactored to accommodate both the existing seek
    of any entry as well as seeking non-deleted entries (the addition of the `skip_tombstones`
    argument). Furthermore, this refactoring also migrated the seek logic to use the
    `streamIterator` (rather than `raxIterator`) that was, in turn, extended with the
    `skip_tombstones` Boolean struct field to control the emission of these.
    
    Co-authored-by: Guy Benoish <guy.benoish@redislabs.com>
    Co-authored-by: Oran Agra <oran@redislabs.com>

diff --git a/src/t_stream.c b/src/t_stream.c
--- a/src/t_stream.c
+++ b/src/t_stream.c
@@ -2293,12 +2455,11 @@
 void streamFreeConsumer(streamConsumer *sc) {
     raxFree(sc->pel); /* No value free callback: the PEL entries are shared
                          between the consumer and the main stream PEL. */
     sdsfree(sc->name);
     zfree(sc);
 }
 
 /* Create a new consumer group in the context of the stream 's', having the
- * specified name and last server ID. If a consumer group with the same name
- * already existed NULL is returned, otherwise the pointer to the consumer
- * group is returned. */
-streamCG *streamCreateCG(stream *s, char *name, size_t namelen, streamID *id) {
+ * specified name, last server ID and reads counter. If a consumer group with
+ * the same name already exists NULL is returned, otherwise the pointer to the
+ * consumer group is returned. */
